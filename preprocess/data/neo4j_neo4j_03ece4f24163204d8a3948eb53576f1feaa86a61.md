Refactoring Types: ['Move Attribute']
/neo4j/io/fs/DefaultFileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.fs;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.RandomAccessFile;
import java.io.Reader;
import java.io.Writer;
import java.nio.channels.FileChannel;
import java.util.HashMap;
import java.util.Map;

import org.neo4j.function.Function;

import static java.lang.String.format;

/**
 * Default file system abstraction that creates files using the underlying file system.
 */
public class DefaultFileSystemAbstraction
        implements FileSystemAbstraction
{
    static final String UNABLE_TO_CREATE_DIRECTORY_FORMAT = "Unable to create directory path [%s] for Neo4j store.";

    @Override
    public StoreFileChannel open( File fileName, String mode ) throws IOException
    {
        // Returning only the channel is ok, because the channel, when close()d will close its parent File.
        FileChannel channel = new RandomAccessFile( fileName, mode ).getChannel();
        return new StoreFileChannel( channel );
    }

    @Override
    public OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException
    {
        return new FileOutputStream( fileName, append );
    }

    @Override
    public InputStream openAsInputStream( File fileName ) throws IOException
    {
        return new FileInputStream( fileName );
    }

    @Override
    public Reader openAsReader( File fileName, String encoding ) throws IOException
    {
        return new InputStreamReader( new FileInputStream( fileName ), encoding );
    }

    @Override
    public Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException
    {
        return new OutputStreamWriter( new FileOutputStream( fileName, append ), encoding );
    }

    @Override
    public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
    {
        return FileLock.getOsSpecificFileLock( fileName, channel );
    }

    @Override
    public StoreFileChannel create( File fileName ) throws IOException
    {
        return open( fileName, "rw" );
    }

    @Override
    public boolean mkdir( File fileName )
    {
        return fileName.mkdir();
    }

    @Override
    public void mkdirs( File path ) throws IOException
    {
        if (path.exists())
        {
            return;
        }

        boolean directoriesWereCreated = path.mkdirs();

        if (directoriesWereCreated)
        {
            return;
        }

        throw new IOException( format( UNABLE_TO_CREATE_DIRECTORY_FORMAT, path ) );
    }

    @Override
    public boolean fileExists( File fileName )
    {
        return fileName.exists();
    }

    @Override
    public long getFileSize( File fileName )
    {
        return fileName.length();
    }

    @Override
    public boolean deleteFile( File fileName )
    {
        return FileUtils.deleteFile( fileName );
    }

    @Override
    public void deleteRecursively( File directory ) throws IOException
    {
        FileUtils.deleteRecursively( directory );
    }

    @Override
    public boolean renameFile( File from, File to ) throws IOException
    {
        return FileUtils.renameFile( from, to );
    }

    @Override
    public File[] listFiles( File directory )
    {
        return directory.listFiles();
    }

    @Override
    public File[] listFiles( File directory, FilenameFilter filter )
    {
        return directory.listFiles( filter );
    }

    @Override
    public boolean isDirectory( File file )
    {
        return file.isDirectory();
    }

    @Override
    public void moveToDirectory( File file, File toDirectory ) throws IOException
    {
        FileUtils.moveFileToDirectory( file, toDirectory );
    }

    @Override
    public void copyFile( File from, File to ) throws IOException
    {
        FileUtils.copyFile( from, to );
    }

    @Override
    public void copyRecursively( File fromDirectory, File toDirectory ) throws IOException
    {
        FileUtils.copyRecursively( fromDirectory, toDirectory );
    }

    private final Map<Class<? extends ThirdPartyFileSystem>, ThirdPartyFileSystem> thirdPartyFileSystems =
            new HashMap<>();

    @Override
    public synchronized <K extends ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem(
            Class<K> clazz, Function<Class<K>, K> creator )
    {
        ThirdPartyFileSystem fileSystem = thirdPartyFileSystems.get( clazz );
        if (fileSystem == null)
        {
            thirdPartyFileSystems.put( clazz, fileSystem = creator.apply( clazz ) );
        }
        return clazz.cast( fileSystem );
    }
}


File: community/io/src/main/java/org/neo4j/io/fs/DelegateFileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.fs;

import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.Reader;
import java.io.Writer;
import java.nio.file.DirectoryStream;
import java.nio.file.FileSystem;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.StandardCopyOption;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.neo4j.function.Function;

/**
 * This FileSystemAbstract implementation delegates all calls to a given {@link FileSystem} implementation.
 * This is useful for testing with arbitrary 3rd party file systems, such as Jimfs.
 */
public class DelegateFileSystemAbstraction implements FileSystemAbstraction
{
    private final FileSystem fs;

    public DelegateFileSystemAbstraction( FileSystem fs )
    {
        this.fs = fs;
    }

    @Override
    public StoreChannel open( File fileName, String mode ) throws IOException
    {
        return new StoreFileChannel( FileUtils.open( path( fileName ), mode ) );
    }

    private Path path( File fileName )
    {
        return path( fileName.getPath() );
    }

    private Path path( String fileName )
    {
        return fs.getPath( fileName );
    }

    @Override
    public OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException
    {
        return FileUtils.openAsOutputStream( path( fileName ), append );
    }

    @Override
    public InputStream openAsInputStream( File fileName ) throws IOException
    {
        return FileUtils.openAsInputStream( path( fileName ) );
    }

    @Override
    public Reader openAsReader( File fileName, String encoding ) throws IOException
    {
        return new InputStreamReader( openAsInputStream( fileName ), encoding );
    }

    @Override
    public Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException
    {
        return new OutputStreamWriter( openAsOutputStream( fileName, append ), encoding );
    }

    @Override
    public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
    {
        final java.nio.channels.FileLock lock = channel.tryLock();
        return new FileLock()
        {
            @Override
            public void release() throws IOException
            {
                lock.release();
            }
        };
    }

    @Override
    public StoreChannel create( File fileName ) throws IOException
    {
        return open( fileName, "rw" );
    }

    @Override
    public boolean fileExists( File fileName )
    {
        return Files.exists( path( fileName ) );
    }

    @Override
    public boolean mkdir( File fileName )
    {
        if ( !fileExists( fileName ) )
        {
            try
            {
                Files.createDirectory( path( fileName ) );
                return true;
            }
            catch ( IOException ignore )
            {
            }
        }
        return false;
    }

    @Override
    public void mkdirs( File fileName ) throws IOException
    {
        Files.createDirectories( path( fileName ) );
    }

    @Override
    public long getFileSize( File fileName )
    {
        try
        {
            return Files.size( path( fileName ) );
        }
        catch ( IOException e )
        {
            return 0;
        }
    }

    @Override
    public boolean deleteFile( File fileName )
    {
        try
        {
            Files.delete( path( fileName ) );
            return true;
        }
        catch ( IOException e )
        {
            return false;
        }
    }

    @Override
    public void deleteRecursively( File directory ) throws IOException
    {
        if ( fileExists( directory ) )
        {
            FileUtils.deletePathRecursively( path( directory ) );
        }
    }

    @Override
    public boolean renameFile( File from, File to ) throws IOException
    {
        Files.move( path( from ), path( to ) );
        return true;
    }

    @Override
    public File[] listFiles( File directory )
    {
        List<File> files = new ArrayList<>();
        try
        {
            for ( Path path : Files.newDirectoryStream( path( directory ) ) )
            {
                files.add( path.toFile() );
            }
        }
        catch ( IOException e )
        {
            return null;
        }
        return files.toArray( new File[files.size()] );
    }

    @Override
    public File[] listFiles( File directory, final FilenameFilter filter )
    {
        List<File> files = new ArrayList<>();
        try
        {
            DirectoryStream.Filter<Path> dirfilter = new DirectoryStream.Filter<Path>()
            {
                @Override
                public boolean accept( Path entry ) throws IOException
                {
                    return filter.accept( entry.getParent().toFile(), entry.getFileName().toString() );
                }
            };
            for ( Path path : Files.newDirectoryStream( path( directory ), dirfilter ) )
            {
                files.add( path.toFile() );
            }
        }
        catch ( IOException e )
        {
            return null;
        }
        return files.toArray( new File[files.size()] );
    }

    @Override
    public boolean isDirectory( File file )
    {
        return Files.isDirectory( path( file ) );
    }

    @Override
    public void moveToDirectory( File file, File toDirectory ) throws IOException
    {
        Files.move( path( file ), path( toDirectory ).resolve( path( file.getName() ) ) );
    }

    @Override
    public void copyFile( File from, File to ) throws IOException
    {
        Files.copy( path( from ), path( to ) );
    }

    @Override
    public void copyRecursively( File fromDirectory, File toDirectory ) throws IOException
    {
        Path target = path( toDirectory );
        Path source = path( fromDirectory );
        copyRecursively( source, target );
    }

    private void copyRecursively( Path source, Path target ) throws IOException
    {
        for ( Path sourcePath : Files.newDirectoryStream( source ) )
        {
            Path targetPath = target.resolve( sourcePath.getFileName() );
            if ( Files.isDirectory( sourcePath ) )
            {
                Files.createDirectories( targetPath );
                copyRecursively( sourcePath, targetPath );
            }
            else
            {
                Files.copy( sourcePath, targetPath,
                        StandardCopyOption.REPLACE_EXISTING, StandardCopyOption.COPY_ATTRIBUTES );
            }
        }
    }

    private final Map<Class<?>,Object> thirdPartyFs = new HashMap<>();

    @Override
    public synchronized <K extends ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem(
            Class<K> clazz, Function<Class<K>,K> creator )
    {
        // what in the ever-loving mother of the lake is this!?
        K otherFs = (K) thirdPartyFs.get( clazz );
        if ( otherFs == null )
        {
            otherFs = creator.apply( clazz );
            thirdPartyFs.put( clazz, otherFs );
        }
        return otherFs;
    }
}


File: community/io/src/main/java/org/neo4j/io/fs/FileLock.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.fs;

import java.io.File;
import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.channels.FileChannel;
import java.nio.channels.OverlappingFileLockException;

public abstract class FileLock
{
    // This should not be here, see note in getOsSpecificFileLock.
    public static final String STORE_LOCK_FILENAME = "store_lock";

    // This should not be here, see note in getOsSpecificFileLock
    public static final String NEO_STORE_NAME = "neostore";

    private static FileLock wrapFileChannelLock( StoreChannel channel ) throws IOException
    {
        final java.nio.channels.FileLock lock = channel.tryLock();
        if ( lock == null )
        {
            throw new IOException( "Unable to lock " + channel );
        }

        return new FileLock()
        {
            @Override
            public void release() throws IOException
            {
                lock.release();
            }
        };
    }

    public static FileLock getOsSpecificFileLock( File fileName, StoreChannel channel )
            throws IOException
    {
        if ( FileUtils.OS_IS_WINDOWS )
        {
            // TODO: This code should not be here. It is file-specific, and the logic here should
            // be handled in the StoreLocker.

            /*
             * We need to grab only one lock for the whole store. Even though every store will try to grab one
             * we will honor only the top level, dedicated store lock. This has the benefit that older versions of
             * Neo4j that do not have a dedicated locker still lock on the parent file of neostore so this will still
             * block when new instances are started on top of in use older stores and vice versa.
             */
            if ( fileName.getName().equals( STORE_LOCK_FILENAME ) )
            {
                return getLockFileBasedFileLock( fileName.getParentFile() );
            }

            // For the rest just return placebo locks
            return new PlaceboFileLock();
        }
        else if ( fileName.getName().equals( NEO_STORE_NAME ) )
        {
            // Lock the file
            FileLock regular = wrapFileChannelLock( channel );
            
            // Lock the parent as well
            boolean success = false;
            try
            {
                FileLock extra = getLockFileBasedFileLock( fileName.getParentFile() );
                success = true;
                return new DoubleFileLock( regular, extra );
            }
            finally
            {
                if ( !success )
                {   // The parent lock failed, so unlock the regular too
                    regular.release();
                }
            }
        }
        else
        {
            return wrapFileChannelLock( channel );
        }
    }

    private static FileLock getLockFileBasedFileLock( File storeDir ) throws IOException
    {
        File lockFile = new File( storeDir, "lock" );
        if ( !lockFile.exists() )
        {
            if ( !lockFile.createNewFile() )
            {
                throw new IOException( "Couldn't create lock file " + lockFile.getAbsolutePath() );
            }
        }
        FileChannel fileChannel = new RandomAccessFile( lockFile, "rw" ).getChannel();
        java.nio.channels.FileLock fileChannelLock = null;
        try
        {
            fileChannelLock = fileChannel.tryLock();
        }
        catch ( OverlappingFileLockException e )
        {
            // OK, let fileChannelLock continue to be null and we'll deal with it below
        }
        if ( fileChannelLock == null )
        {
            fileChannel.close();
            throw new IOException( "Couldn't lock lock file " + lockFile.getAbsolutePath()  +
                    " because another process already holds the lock." );
        }
        return new WindowsFileLock( lockFile, fileChannel, fileChannelLock );
    }

    public abstract void release() throws IOException;

    private static class PlaceboFileLock extends FileLock
    {
        @Override
        public void release() throws IOException
        {
        }
    }

    private static class DoubleFileLock extends FileLock
    {
        private final FileLock regular;
        private final FileLock extra;

        DoubleFileLock( FileLock regular, FileLock extra )
        {
            this.regular = regular;
            this.extra = extra;
        }

        @Override
        public void release() throws IOException
        {
            regular.release();
            extra.release();
        }
    }

    private static class WindowsFileLock extends FileLock
    {
        private final File lockFile;
        private final FileChannel fileChannel;
        private final java.nio.channels.FileLock fileChannelLock;

        public WindowsFileLock( File lockFile, FileChannel fileChannel, java.nio.channels.FileLock lock )
        {
            this.lockFile = lockFile;
            this.fileChannel = fileChannel;
            this.fileChannelLock = lock;
        }

        @Override
        public void release() throws IOException
        {
            try
            {
                fileChannelLock.release();
            }
            finally
            {
                try
                {
                    fileChannel.close();
                }
                finally
                {
                    if ( !lockFile.delete() )
                    {
                        throw new IOException( "Couldn't delete lock file " + lockFile.getAbsolutePath() );
                    }
                }
            }
        }
    }
}


File: community/io/src/main/java/org/neo4j/io/fs/FileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.fs;

import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.Reader;
import java.io.Writer;
import java.util.zip.ZipOutputStream;

import org.neo4j.function.Function;

public interface FileSystemAbstraction
{
    StoreChannel open( File fileName, String mode ) throws IOException;
    
    OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException;
    
    InputStream openAsInputStream( File fileName ) throws IOException;
    
    Reader openAsReader( File fileName, String encoding ) throws IOException;
    
    Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException;
    
    FileLock tryLock( File fileName, StoreChannel channel ) throws IOException;
    
    StoreChannel create( File fileName ) throws IOException;
    
    boolean fileExists( File fileName );
    
    boolean mkdir( File fileName );
    
    void mkdirs( File fileName ) throws IOException;
    
    long getFileSize( File fileName );

    boolean deleteFile( File fileName );
    
    void deleteRecursively( File directory ) throws IOException;
    
    boolean renameFile( File from, File to ) throws IOException;
    
    File[] listFiles( File directory );

    File[] listFiles( File directory, FilenameFilter filter );

    boolean isDirectory( File file );
    
    void moveToDirectory( File file, File toDirectory ) throws IOException;
    
    void copyFile( File from, File to ) throws IOException;
    
    void copyRecursively( File fromDirectory, File toDirectory ) throws IOException;

    <K extends ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem( Class<K> clazz, Function<Class<K>, K> creator );

    interface ThirdPartyFileSystem
    {
        void close();

        void dumpToZip( ZipOutputStream zip, byte[] scratchPad ) throws IOException;
    }
}


File: community/io/src/main/java/org/neo4j/io/pagecache/impl/SingleFilePageSwapper.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.pagecache.impl;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.ClosedChannelException;

import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.io.pagecache.Page;
import org.neo4j.io.pagecache.PageCursor;
import org.neo4j.io.pagecache.PageEvictionCallback;
import org.neo4j.io.pagecache.PageSwapper;
import org.neo4j.io.pagecache.impl.muninn.MuninnPageCache;
import org.neo4j.unsafe.impl.internal.dragons.UnsafeUtil;

import static java.lang.String.format;

/**
 * A simple PageSwapper implementation that directs all page swapping to a
 * single file on the file system.
 *
 * It additionally tracks the file size precisely, to avoid calling into the
 * file system whenever the size of the given file is queried.
 */
public class SingleFilePageSwapper implements PageSwapper
{
    private static int defaultChannelStripePower()
    {
        int vcores = Runtime.getRuntime().availableProcessors();
        // Find the lowest 2's exponent that can accommodate 'vcores'
        int stripePower = 32 - Integer.numberOfLeadingZeros( vcores - 1 );
        return Math.min( 64, Math.max( 1, stripePower ) );
    }

    // Exponent of 2 of how many channels we open per file:
    private static final int channelStripePower = Integer.getInteger(
            "org.neo4j.io.pagecache.implSingleFilePageSwapper.channelStripePower",
            defaultChannelStripePower() );

    // Exponent of 2 of how many consecutive pages go to the same stripe
    private static final int channelStripeShift = Integer.getInteger(
            "org.neo4j.io.pagecache.implSingleFilePageSwapper.channelStripeShift", 4 );

    private static final int channelStripeCount = 1 << channelStripePower;
    private static final int channelStripeMask = channelStripeCount - 1;

    private static final long fileSizeOffset =
            UnsafeUtil.getFieldOffset( SingleFilePageSwapper.class, "fileSize" );

    private static final ThreadLocal<ByteBuffer> proxyCache = new ThreadLocal<>();

    private static ByteBuffer proxy( long buffer, int bufferLength ) throws IOException
    {
        ByteBuffer buf = proxyCache.get();
        if ( buf != null )
        {
            UnsafeUtil.initDirectByteBuffer( buf, buffer, bufferLength );
            return buf;
        }
        return createAndGetNewBuffer( buffer, bufferLength );
    }

    private static ByteBuffer createAndGetNewBuffer( long buffer, int bufferLength ) throws IOException
    {
        ByteBuffer buf;
        try
        {
            buf = UnsafeUtil.newDirectByteBuffer( buffer, bufferLength );
        }
        catch ( Exception e )
        {
            throw new IOException( e );
        }
        proxyCache.set( buf );
        return buf;
    }

    private final FileSystemAbstraction fs;
    private final File file;
    private final int filePageSize;
    private volatile PageEvictionCallback onEviction;
    private final StoreChannel[] channels;

    // Guarded by synchronized(this). See tryReopen() and close().
    private boolean closed;

    @SuppressWarnings( "unused" ) // Accessed through unsafe
    private volatile long fileSize;

    public SingleFilePageSwapper(
            File file,
            FileSystemAbstraction fs,
            int filePageSize,
            PageEvictionCallback onEviction ) throws IOException
    {
        this.fs = fs;
        this.file = file;
        this.channels = new StoreChannel[channelStripeCount];
        for ( int i = 0; i < channelStripeCount; i++ )
        {
            channels[i] = fs.open( file, "rw" );
        }
        this.filePageSize = filePageSize;
        this.onEviction = onEviction;
        increaseFileSizeTo( channels[0].size() );
    }

    private void increaseFileSizeTo( long newFileSize )
    {
        long currentFileSize;
        do
        {
            currentFileSize = getCurrentFileSize();
        }
        while ( currentFileSize < newFileSize && !UnsafeUtil.compareAndSwapLong(
                this, fileSizeOffset, currentFileSize, newFileSize ) );
    }

    private long getCurrentFileSize()
    {
        return UnsafeUtil.getLongVolatile( this, fileSizeOffset );
    }

    private void setCurrentFileSize( long size )
    {
        UnsafeUtil.putLongVolatile( this, fileSizeOffset, size );
    }

    private StoreChannel channel( long filePageId )
    {
        int stripe = stripe( filePageId );
        return channels[stripe];
    }

    private static int stripe( long filePageId )
    {
        return (int) (filePageId >>> channelStripeShift) & channelStripeMask;
    }

    private int swapIn( StoreChannel channel, Page page, long fileOffset, int filePageSize ) throws IOException
    {
        int cachePageSize = page.size();
        long address = page.address();
        int readTotal = 0;
        try
        {
            ByteBuffer bufferProxy = proxy( address, filePageSize );
            int read;
            do
            {
                read = channel.read( bufferProxy, fileOffset + readTotal );
            }
            while ( read != -1 && (readTotal += read) < filePageSize );

            // Zero-fill the rest.
            assert readTotal >= 0 && filePageSize <= cachePageSize && readTotal <= filePageSize: format(
                    "pointer = %h, readTotal = %s, length = %s, page size = %s",
                    address, readTotal, filePageSize, cachePageSize );
            UnsafeUtil.setMemory( address + readTotal, filePageSize - readTotal, MuninnPageCache.ZERO_BYTE );
            return readTotal;
        }
        catch ( IOException e )
        {
            throw e;
        }
        catch ( Throwable e )
        {
            String msg = format(
                    "Read failed after %s of %s bytes from fileOffset %s",
                    readTotal, filePageSize, fileOffset );
            throw new IOException( msg, e );
        }
    }

    private int swapOut( Page page, long fileOffset, StoreChannel channel ) throws IOException
    {
        try
        {
            ByteBuffer bufferProxy = proxy( page.address(), filePageSize );
            channel.writeAll( bufferProxy, fileOffset );
        }
        catch ( IOException e )
        {
            throw e;
        }
        catch ( Throwable e )
        {
            throw new IOException( e );
        }
        return filePageSize;
    }

    private void clear( Page page )
    {
        UnsafeUtil.setMemory( page.address(), page.size(), MuninnPageCache.ZERO_BYTE );
    }

    @Override
    public int read( long filePageId, Page page ) throws IOException
    {
        long fileOffset = pageIdToPosition( filePageId );
        try
        {
            if ( fileOffset < getCurrentFileSize() )
            {
                return swapIn( channel( filePageId ), page, fileOffset, filePageSize );
            }
            else
            {
                clear( page );
            }
        }
        catch ( ClosedChannelException e )
        {
            // AsynchronousCloseException is a subclass of
            // ClosedChannelException, and ClosedByInterruptException is in
            // turn a subclass of AsynchronousCloseException.
            tryReopen( filePageId, e );
            boolean interrupted = Thread.interrupted();
            // Recurse because this is hopefully a very rare occurrence.
            int bytesRead = read( filePageId, page );
            if ( interrupted )
            {
                Thread.currentThread().interrupt();
            }
            return bytesRead;
        }
        return 0;
    }

    @Override
    public int write( long filePageId, Page page ) throws IOException
    {
        long fileOffset = pageIdToPosition( filePageId );
        increaseFileSizeTo( fileOffset + filePageSize );
        try
        {
            StoreChannel channel = channel( filePageId );
            return swapOut( page, fileOffset, channel );
        }
        catch ( ClosedChannelException e )
        {
            // AsynchronousCloseException is a subclass of
            // ClosedChannelException, and ClosedByInterruptException is in
            // turn a subclass of AsynchronousCloseException.
            tryReopen( filePageId, e );
            boolean interrupted = Thread.interrupted();
            // Recurse because this is hopefully a very rare occurrence.
            int bytesWritten = write( filePageId, page );
            if ( interrupted )
            {
                Thread.currentThread().interrupt();
            }
            return bytesWritten;
        }
    }

    @Override
    public void evicted( long filePageId, Page page )
    {
        PageEvictionCallback callback = this.onEviction;
        if ( callback != null )
        {
            callback.onEvict( filePageId, page );
        }
    }

    @Override
    public File file()
    {
        return file;
    }

    private long pageIdToPosition( long pageId )
    {
        return filePageSize * pageId;
    }

    @Override
    public boolean equals( Object o )
    {
        if ( this == o )
        { return true; }
        if ( o == null || getClass() != o.getClass() )
        { return false; }

        SingleFilePageSwapper that = (SingleFilePageSwapper) o;

        return file.equals( that.file );

    }

    @Override
    public int hashCode()
    {
        return file.hashCode();
    }

    /**
     * Reopens the channel if it has been closed and the close() method on
     * this swapper has not been called. In other words, if the channel has
     * been "accidentally" closed by an interrupt or the like.
     *
     * If the channel has been explicitly closed with the PageSwapper#close()
     * method, then this method will re-throw the passed-in exception.
     *
     * If the reopening of the file fails with an exception for some reason,
     * then that exception is added as a suppressed exception to the passed in
     * ClosedChannelException, and the CCE is then rethrown.
     */
    private synchronized void tryReopen( long filePageId, ClosedChannelException closedException ) throws ClosedChannelException
    {
        int stripe = stripe( filePageId );
        StoreChannel channel = channels[stripe];
        if ( channel.isOpen() )
        {
            // Someone got ahead of us, presumably. Nothing to do.
            return;
        }

        if ( closed )
        {
            // We've been explicitly closed, so we shouldn't reopen the
            // channel.
            throw closedException;
        }

        try
        {
            channels[stripe] = fs.open( file, "rw" );
        }
        catch ( IOException e )
        {
            closedException.addSuppressed( e );
            throw closedException;
        }
    }

    @Override
    public synchronized void close() throws IOException
    {
        closed = true;
        for ( StoreChannel channel : channels )
        {
            channel.close();
        }

        // Eagerly relinquish our reference to the onEviction callback, because even though
        // we've closed the PagedFile at this point, there are likely still pages in the cache that are bound to this
        // swapper, and will stay bound, until the eviction threads eventually gets around to kicking them out.
        // It is especially important to null out the onEviction callback field, because it is in turn holding on to
        // the striped translation table, which can be a rather large structure.
        onEviction = null;
    }

    @Override
    public void force() throws IOException
    {
        int tokenFilePageId = 0;
        try
        {
            channel( tokenFilePageId ).force( false );
        }
        catch ( ClosedChannelException e )
        {
            // AsynchronousCloseException is a subclass of
            // ClosedChannelException, and ClosedByInterruptException is in
            // turn a subclass of AsynchronousCloseException.
            tryReopen( tokenFilePageId, e );
            boolean interrupted = Thread.interrupted();
            // Recurse because this is hopefully a very rare occurrence.
            force();
            if ( interrupted )
            {
                Thread.currentThread().interrupt();
            }
        }
    }

    @Override
    public long getLastPageId() throws IOException
    {
        long channelSize = getCurrentFileSize();
        if ( channelSize == 0 )
        {
            return PageCursor.UNBOUND_PAGE_ID;
        }
        long div = channelSize / filePageSize;
        long mod = channelSize % filePageSize;
        return mod == 0? div - 1 : div;
    }

    @Override
    public void truncate() throws IOException
    {
        setCurrentFileSize( 0 );
        int tokenFilePageId = 0;
        try
        {
            channel( tokenFilePageId ).truncate( 0 );
        }
        catch ( ClosedChannelException e )
        {
            // AsynchronousCloseException is a subclass of
            // ClosedChannelException, and ClosedByInterruptException is in
            // turn a subclass of AsynchronousCloseException.
            tryReopen( tokenFilePageId, e );
            boolean interrupted = Thread.interrupted();
            // Recurse because this is hopefully a very rare occurrence.
            truncate();
            if ( interrupted )
            {
                Thread.currentThread().interrupt();
            }
        }
    }

    @Override
    public String toString()
    {
        return "SingleFilePageSwapper{" +
                "filePageSize=" + filePageSize +
                ", file=" + file +
                '}';
    }
}


File: community/io/src/test/java/org/neo4j/adversaries/fs/AdversarialFileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.adversaries.fs;

import java.io.File;
import java.io.FileNotFoundException;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.Reader;
import java.io.UnsupportedEncodingException;
import java.io.Writer;
import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;
import java.util.HashMap;
import java.util.Map;

import org.neo4j.adversaries.Adversary;
import org.neo4j.function.Function;
import org.neo4j.io.fs.DefaultFileSystemAbstraction;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;

/**
 * Used by the robustness suite to check for partial failures.
 */
@SuppressWarnings("unchecked")
public class AdversarialFileSystemAbstraction implements FileSystemAbstraction
{
    private final FileSystemAbstraction delegate;
    private final Adversary adversary;

    public AdversarialFileSystemAbstraction( Adversary adversary )
    {
        this( adversary, new DefaultFileSystemAbstraction() );
    }

    public AdversarialFileSystemAbstraction( Adversary adversary, FileSystemAbstraction delegate )
    {
        this.adversary = adversary;
        this.delegate = delegate;
    }

    public StoreChannel open( File fileName, String mode ) throws IOException
    {
        adversary.injectFailure( FileNotFoundException.class, IOException.class, SecurityException.class );
        return new AdversarialFileChannel( delegate.open( fileName, mode ), adversary );
    }

    public boolean renameFile( File from, File to ) throws IOException
    {
        adversary.injectFailure( FileNotFoundException.class, SecurityException.class );
        return delegate.renameFile( from, to );
    }

    public OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException
    {
        adversary.injectFailure( FileNotFoundException.class, SecurityException.class );
        return new AdversarialOutputStream( delegate.openAsOutputStream( fileName, append ), adversary );
    }

    public StoreChannel create( File fileName ) throws IOException
    {
        adversary.injectFailure( FileNotFoundException.class, IOException.class, SecurityException.class );
        return new AdversarialFileChannel( delegate.create( fileName ), adversary );
    }

    public boolean mkdir( File fileName )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.mkdir( fileName );
    }

    public File[] listFiles( File directory )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.listFiles( directory );
    }

    public File[] listFiles( File directory, FilenameFilter filter )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.listFiles( directory, filter );
    }

    public Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException
    {
        adversary.injectFailure(
                UnsupportedEncodingException.class, FileNotFoundException.class, SecurityException.class );
        return new AdversarialWriter( delegate.openAsWriter( fileName, encoding, append ), adversary );
    }

    public Reader openAsReader( File fileName, String encoding ) throws IOException
    {
        adversary.injectFailure(
                UnsupportedEncodingException.class, FileNotFoundException.class, SecurityException.class );
        return new AdversarialReader( delegate.openAsReader( fileName, encoding ), adversary );
    }

    public long getFileSize( File fileName )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.getFileSize( fileName );
    }

    public void copyFile( File from, File to ) throws IOException
    {
        adversary.injectFailure( SecurityException.class, FileNotFoundException.class, IOException.class );
        delegate.copyFile( from, to );
    }

    public void copyRecursively( File fromDirectory, File toDirectory ) throws IOException
    {
        adversary.injectFailure( SecurityException.class, IOException.class, NullPointerException.class );
        delegate.copyRecursively( fromDirectory, toDirectory );
    }

    public boolean deleteFile( File fileName )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.deleteFile( fileName );
    }

    public InputStream openAsInputStream( File fileName ) throws IOException
    {
        adversary.injectFailure( FileNotFoundException.class, SecurityException.class );
        return new AdversarialInputStream( delegate.openAsInputStream( fileName ), adversary );
    }

    public void moveToDirectory( File file, File toDirectory ) throws IOException
    {
        adversary.injectFailure(
                SecurityException.class, IllegalArgumentException.class, FileNotFoundException.class,
                NullPointerException.class, IOException.class );
        delegate.moveToDirectory( file, toDirectory );
    }

    public boolean isDirectory( File file )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.isDirectory( file );
    }

    public boolean fileExists( File fileName )
    {
        adversary.injectFailure( SecurityException.class );
        return delegate.fileExists( fileName );
    }

    public void mkdirs( File fileName ) throws IOException
    {
        adversary.injectFailure( SecurityException.class, IOException.class );
        delegate.mkdirs( fileName );
    }

    public void deleteRecursively( File directory ) throws IOException
    {
        adversary.injectFailure( SecurityException.class, NullPointerException.class, IOException.class );
        delegate.deleteRecursively( directory );
    }

    public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
    {
        adversary.injectFailure( SecurityException.class, IOException.class, FileNotFoundException.class );
        return delegate.tryLock( fileName, channel );
    }

    private final Map<Class<? extends ThirdPartyFileSystem>, ThirdPartyFileSystem> thirdPartyFileSystems =
            new HashMap<>();

    @Override
    public synchronized <K extends ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem(
            Class<K> clazz,
            Function<Class<K>, K> creator )
    {
        ThirdPartyFileSystem fileSystem = thirdPartyFileSystems.get( clazz );
        if (fileSystem == null)
        {
            fileSystem = creator.apply( clazz );
            fileSystem = adversarialProxy( fileSystem, clazz );
            thirdPartyFileSystems.put( clazz, fileSystem );
        }
        return (K) fileSystem;
    }

    private <K extends ThirdPartyFileSystem> ThirdPartyFileSystem adversarialProxy(
            final ThirdPartyFileSystem fileSystem,
            Class<K> clazz )
    {
        InvocationHandler handler = new InvocationHandler()
        {
            @Override
            public Object invoke( Object proxy, Method method, Object[] args ) throws Throwable
            {
                adversary.injectFailure( (Class<? extends Throwable>[]) method.getExceptionTypes() );
                return method.invoke( fileSystem, args );
            }
        };
        ClassLoader loader = Thread.currentThread().getContextClassLoader();
        return (ThirdPartyFileSystem) Proxy.newProxyInstance( loader, new Class[] { clazz }, handler );
    }
}


File: community/io/src/test/java/org/neo4j/graphdb/mockfs/DelegatingFileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.graphdb.mockfs;

import java.io.File;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.Reader;
import java.io.Writer;

import org.neo4j.function.Function;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;

public class DelegatingFileSystemAbstraction implements FileSystemAbstraction
{
    private final FileSystemAbstraction delegate;

    public DelegatingFileSystemAbstraction( FileSystemAbstraction delegate )
    {
        this.delegate = delegate;
    }

    @Override
    public StoreChannel open( File fileName, String mode ) throws IOException
    {
        return delegate.open( fileName, mode );
    }

    @Override
    public void moveToDirectory( File file, File toDirectory ) throws IOException
    {
        delegate.moveToDirectory( file, toDirectory );
    }

    @Override
    public boolean mkdir( File fileName )
    {
        return delegate.mkdir( fileName );
    }

    @Override
    public void copyFile( File from, File to ) throws IOException
    {
        delegate.copyFile( from, to );
    }

    @Override
    public <K extends FileSystemAbstraction.ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem( Class<K> clazz,
                                                                                                     Function<Class<K>, K> creator )
    {
        return delegate.getOrCreateThirdPartyFileSystem( clazz, creator );
    }

    @Override
    public boolean renameFile( File from, File to ) throws IOException
    {
        return delegate.renameFile( from, to );
    }

    @Override
    public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
    {
        return delegate.tryLock( fileName, channel );
    }

    @Override
    public StoreChannel create( File fileName ) throws IOException
    {
        return delegate.create( fileName );
    }

    @Override
    public void mkdirs( File fileName ) throws IOException
    {
        delegate.mkdirs( fileName );
    }

    @Override
    public boolean deleteFile( File fileName )
    {
        return delegate.deleteFile( fileName );
    }

    @Override
    public InputStream openAsInputStream( File fileName ) throws IOException
    {
        return delegate.openAsInputStream( fileName );
    }

    @Override
    public boolean fileExists( File fileName )
    {
        return delegate.fileExists( fileName );
    }

    @Override
    public File[] listFiles( File directory, FilenameFilter filter )
    {
        return delegate.listFiles( directory, filter );
    }

    @Override
    public boolean isDirectory( File file )
    {
        return delegate.isDirectory( file );
    }

    @Override
    public long getFileSize( File fileName )
    {
        return delegate.getFileSize( fileName );
    }

    @Override
    public Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException
    {
        return delegate.openAsWriter( fileName, encoding, append );
    }

    @Override
    public File[] listFiles( File directory )
    {
        return delegate.listFiles( directory );
    }

    @Override
    public void deleteRecursively( File directory ) throws IOException
    {
        delegate.deleteRecursively( directory );
    }

    @Override
    public OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException
    {
        return delegate.openAsOutputStream( fileName, append );
    }

    @Override
    public Reader openAsReader( File fileName, String encoding ) throws IOException
    {
        return delegate.openAsReader( fileName, encoding );
    }

    @Override
    public void copyRecursively( File fromDirectory, File toDirectory ) throws IOException
    {
        delegate.copyRecursively( fromDirectory, toDirectory );
    }
}


File: community/io/src/test/java/org/neo4j/graphdb/mockfs/EphemeralFileSystemAbstraction.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.graphdb.mockfs;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FilenameFilter;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.OutputStream;
import java.io.OutputStreamWriter;
import java.io.Reader;
import java.io.Writer;
import java.lang.ref.WeakReference;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.ClosedByInterruptException;
import java.nio.channels.ClosedChannelException;
import java.nio.channels.FileChannel;
import java.nio.channels.ReadableByteChannel;
import java.nio.channels.WritableByteChannel;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.NoSuchElementException;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;
import java.util.zip.CRC32;
import java.util.zip.Checksum;
import java.util.zip.ZipEntry;
import java.util.zip.ZipOutputStream;

import org.neo4j.function.Function;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.io.fs.StoreFileChannel;
import org.neo4j.test.impl.ChannelInputStream;
import org.neo4j.test.impl.ChannelOutputStream;

import static java.lang.Math.max;
import static java.lang.Math.min;
import static java.util.Arrays.asList;

public class EphemeralFileSystemAbstraction implements FileSystemAbstraction
{
    interface Positionable
    {
        long pos();

        void pos( long position );
    }

    private final Set<File> directories = Collections.newSetFromMap( new ConcurrentHashMap<File,Boolean>() );
    private final Map<File,EphemeralFileData> files;
    private final Map<Class<? extends ThirdPartyFileSystem>,ThirdPartyFileSystem> thirdPartyFileSystems =
            new HashMap<>();

    public EphemeralFileSystemAbstraction()
    {
        this.files = new ConcurrentHashMap<>();
    }

    private EphemeralFileSystemAbstraction( Set<File> directories, Map<File,EphemeralFileData> files )
    {
        this.files = new ConcurrentHashMap<>( files );
        this.directories.addAll( directories );
    }

    public synchronized void shutdown()
    {
        for ( EphemeralFileData file : files.values() )
        {
            free( file );
        }

        files.clear();

        for ( ThirdPartyFileSystem thirdPartyFileSystem : thirdPartyFileSystems.values() )
        {
            thirdPartyFileSystem.close();
        }
        thirdPartyFileSystems.clear();
    }

    @Override
    protected void finalize() throws Throwable
    {
        shutdown();
        super.finalize();
    }

    public void assertNoOpenFiles() throws Exception
    {
        FileStillOpenException exception = null;
        for ( EphemeralFileData file : files.values() )
        {
            Iterator<EphemeralFileChannel> channels = file.getOpenChannels();
            while ( channels.hasNext() )
            {
                EphemeralFileChannel channel = channels.next();
                if ( exception == null )
                {
                    exception = channel.openedAt;
                }
                else
                {
                    exception.addSuppressed( channel.openedAt );
                }
            }
        }
        if ( exception != null )
        {
            throw exception;
        }
    }

    public void dumpZip( OutputStream output ) throws IOException
    {
        try ( ZipOutputStream zip = new ZipOutputStream( output ) )
        {
            String prefix = null;
            for ( Map.Entry<File,EphemeralFileData> entry : files.entrySet() )
            {
                File file = entry.getKey();
                String parent = file.getParentFile().getAbsolutePath();
                if ( prefix == null || prefix.startsWith( parent ) )
                {
                    prefix = parent;
                }
                zip.putNextEntry( new ZipEntry( file.getAbsolutePath() ) );
                entry.getValue().dumpTo( zip );
                zip.closeEntry();
            }
            for ( ThirdPartyFileSystem fs : thirdPartyFileSystems.values() )
            {
                fs.dumpToZip( zip, EphemeralFileData.SCRATCH_PAD.get() );
            }
            if ( prefix != null )
            {
                File directory = new File( prefix );
                if ( directory.exists() ) // things ended up on the file system...
                {
                    addRecursively( zip, directory );
                }
            }
        }
    }

    private void addRecursively( ZipOutputStream output, File input ) throws IOException
    {
        if ( input.isFile() )
        {
            output.putNextEntry( new ZipEntry( input.getAbsolutePath() ) );
            byte[] scratchPad = EphemeralFileData.SCRATCH_PAD.get();
            try ( FileInputStream source = new FileInputStream( input ) )
            {
                for ( int read; 0 <= (read = source.read( scratchPad )); )
                {
                    output.write( scratchPad, 0, read );
                }
            }
            output.closeEntry();
        }
        else
        {
            File[] children = input.listFiles();
            if ( children != null )
            {
                for ( File child : children )
                {
                    addRecursively( output, child );
                }
            }
        }
    }

    private void free( EphemeralFileData file )
    {
        if ( file != null )
        {
            file.fileAsBuffer.free();
        }
    }

    @Override
    public synchronized StoreChannel open( File fileName, String mode ) throws IOException
    {
        EphemeralFileData data = files.get( fileName );
        if ( data != null )
        {
            return new StoreFileChannel( new EphemeralFileChannel(
                    data, new FileStillOpenException( fileName.getPath() ) ) );
        }
        return create( fileName );
    }

    @Override
    public OutputStream openAsOutputStream( File fileName, boolean append ) throws IOException
    {
        return new ChannelOutputStream( open( fileName, "rw" ), append );
    }

    @Override
    public InputStream openAsInputStream( File fileName ) throws IOException
    {
        return new ChannelInputStream( open( fileName, "r" ) );
    }

    @Override
    public Reader openAsReader( File fileName, String encoding ) throws IOException
    {
        return new InputStreamReader( openAsInputStream( fileName ), encoding );
    }

    @Override
    public Writer openAsWriter( File fileName, String encoding, boolean append ) throws IOException
    {
        return new OutputStreamWriter( openAsOutputStream( fileName, append ), encoding );
    }

    @Override
    public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
    {
        final java.nio.channels.FileLock lock = channel.tryLock();
        return new FileLock()
        {
            @Override
            public void release() throws IOException
            {
                lock.release();
            }
        };
    }

    @Override
    public synchronized StoreChannel create( File fileName ) throws IOException
    {
        File parentFile = fileName.getParentFile();
        if ( parentFile != null /*means that this is the 'default location'*/ && !fileExists( parentFile ) )
        {
            throw new FileNotFoundException( "'" + fileName
                                             + "' (The system cannot find the path specified)" );
        }

        EphemeralFileData data = new EphemeralFileData();
        free( files.put( fileName, data ) );
        return new StoreFileChannel(
                new EphemeralFileChannel( data, new FileStillOpenException( fileName.getPath() ) ) );
    }

    @Override
    public long getFileSize( File fileName )
    {
        EphemeralFileData file = files.get( fileName );
        return file == null ? 0 : file.size();
    }

    @Override
    public boolean fileExists( File file )
    {
        return directories.contains( file.getAbsoluteFile() ) || files.containsKey( file );
    }

    @Override
    public boolean isDirectory( File file )
    {
        return directories.contains( file.getAbsoluteFile() );
    }

    @Override
    public boolean mkdir( File directory )
    {
        if ( fileExists( directory ) )
        {
            return false;
        }

        directories.add( directory.getAbsoluteFile() );
        return true;
    }

    @Override
    public void mkdirs( File directory )
    {
        File currentDirectory = directory.getAbsoluteFile();

        while ( currentDirectory != null )
        {
            mkdir( currentDirectory );
            currentDirectory = currentDirectory.getParentFile();
        }
    }

    @Override
    public boolean deleteFile( File fileName )
    {
        EphemeralFileData removed = files.remove( fileName );
        free( removed );
        return removed != null;
    }

    @Override
    public void deleteRecursively( File directory ) throws IOException
    {
        List<String> directoryPathItems = splitPath( directory );
        for ( Map.Entry<File,EphemeralFileData> file : files.entrySet() )
        {
            File fileName = file.getKey();
            List<String> fileNamePathItems = splitPath( fileName );
            if ( directoryMatches( directoryPathItems, fileNamePathItems ) )
            {
                deleteFile( fileName );
            }
        }
    }

    @Override
    public boolean renameFile( File from, File to ) throws IOException
    {
        if ( !files.containsKey( from ) )
        {
            throw new IOException( "'" + from + "' doesn't exist" );
        }
        if ( files.containsKey( to ) )
        {
            throw new IOException( "'" + to + "' already exists" );
        }
        files.put( to, files.remove( from ) );
        return true;
    }

    @Override
    public File[] listFiles( File directory )
    {
        if ( files.containsKey( directory ) )
        {
            // This means that you're trying to list files on a file, not a directory.
            return null;
        }

        List<String> directoryPathItems = splitPath( directory );
        Set<File> found = new HashSet<>();
        Iterator<File> files = new CombiningIterator<>( asList( this.files.keySet().iterator(), directories.iterator() ) );
        while ( files.hasNext() )
        {
            File file = files.next();
            List<String> fileNamePathItems = splitPath( file );
            if ( directoryMatches( directoryPathItems, fileNamePathItems ) )
            {
                found.add( constructPath( fileNamePathItems, directoryPathItems.size() + 1 ) );
            }
        }

        return found.toArray( new File[found.size()] );
    }

    @Override
    public File[] listFiles( File directory, FilenameFilter filter )
    {
        if ( files.containsKey( directory ) )
        // This means that you're trying to list files on a file, not a directory.
        {
            return null;
        }

        List<String> directoryPathItems = splitPath( directory );
        Set<File> found = new HashSet<>();
        Iterator<File> files = new CombiningIterator<>( asList( this.files.keySet().iterator(), directories.iterator() ) );
        while ( files.hasNext() )
        {
            File file = files.next();
            List<String> fileNamePathItems = splitPath( file );
            if ( directoryMatches( directoryPathItems, fileNamePathItems ) )
            {
                File path = constructPath( fileNamePathItems, directoryPathItems.size() + 1 );
                if ( filter.accept( path.getParentFile(), path.getName() ) )
                {
                    found.add( path );
                }
            }
        }
        return found.toArray( new File[found.size()] );
    }

    private File constructPath( List<String> pathItems, int count )
    {
        File file = null;
        for ( String pathItem : pathItems.subList( 0, count ) )
        {
            file = file == null ? new File( pathItem ) : new File( file, pathItem );
        }
        return file;
    }

    private boolean directoryMatches( List<String> directoryPathItems, List<String> fileNamePathItems )
    {
        return fileNamePathItems.size() > directoryPathItems.size() &&
               fileNamePathItems.subList( 0, directoryPathItems.size() ).equals( directoryPathItems );
    }

    private List<String> splitPath( File path )
    {
        return asList( path.getPath().replaceAll( "\\\\", "/" ).split( "/" ) );
    }

    @Override
    public void moveToDirectory( File file, File toDirectory ) throws IOException
    {
        EphemeralFileData fileToMove = files.remove( file );
        if ( fileToMove == null )
        {
            throw new FileNotFoundException( file.getPath() );
        }
        files.put( new File( toDirectory, file.getName() ), fileToMove );
    }

    @Override
    public void copyFile( File from, File to ) throws IOException
    {
        EphemeralFileData data = files.get( from );
        if ( data == null )
        {
            throw new FileNotFoundException( "File " + from + " not found" );
        }
        copyFile( from, this, to, newCopyBuffer() );
    }

    @Override
    public void copyRecursively( File fromDirectory, File toDirectory ) throws IOException
    {
        copyRecursivelyFromOtherFs( fromDirectory, this, toDirectory, newCopyBuffer() );
    }

    public EphemeralFileSystemAbstraction snapshot()
    {
        Map<File,EphemeralFileData> copiedFiles = new HashMap<>();
        for ( Map.Entry<File,EphemeralFileData> file : files.entrySet() )
        {
            copiedFiles.put( file.getKey(), file.getValue().copy() );
        }
        return new EphemeralFileSystemAbstraction( directories, copiedFiles );
    }

    public void copyRecursivelyFromOtherFs( File from, FileSystemAbstraction fromFs, File to ) throws IOException
    {
        copyRecursivelyFromOtherFs( from, fromFs, to, newCopyBuffer() );
    }

    public long checksum()
    {
        Checksum checksum = new CRC32();
        byte[] data = new byte[4096];

        // Go through file name list in sorted order, so that checksum is consistent
        List<File> names = new ArrayList<>( files.size() );
        names.addAll( files.keySet() );

        Collections.sort( names, new Comparator<File>()
        {
            @Override
            public int compare( File o1, File o2 )
            {
                return o1.getAbsolutePath().compareTo( o2.getAbsolutePath() );
            }
        } );

        for ( File name : names )
        {
            EphemeralFileData file = files.get( name );
            ByteBuffer buf = file.fileAsBuffer.buf;
            buf.position( 0 );
            while ( buf.position() < buf.limit() )
            {
                int len = Math.min( data.length, buf.limit() - buf.position() );
                buf.get( data );
                checksum.update( data, 0, len );
            }
        }
        return checksum.getValue();
    }

    private ByteBuffer newCopyBuffer()
    {
        return ByteBuffer.allocate( 1024 * 1024 );
    }

    private void copyRecursivelyFromOtherFs( File from, FileSystemAbstraction fromFs, File to, ByteBuffer buffer )
            throws IOException
    {
        this.mkdirs( to );
        for ( File fromFile : fromFs.listFiles( from ) )
        {
            File toFile = new File( to, fromFile.getName() );
            if ( fromFs.isDirectory( fromFile ) )
            {
                copyRecursivelyFromOtherFs( fromFile, fromFs, toFile );
            }
            else
            {
                copyFile( fromFile, fromFs, toFile, buffer );
            }
        }
    }

    private void copyFile( File from, FileSystemAbstraction fromFs, File to, ByteBuffer buffer ) throws IOException
    {
        StoreChannel source = fromFs.open( from, "r" );
        StoreChannel sink = this.open( to, "rw" );
        try
        {
            for ( int available; (available = (int) (source.size() - source.position())) > 0; )
            {
                buffer.clear();
                buffer.limit( min( available, buffer.capacity() ) );
                source.read( buffer );
                buffer.flip();
                sink.write( buffer );
            }
        }
        finally
        {
            if ( source != null )
            {
                source.close();
            }
            if ( sink != null )
            {
                sink.close();
            }
        }
    }

    @Override
    public synchronized <K extends ThirdPartyFileSystem> K getOrCreateThirdPartyFileSystem(
            Class<K> clazz, Function<Class<K>,K> creator )
    {
        ThirdPartyFileSystem fileSystem = thirdPartyFileSystems.get( clazz );
        if ( fileSystem == null )
        {
            thirdPartyFileSystems.put( clazz, fileSystem = creator.apply( clazz ) );
        }
        return clazz.cast( fileSystem );
    }

    @SuppressWarnings( "serial" )
    private static class FileStillOpenException extends Exception
    {
        private final String filename;

        FileStillOpenException( String filename )
        {
            super( "File still open: [" + filename + "]" );
            this.filename = filename;
        }
    }

    static class LocalPosition implements Positionable
    {
        private long position;

        public LocalPosition( long position )
        {
            this.position = position;
        }

        @Override
        public long pos()
        {
            return position;
        }

        @Override
        public void pos( long position )
        {
            this.position = position;
        }
    }

    private static class EphemeralFileChannel extends FileChannel implements Positionable
    {
        final FileStillOpenException openedAt;
        private final EphemeralFileData data;
        private long position = 0;

        EphemeralFileChannel( EphemeralFileData data, FileStillOpenException opened )
        {
            this.data = data;
            this.openedAt = opened;
            data.open( this );
        }

        @Override
        public String toString()
        {
            return String.format( "%s[%s]", getClass().getSimpleName(), openedAt.filename );
        }

        private void checkIfClosedOrInterrupted() throws IOException
        {
            if ( !isOpen() )
            {
                throw new ClosedChannelException();
            }

            if ( Thread.currentThread().isInterrupted() )
            {
                close();
                throw new ClosedByInterruptException();
            }
        }

        @Override
        public int read( ByteBuffer dst ) throws IOException
        {
            checkIfClosedOrInterrupted();
            return data.read( this, dst );
        }

        @Override
        public long read( ByteBuffer[] dsts, int offset, int length ) throws IOException
        {
            checkIfClosedOrInterrupted();
            throw new UnsupportedOperationException();
        }

        @Override
        public int write( ByteBuffer src ) throws IOException
        {
            checkIfClosedOrInterrupted();
            return data.write( this, src );
        }

        @Override
        public long write( ByteBuffer[] srcs, int offset, int length ) throws IOException
        {
            checkIfClosedOrInterrupted();
            throw new UnsupportedOperationException();
        }

        @Override
        public long position() throws IOException
        {
            checkIfClosedOrInterrupted();
            return position;
        }

        @Override
        public FileChannel position( long newPosition ) throws IOException
        {
            checkIfClosedOrInterrupted();
            this.position = newPosition;
            return this;
        }

        @Override
        public long size() throws IOException
        {
            checkIfClosedOrInterrupted();
            return data.size();
        }

        @Override
        public FileChannel truncate( long size ) throws IOException
        {
            checkIfClosedOrInterrupted();
            data.truncate( size );
            return this;
        }

        @Override
        public void force( boolean metaData ) throws IOException
        {
            checkIfClosedOrInterrupted();
            // Otherwise no forcing of an in-memory file
        }

        @Override
        public long transferTo( long position, long count, WritableByteChannel target ) throws IOException
        {
            throw new UnsupportedOperationException();
        }

        @Override
        public long transferFrom( ReadableByteChannel src, long position, long count ) throws IOException
        {
            checkIfClosedOrInterrupted();
            long previousPos = position();
            position( position );
            try
            {
                long transferred = 0;
                ByteBuffer intermediary = ByteBuffer.allocateDirect( 8096 );
                while ( transferred < count )
                {
                    intermediary.clear();
                    intermediary.limit( (int) min( intermediary.capacity(), count - transferred ) );
                    int read = src.read( intermediary );
                    if ( read == -1 )
                    {
                        break;
                    }
                    transferred += read;
                    intermediary.flip();
                }
                return transferred;
            }
            finally
            {
                position( previousPos );
            }
        }

        @Override
        public int read( ByteBuffer dst, long position ) throws IOException
        {
            checkIfClosedOrInterrupted();
            return data.read( new LocalPosition( position ), dst );
        }

        @Override
        public int write( ByteBuffer src, long position ) throws IOException
        {
            checkIfClosedOrInterrupted();
            return data.write( new LocalPosition( position ), src );
        }

        @Override
        public MappedByteBuffer map( FileChannel.MapMode mode, long position, long size ) throws IOException
        {
            checkIfClosedOrInterrupted();
            throw new IOException( "Not supported" );
        }

        @Override
        public java.nio.channels.FileLock lock( long position, long size, boolean shared ) throws IOException
        {
            checkIfClosedOrInterrupted();
            synchronized ( data.channels )
            {
                if ( !data.lock() )
                {
                    return null;
                }
                return new EphemeralFileLock( this, data );
            }
        }

        @Override
        public java.nio.channels.FileLock tryLock( long position, long size, boolean shared ) throws IOException
        {
            synchronized ( data.channels )
            {
                if ( !data.lock() )
                {
                    throw new IOException( "Locked" );
                }
                return new EphemeralFileLock( this, data );
            }
        }

        @Override
        protected void implCloseChannel() throws IOException
        {
            data.close( this );
        }

        @Override
        public long pos()
        {
            return position;
        }

        @Override
        public void pos( long position )
        {
            this.position = position;
        }
    }

    private static class EphemeralFileData
    {
        private static final ThreadLocal<byte[]> SCRATCH_PAD = new ThreadLocal<byte[]>()
        {
            @Override
            protected byte[] initialValue()
            {
                return new byte[1024];
            }
        };
        private final DynamicByteBuffer fileAsBuffer;
        private final Collection<WeakReference<EphemeralFileChannel>> channels = new LinkedList<>();
        private int size;
        private int locked;

        public EphemeralFileData()
        {
            this( new DynamicByteBuffer() );
        }

        private EphemeralFileData( DynamicByteBuffer data )
        {
            this.fileAsBuffer = data;
        }

        int read( Positionable fc, ByteBuffer dst )
        {
            int wanted = dst.limit() - dst.position();
            int available = min( wanted, (int) (size() - fc.pos()) );
            if ( available == 0 )
            {
                return -1; // EOF
            }
            int pending = available;
            // Read up until our internal size
            byte[] scratchPad = SCRATCH_PAD.get();
            while ( pending > 0 )
            {
                int howMuchToReadThisTime = min( pending, scratchPad.length );
                long pos = fc.pos();
                fileAsBuffer.get( (int) pos, scratchPad, 0, howMuchToReadThisTime );
                fc.pos( pos + howMuchToReadThisTime );
                dst.put( scratchPad, 0, howMuchToReadThisTime );
                pending -= howMuchToReadThisTime;
            }
            return available; // return how much data was read
        }

        int write( Positionable fc, ByteBuffer src )
        {
            int wanted = src.limit();
            int pending = wanted;
            byte[] scratchPad = SCRATCH_PAD.get();

            synchronized ( fileAsBuffer )
            {
                while ( pending > 0 )
                {
                    int howMuchToWriteThisTime = min( pending, scratchPad.length );
                    src.get( scratchPad, 0, howMuchToWriteThisTime );
                    long pos = fc.pos();
                    fileAsBuffer.put( (int) pos, scratchPad, 0, howMuchToWriteThisTime );
                    fc.pos( pos + howMuchToWriteThisTime );
                    pending -= howMuchToWriteThisTime;
                }

                // If we just made a jump in the file fill the rest of the gap with zeros
                int newSize = max( size, (int) fc.pos() );
                int intermediaryBytes = newSize - wanted - size;
                if ( intermediaryBytes > 0 )
                {
                    fileAsBuffer.fillWithZeros( size, intermediaryBytes );
                }

                size = newSize;
            }
            return wanted;
        }

        EphemeralFileData copy()
        {
            synchronized ( fileAsBuffer )
            {
                EphemeralFileData copy = new EphemeralFileData( fileAsBuffer.copy() );
                copy.size = size;
                return copy;
            }
        }

        void open( EphemeralFileChannel channel )
        {
            synchronized ( channels )
            {
                channels.add( new WeakReference<>( channel ) );
            }
        }

        void close( EphemeralFileChannel channel )
        {
            synchronized ( channels )
            {
                locked = 0; // Regular file systems seems to release all file locks when closed...
                for ( Iterator<EphemeralFileChannel> iter = getOpenChannels(); iter.hasNext(); )
                {
                    if ( iter.next() == channel )
                    {
                        iter.remove();
                    }
                }
            }
        }

        Iterator<EphemeralFileChannel> getOpenChannels()
        {
            final Iterator<WeakReference<EphemeralFileChannel>> refs = channels.iterator();

            return new PrefetchingIterator<EphemeralFileChannel>()
                        {
                            @Override
                            protected EphemeralFileChannel fetchNextOrNull()
                            {
                                while ( refs.hasNext() )
                                {
                                    EphemeralFileChannel channel = refs.next().get();
                                    if ( channel != null ) return channel;
                                    refs.remove();
                                }
                                return null;
                            }

                            @Override
                            public void remove()
                            {
                                refs.remove();
                            }
                        };
        }

        long size()
        {
            synchronized ( fileAsBuffer )
            {
                return size;
            }
        }

        void truncate( long newSize )
        {
            synchronized ( fileAsBuffer )
            {
                this.size = (int) newSize;
            }
        }

        boolean lock()
        {
            return locked == 0;
        }

        void dumpTo( OutputStream target ) throws IOException
        {
            byte[] scratchPad = SCRATCH_PAD.get();
            synchronized ( fileAsBuffer )
            {
                fileAsBuffer.dump( target, scratchPad, size );
            }
        }

        @Override
        public String toString()
        {
            return "size: " + size + ", locked:" + locked;
        }
    }

    private static class EphemeralFileLock extends java.nio.channels.FileLock
    {
        private EphemeralFileData file;

        EphemeralFileLock( EphemeralFileChannel channel, EphemeralFileData file )
        {
            super( channel, 0, Long.MAX_VALUE, false );
            this.file = file;
            file.locked++;
        }

        @Override
        public boolean isValid()
        {
            return file != null;
        }

        @Override
        public void release() throws IOException
        {
            synchronized ( file.channels )
            {
                if ( file == null || file.locked == 0 )
                {
                    return;
                }
                file.locked--;
                file = null;
            }
        }
    }

    /**
     * Dynamically expanding ByteBuffer substitute/wrapper. This will allocate ByteBuffers on the go
     * so that we don't have to allocate too big of a buffer up-front.
     */
    private static class DynamicByteBuffer
    {
        private static final int[] SIZES;
        private static final byte[] zeroBuffer = new byte[1024];
        private ByteBuffer buf;

        public DynamicByteBuffer()
        {
            buf = allocate( 0 );
        }

        /** This is a copying constructor, the input buffer is just read from, never stored in 'this'. */
        private DynamicByteBuffer( ByteBuffer toClone )
        {
            int sizeIndex = sizeIndexFor( toClone.capacity() );
            buf = allocate( sizeIndex );
            copyByteBufferContents( toClone, buf );
        }

        private static int sizeIndexFor( int capacity )
        {
            // Double size each time, but after 1M only increase by 1M at a time, until required amount is reached.
            int sizeIndex = capacity / SIZES[SIZES.length - 1];
            if ( sizeIndex == 0 )
            {
                for (; sizeIndex < SIZES.length; sizeIndex++ )
                {
                    if ( capacity == SIZES[sizeIndex] )
                    {
                        break;
                    }
                }
            }
            else
            {
                sizeIndex += SIZES.length - 1;
            }
            return sizeIndex;
        }

        synchronized DynamicByteBuffer copy()
        {
            return new DynamicByteBuffer( buf ); // invoke "copy constructor"
        }

        static
        {
            int K = 1024;
            SIZES = new int[]{64 * K, 128 * K, 256 * K, 512 * K, 1024 * K};
        }

        private void copyByteBufferContents( ByteBuffer from, ByteBuffer to )
        {
            int positionBefore = from.position();
            try
            {
                from.position( 0 );
                to.put( from );
            }
            finally
            {
                from.position( positionBefore );
                to.position( 0 );
            }
        }

        /**
         * Tries to allocate a buffer of at least the specified size.
         * If no free buffers are available of the available capacity, we
         * check for buffers up to two sizes larger. If still no buffers
         * are found we allocate a new buffer of the specified size.
         */
        private ByteBuffer allocate( int sizeIndex )
        {
            int capacity = (sizeIndex < SIZES.length) ?
                           SIZES[sizeIndex] : ((sizeIndex - SIZES.length + 1) * SIZES[SIZES.length - 1]);
            try
            {
                return ByteBuffer.allocateDirect( capacity );
            }
            catch ( OutOfMemoryError oom )
            {
                try
                {
                    return ByteBuffer.allocate( capacity );
                }
                catch ( OutOfMemoryError secondOom )
                {
                    oom.addSuppressed( secondOom );
                    throw oom;
                }
            }
        }

        void free()
        {
            try
            {
                clear();
            }
            finally
            {
                buf = null;
            }
        }

        synchronized void put( int pos, byte[] bytes, int offset, int length )
        {
            verifySize( pos + length );
            try
            {
                buf.position( pos );
            }
            catch ( IllegalArgumentException e )
            {
                throw new IllegalArgumentException( buf + ", " + pos, e );
            }
            buf.put( bytes, offset, length );
        }

        synchronized void get( int pos, byte[] scratchPad, int i, int howMuchToReadThisTime )
        {
            buf.position( pos );
            buf.get( scratchPad, i, howMuchToReadThisTime );
        }

        synchronized void fillWithZeros( int pos, int bytes )
        {
            buf.position( pos );
            while ( bytes > 0 )
            {
                int howMuchToReadThisTime = min( bytes, zeroBuffer.length );
                buf.put( zeroBuffer, 0, howMuchToReadThisTime );
                bytes -= howMuchToReadThisTime;
            }
            buf.position( pos );
        }

        /**
         * Checks if more space needs to be allocated.
         */
        private void verifySize( int totalAmount )
        {
            if ( buf.capacity() >= totalAmount )
            {
                return;
            }

            // Double size each time, but after 1M only increase by 1M at a time, until required amount is reached.
            int newSize = buf.capacity();
            int sizeIndex = sizeIndexFor( newSize );
            while ( newSize < totalAmount )
            {
                newSize += Math.min( newSize, 1024 * 1024 );
                sizeIndex++;
            }
            int oldPosition = this.buf.position();
            ByteBuffer buf = allocate( sizeIndex );
            this.buf.position( 0 );
            buf.put( this.buf );
            this.buf = buf;
            this.buf.position( oldPosition );
        }

        public void clear()
        {
            this.buf.clear();
        }

        void dump( OutputStream target, byte[] scratchPad, int size ) throws IOException
        {
            buf.position( 0 );
            while ( size > 0 )
            {
                int read = min( size, scratchPad.length );
                buf.get( scratchPad, 0, read );
                size -= read;
                target.write( scratchPad, 0, read );
            }
        }
    }

    // Copied from kernel since we don't want to depend on that module here
    private static abstract class PrefetchingIterator<T> implements Iterator<T>
    {
        boolean hasFetchedNext;
        T nextObject;

    	/**
    	 * @return {@code true} if there is a next item to be returned from the next
    	 * call to {@link #next()}.
    	 */
    	@Override
        public boolean hasNext()
    	{
    		return peek() != null;
    	}

        /**
         * @return the next element that will be returned from {@link #next()} without
         * actually advancing the iterator
         */
        public T peek()
        {
            if ( hasFetchedNext )
            {
                return nextObject;
            }

            nextObject = fetchNextOrNull();
            hasFetchedNext = true;
            return nextObject;
        }

        /**
    	 * Uses {@link #hasNext()} to try to fetch the next item and returns it
    	 * if found, otherwise it throws a {@link java.util.NoSuchElementException}.
    	 *
    	 * @return the next item in the iteration, or throws
    	 * {@link java.util.NoSuchElementException} if there's no more items to return.
    	 */
    	@Override
        public T next()
    	{
    		if ( !hasNext() )
    		{
    			throw new NoSuchElementException();
    		}
    		T result = nextObject;
    		nextObject = null;
    		hasFetchedNext = false;
    		return result;
    	}

    	protected abstract T fetchNextOrNull();

    	@Override
        public void remove()
    	{
    		throw new UnsupportedOperationException();
    	}
    }

    private static class CombiningIterator<T> extends PrefetchingIterator<T>
    {
        private Iterator<? extends Iterator<T>> iterators;
        private Iterator<T> currentIterator;

        public CombiningIterator( Iterable<? extends Iterator<T>> iterators )
        {
            this( iterators.iterator() );
        }

        public CombiningIterator( Iterator<? extends Iterator<T>> iterators )
        {
            this.iterators = iterators;
        }

        @Override
        protected T fetchNextOrNull()
        {
            if ( currentIterator == null || !currentIterator.hasNext() )
            {
                while ( (currentIterator = nextIteratorOrNull()) != null )
                {
                    if ( currentIterator.hasNext() )
                    {
                        break;
                    }
                }
            }
            return currentIterator != null && currentIterator.hasNext() ? currentIterator.next() : null;
        }

        protected Iterator<T> nextIteratorOrNull()
        {
            if(iterators.hasNext())
            {
                return iterators.next();
            }
            return null;
        }
    }
}


File: community/io/src/test/java/org/neo4j/io/fs/FileSystemAbstractionInterruptionTest.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.fs;

import org.junit.After;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.ClosedByInterruptException;
import java.nio.channels.ClosedChannelException;
import java.util.Arrays;

import org.neo4j.function.Factory;
import org.neo4j.graphdb.mockfs.EphemeralFileSystemAbstraction;
import org.neo4j.test.TargetDirectory;

import static org.hamcrest.Matchers.is;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

@RunWith( Parameterized.class )
public class FileSystemAbstractionInterruptionTest
{
    private static final Factory<FileSystemAbstraction> ephemeral = new Factory<FileSystemAbstraction>()
    {
        @Override
        public FileSystemAbstraction newInstance()
        {
            return new EphemeralFileSystemAbstraction();
        }
    };

    private static final Factory<FileSystemAbstraction> real = new Factory<FileSystemAbstraction>()
    {
        @Override
        public FileSystemAbstraction newInstance()
        {
            return new DefaultFileSystemAbstraction();
        }
    };

    @Parameterized.Parameters(name = "{0}")
    public static Iterable<Object[]> dataPoints()
    {
        return Arrays.asList(new Object[][]{
                { "ephemeral", ephemeral },
                { "real", real }
        });
    }

    @Rule
    public final TargetDirectory.TestDirectory testdir =
            TargetDirectory.testDirForTest( FileSystemAbstractionInterruptionTest.class );

    private FileSystemAbstraction fs;
    private File file;

    public FileSystemAbstractionInterruptionTest( String name, Factory<FileSystemAbstraction> factory )
    {
        fs = factory.newInstance();
    }

    @Before
    public void interruptPriorToCall()
    {
        Thread.currentThread().interrupt();
    }

    @Before
    public void createWorkingDirectoryAndTestFile() throws IOException
    {
        fs.mkdirs( testdir.directory() );
        file = testdir.file( "a" );
        fs.create( file ).close();
        channel = null;
        channelShouldBeClosed = false;
    }

    private StoreChannel channel;
    private boolean channelShouldBeClosed;

    @After
    public void verifyInterruptionAndChannelState() throws IOException
    {
        assertTrue( Thread.interrupted() );
        assertThat( "channelShouldBeClosed? " + channelShouldBeClosed,
                channel.isOpen(),
                is( !channelShouldBeClosed ) );

        if ( channelShouldBeClosed )
        {
            try
            {
                channel.force( true );
                fail( "Operating on a closed channel should fail" );
            }
            catch ( ClosedChannelException expected )
            {
                // This is good. What we expect to see.
            }
        }
    }

    private StoreChannel chan( boolean channelShouldBeClosed ) throws IOException
    {
        this.channelShouldBeClosed = channelShouldBeClosed;
        channel = fs.open( file, "rw" );
        return channel;
    }

    @Test
    public void fs_openClose() throws IOException
    {
        chan( true ).close();
    }

    @Test
    public void fs_tryLock() throws IOException
    {
        fs.tryLock( file, chan( false ) ).release();
    }

    @Test
    public void ch_tryLock() throws IOException
    {
        chan( false ).tryLock().release();
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_setPosition() throws IOException
    {
        chan( true ).position( 0 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_getPosition() throws IOException
    {
        chan( true ).position();
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_truncate() throws IOException
    {
        chan( true ).truncate( 0 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_force() throws IOException
    {
        chan( true ).force( true );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_writeAll_ByteBuffer() throws IOException
    {
        chan( true ).writeAll( ByteBuffer.allocate( 1 ) );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_writeAll_ByteBuffer_position() throws IOException
    {
        chan( true ).writeAll( ByteBuffer.allocate( 1 ), 1 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_write_ByteBuffer_position() throws IOException
    {
        chan( true ).write( ByteBuffer.allocate( 1 ), 1 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_read_ByteBuffer() throws IOException
    {
        chan( true ).read( ByteBuffer.allocate( 1 ) );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_write_ByteBuffer() throws IOException
    {
        chan( true ).write( ByteBuffer.allocate( 1 ) );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_size() throws IOException
    {
        chan( true ).size();
    }

    @Test
    public void ch_isOpen() throws IOException
    {
        chan( false ).isOpen();
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_write_ByteBuffers_offset_length() throws IOException
    {
        chan( true ).write( new ByteBuffer[]{ByteBuffer.allocate( 1 )}, 0, 1 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_write_ByteBuffers() throws IOException
    {
        chan( true ).write( new ByteBuffer[]{ByteBuffer.allocate( 1 )} );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_read_ByteBuffers_offset_length() throws IOException
    {
        chan( true ).read( new ByteBuffer[]{ByteBuffer.allocate( 1 )}, 0, 1 );
    }

    @Test(expected = ClosedByInterruptException.class)
    public void ch_read_ByteBuffers() throws IOException
    {
        chan( true ).read( new ByteBuffer[]{ByteBuffer.allocate( 1 )} );
    }
}


File: community/io/src/test/java/org/neo4j/io/pagecache/impl/SingleFilePageSwapperTest.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.io.pagecache.impl;

import org.junit.After;
import org.junit.Test;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.nio.ByteBuffer;

import org.neo4j.graphdb.mockfs.EphemeralFileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.io.pagecache.PageSwapper;
import org.neo4j.io.pagecache.PageSwapperFactory;
import org.neo4j.io.pagecache.PageSwapperTest;

import static org.junit.Assert.assertThat;
import static org.neo4j.test.ByteArrayMatcher.byteArray;

public class SingleFilePageSwapperTest extends PageSwapperTest
{
    private final File file = new File( "file" );
    private EphemeralFileSystemAbstraction fs = new EphemeralFileSystemAbstraction();

    @After
    public void tearDown()
    {
        fs.shutdown();
    }

    protected PageSwapperFactory swapperFactory()
    {
        SingleFilePageSwapperFactory factory = new SingleFilePageSwapperFactory();
        factory.setFileSystemAbstraction( fs );
        return factory;
    }

    @Test
    public void swappingInMustFillPageWithData() throws IOException
    {
        byte[] bytes = new byte[] { 1, 2, 3, 4 };
        StoreChannel channel = fs.create( file );
        channel.writeAll( wrap( bytes ) );
        channel.close();

        PageSwapperFactory factory = swapperFactory();
        PageSwapper swapper = factory.createPageSwapper( file, 4, null, false );
        ByteBuffer target = ByteBuffer.allocateDirect( 4 );
        ByteBufferPage page = new ByteBufferPage( target );
        swapper.read( 0, page );

        assertThat( array( target ), byteArray( bytes ) );
    }

    @Test
    public void mustZeroFillPageBeyondEndOfFile() throws IOException
    {
        byte[] bytes = new byte[] {
                // --- page 0:
                1, 2, 3, 4,
                // --- page 1:
                5, 6
        };
        StoreChannel channel = fs.create( file );
        channel.writeAll( wrap( bytes ) );
        channel.close();

        PageSwapperFactory factory = swapperFactory();
        PageSwapper swapper = factory.createPageSwapper( file, 4, null, false );
        ByteBuffer target = ByteBuffer.allocateDirect( 4 );
        ByteBufferPage page = new ByteBufferPage( target );
        swapper.read( 1, page );

        assertThat( array( target ), byteArray( new byte[]{ 5, 6, 0, 0 } ) );
    }

    @Test
    public void swappingOutMustWritePageToFile() throws IOException
    {
        fs.create( file ).close();

        byte[] expected = new byte[] { 1, 2, 3, 4 };
        ByteBufferPage page = new ByteBufferPage( wrap( expected ) );

        PageSwapperFactory factory = swapperFactory();
        PageSwapper swapper = factory.createPageSwapper( file, 4, null, false );
        swapper.write( 0, page );

        InputStream stream = fs.openAsInputStream( file );
        byte[] actual = new byte[expected.length];
        stream.read( actual );

        assertThat( actual, byteArray( expected ) );
    }

    @Test
    public void swappingOutMustNotOverwriteDataBeyondPage() throws IOException
    {
        byte[] initialData = new byte[] {
                // --- page 0:
                1, 2, 3, 4,
                // --- page 1:
                5, 6, 7, 8,
                // --- page 2:
                9, 10
        };
        byte[] finalData = new byte[] {
                // --- page 0:
                1, 2, 3, 4,
                // --- page 1:
                8, 7, 6, 5,
                // --- page 2:
                9, 10
        };
        StoreChannel channel = fs.create( file );
        channel.writeAll( wrap( initialData ) );
        channel.close();

        byte[] change = new byte[] { 8, 7, 6, 5 };
        ByteBufferPage page = new ByteBufferPage( wrap( change ) );

        PageSwapperFactory factory = swapperFactory();
        PageSwapper swapper = factory.createPageSwapper( file, 4, null, false );
        swapper.write( 1, page );

        InputStream stream = fs.openAsInputStream( file );
        byte[] actual = new byte[(int) fs.getFileSize( file )];
        stream.read( actual );

        assertThat( actual, byteArray( finalData ) );
    }

    private byte[] array( ByteBuffer target )
    {
        target.clear();
        byte[] array = new byte[target.capacity()];
        while ( target.position() < target.capacity() )
        {
            array[target.position()] = target.get();
        }
        return array;
    }

    private ByteBuffer wrap( byte[] bytes )
    {
        ByteBuffer buffer = ByteBuffer.allocateDirect( bytes.length );
        for ( byte b : bytes )
        {
            buffer.put( b );
        }
        buffer.clear();
        return buffer;
    }
}


File: community/kernel/src/main/java/org/neo4j/kernel/StoreLocker.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel;

import java.io.File;
import java.io.IOException;
import java.nio.channels.OverlappingFileLockException;

import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;

/**
 * @deprecated This will be moved to internal packages in the next major release.
 */
@Deprecated
public class StoreLocker
{
    public static final String STORE_LOCK_FILENAME = FileLock.STORE_LOCK_FILENAME;

    private final FileSystemAbstraction fileSystemAbstraction;

    private FileLock storeLockFileLock;
    private StoreChannel storeLockFileChannel;

    public StoreLocker( FileSystemAbstraction fileSystemAbstraction )
    {
        this.fileSystemAbstraction = fileSystemAbstraction;
    }

    /**
     * Obtains lock on store file so that we can ensure the store is not shared between database instances
     * <p>
     * Creates store dir if necessary, creates store lock file if necessary
     *
     * @throws StoreLockException if lock could not be acquired
     */
    public void checkLock( File storeDir ) throws StoreLockException
    {
        File storeLockFile = new File( storeDir, STORE_LOCK_FILENAME );

        try
        {
            if ( !fileSystemAbstraction.fileExists( storeLockFile ) )
            {
                fileSystemAbstraction.mkdirs( storeLockFile.getParentFile() );
            }
        }
        catch ( IOException e )
        {
            throw new StoreLockException( "Unable to create path for store dir: " + storeDir+". Please ensure no other process is using this database, and that the directory is writable (required even for read-only access)", e );
        }

        try
        {
            storeLockFileChannel = fileSystemAbstraction.open( storeLockFile, "rw" );
            storeLockFileLock = fileSystemAbstraction.tryLock( storeLockFile, storeLockFileChannel );
        }
        catch ( OverlappingFileLockException | IOException e )
        {
            throw new StoreLockException( "Unable to obtain lock on store lock file: " + storeLockFile+". Please ensure no other process is using this database, and that the directory is writable (required even for read-only access)", e );
        }
    }

    public void release() throws IOException
    {
        if ( storeLockFileLock != null )
        {
            storeLockFileLock.release();
            storeLockFileLock = null;
        }
        if ( storeLockFileChannel != null )
        {
            storeLockFileChannel.close();
            storeLockFileChannel = null;
        }
    }
}


File: community/kernel/src/main/java/org/neo4j/kernel/impl/store/CommonAbstractStore.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel.impl.store;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.OverlappingFileLockException;

import org.neo4j.graphdb.config.Setting;
import org.neo4j.graphdb.factory.GraphDatabaseSettings;
import org.neo4j.helpers.collection.Visitor;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.FileUtils.FileOperation;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.io.pagecache.PageCache;
import org.neo4j.io.pagecache.PageCursor;
import org.neo4j.io.pagecache.PagedFile;
import org.neo4j.kernel.IdGeneratorFactory;
import org.neo4j.kernel.IdType;
import org.neo4j.kernel.configuration.Config;
import org.neo4j.kernel.impl.store.id.IdGenerator;
import org.neo4j.kernel.impl.store.id.IdGeneratorImpl;
import org.neo4j.kernel.impl.store.id.IdSequence;
import org.neo4j.kernel.impl.store.record.Record;
import org.neo4j.kernel.impl.storemigration.StoreVersionCheck;
import org.neo4j.logging.Log;
import org.neo4j.logging.LogProvider;
import org.neo4j.logging.Logger;

import static java.nio.ByteBuffer.wrap;
import static org.neo4j.helpers.Exceptions.launderedException;
import static org.neo4j.helpers.UTF8.encode;
import static org.neo4j.io.fs.FileUtils.windowsSafeIOOperation;
import static org.neo4j.io.pagecache.PagedFile.PF_READ_AHEAD;
import static org.neo4j.io.pagecache.PagedFile.PF_SHARED_LOCK;

/**
 * Contains common implementation for {@link AbstractStore} and
 * {@link AbstractDynamicStore}.
 */
public abstract class CommonAbstractStore implements IdSequence, AutoCloseable
{
    public static final String ALL_STORES_VERSION = "v0.A.6";
    public static final String UNKNOWN_VERSION = "Unknown";
    protected final Config configuration;
    protected final PageCache pageCache;
    protected final File storageFileName;
    protected final IdType idType;
    private final IdGeneratorFactory idGeneratorFactory;
    private final StoreVersionMismatchHandler versionMismatchHandler;
    protected FileSystemAbstraction fileSystemAbstraction;
    protected final Log log;
    protected PagedFile storeFile;
    private IdGenerator idGenerator;
    private StoreChannel fileChannel;
    private boolean storeOk = true;
    private Throwable causeOfStoreNotOk;
    private FileLock fileLock;
    private String readTypeDescriptorAndVersion;

    /**
     * Opens and validates the store contained in <CODE>fileName</CODE>
     * loading any configuration defined in <CODE>config</CODE>. After
     * validation the <CODE>initStorage</CODE> method is called.
     * <p>
     * If the store had a clean shutdown it will be marked as <CODE>ok</CODE>
     * and the {@link #getStoreOk()} method will return true.
     * If a problem was found when opening the store the {@link #makeStoreOk()}
     * must be invoked.
     * <p>
     * throws IOException if the unable to open the storage or if the
     * <CODE>initStorage</CODE> method fails
     *
     * @param idType The Id used to index into this store
     */
    public CommonAbstractStore(
            File fileName,
            Config configuration,
            IdType idType,
            IdGeneratorFactory idGeneratorFactory,
            PageCache pageCache,
            FileSystemAbstraction fileSystemAbstraction,
            LogProvider logProvider,
            StoreVersionMismatchHandler versionMismatchHandler )
    {
        this.storageFileName = fileName;
        this.configuration = configuration;
        this.idGeneratorFactory = idGeneratorFactory;
        this.pageCache = pageCache;
        this.fileSystemAbstraction = fileSystemAbstraction;
        this.idType = idType;
        this.log = logProvider.getLog( getClass() );
        this.versionMismatchHandler = versionMismatchHandler;

        try
        {
            checkStorage();
            checkVersion(); // Overriden in NeoStore
            loadStorage();
        }
        catch ( Exception e )
        {
            if ( storeFile != null )
            {
                try
                {
                    storeFile.close();
                }
                catch ( IOException failureToClose )
                {
                    // Not really a suppressed exception, but we still want to throw the real exception, e,
                    // but perhaps also throw this in there or convenience.
                    e.addSuppressed( failureToClose );
                }
            }
            releaseFileLockAndCloseFileChannel();
            throw launderedException( e );
        }
    }

    public static String buildTypeDescriptorAndVersion( String typeDescriptor )
    {
        return buildTypeDescriptorAndVersion( typeDescriptor, ALL_STORES_VERSION );
    }

    public static String buildTypeDescriptorAndVersion( String typeDescriptor, String version )
    {
        return typeDescriptor + " " + version;
    }

    protected static long longFromIntAndMod( long base, long modifier )
    {
        return modifier == 0 && base == IdGeneratorImpl.INTEGER_MINUS_ONE ? -1 : base | modifier;
    }

    public String getTypeAndVersionDescriptor()
    {
        return buildTypeDescriptorAndVersion( getTypeDescriptor() );
    }

    /**
     * Returns the type and version that identifies this store.
     *
     * @return This store's implementation type and version identifier
     */
    public abstract String getTypeDescriptor();

    /**
     * Note: This method runs before the file has been mapped by the page cache, and therefore needs to
     * operate on the store files directly. This method is called by constructors.
     */
    protected void checkStorage()
    {
        if ( !fileSystemAbstraction.fileExists( storageFileName ) )
        {
            throw new StoreNotFoundException( "No such store[" + storageFileName + "] in " + fileSystemAbstraction );
        }
        try
        {
            this.fileChannel = fileSystemAbstraction.open( storageFileName, "rw" );
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Unable to open file " + storageFileName, e );
        }
        try
        {
            this.fileLock = fileSystemAbstraction.tryLock( storageFileName, fileChannel );
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Unable to lock store[" + storageFileName + "]", e );
        }
        catch ( OverlappingFileLockException e )
        {
            throw new IllegalStateException( "Unable to lock store [" + storageFileName +
                                             "], this is usually caused by another Neo4j kernel already running in " +
                                             "this JVM for this particular store" );
        }
    }

    /**
     * Note: This method runs before the file has been mapped by the page cache, and therefore needs to
     * operate on the store files directly. This method is called by constructors.
     */
    protected void checkVersion()
    {
        try
        {
            verifyCorrectTypeDescriptorAndVersion();
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Unable to check version " + getStorageFileName(), e );
        }
    }

    /**
     * Should do first validation on store validating stuff like version and id
     * generator. This method is called by constructors.
     * <p>
     * Note: This method will map the file with the page cache. The store file must not
     * be accessed directly until it has been unmapped - the store file must only be
     * accessed through the page cache.
     */
    protected void loadStorage()
    {
        try
        {
            readAndVerifyBlockSize();
            verifyFileSizeAndTruncate();
            try
            {
                int filePageSize = pageCache.pageSize() - pageCache.pageSize() % getEffectiveRecordSize();
                storeFile = pageCache.map( getStorageFileName(), filePageSize );
            }
            catch ( IOException e )
            {
                // TODO: Just throw IOException, add proper handling further up
                throw new UnderlyingStorageException( e );
            }
            loadIdGenerator();
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Unable to load storage " + getStorageFileName(), e );
        }
    }

    protected long pageIdForRecord( long id )
    {
        return id * getEffectiveRecordSize() / storeFile.pageSize();
    }

    protected int offsetForId( long id )
    {
        return (int) (id * getEffectiveRecordSize() % storeFile.pageSize());
    }

    protected int recordsPerPage()
    {
        return storeFile.pageSize() / getEffectiveRecordSize();
    }

    protected abstract int getEffectiveRecordSize();

    /**
     * Note: This method runs before the file has been mapped by the page cache, and therefore needs to
     * operate on the store files directly. This method is called by constructors.
     */
    protected abstract void verifyFileSizeAndTruncate() throws IOException;

    /**
     * Note: This method runs before the file has been mapped by the page cache, and therefore needs to
     * operate on the store files directly. This method is called by constructors.
     */
    protected abstract void readAndVerifyBlockSize() throws IOException;

    private void loadIdGenerator()
    {
        try
        {
            if ( storeOk )
            {
                openIdGenerator();
            }
            // else we will rebuild the id generator after recovery, and we don't want to have the id generator
            // picking up calls to freeId during recovery.
        }
        catch ( InvalidIdGeneratorException e )
        {
            setStoreNotOk( e );
        }
        finally
        {
            if ( !getStoreOk() )
            {
                log.debug( getStorageFileName() + " non clean shutdown detected" );
            }
        }
    }

    /**
     * Note: This method runs before the file has been mapped by the page cache, and therefore needs to
     * operate on the store files directly. This method is called by constructors.
     */
    protected void verifyCorrectTypeDescriptorAndVersion() throws IOException
    {
        String expectedTypeDescriptorAndVersion = getTypeAndVersionDescriptor();
        try ( PagedFile pagedFile = pageCache.map( storageFileName, pageCache.pageSize() ) )
        {
            readTypeDescriptorAndVersion = StoreVersionCheck.readVersion( pagedFile, expectedTypeDescriptorAndVersion );
        }
        if ( readTypeDescriptorAndVersion == null )
        {
            setStoreNotOk( new IllegalStateException(
                    "No trailer present in store, expected " + expectedTypeDescriptorAndVersion ) );
            return;
        }
        if ( !expectedTypeDescriptorAndVersion.equals( readTypeDescriptorAndVersion ) )
        {
            if ( readTypeDescriptorAndVersion.startsWith( getTypeDescriptor() ) )
            {
                versionMismatchHandler.mismatch( ALL_STORES_VERSION, readTypeDescriptorAndVersion );
            }
            else
            {
                setStoreNotOk( new IllegalStateException(
                        "Unexpected version " + readTypeDescriptorAndVersion + ", expected " +
                        expectedTypeDescriptorAndVersion ) );
            }
        }
    }

    protected abstract boolean isInUse( byte inUseByte );

    /**
     * Should rebuild the id generator from scratch.
     * <p>
     * Note: This method may be called both while the store has the store file mapped in the
     * page cache, and while the store file is not mapped. Implementers must therefore
     * map their own temporary PagedFile for the store file, and do their file IO through that,
     * if they need to access the data in the store file.
     */
    protected void rebuildIdGenerator()
    {
        int blockSize = getEffectiveRecordSize();
        if ( blockSize <= 0 )
        {
            throw new InvalidRecordException( "Illegal blockSize: " + blockSize );
        }

        log.debug( "Rebuilding id generator for[" + getStorageFileName() + "] ..." );
        closeIdGenerator();
        createIdGenerator( getIdFileName() );
        openIdGenerator();

        long defraggedCount = 0;
        boolean fastRebuild = doFastIdGeneratorRebuild();

        try
        {
            long foundHighId = findHighIdBackwards();
            setHighId( foundHighId );
            if ( !fastRebuild )
            {
                try ( PageCursor cursor = storeFile.io( 0, PagedFile.PF_EXCLUSIVE_LOCK | PF_READ_AHEAD ) )
                {
                    defraggedCount = rebuildIdGeneratorSlow( cursor, recordsPerPage(), blockSize,
                            foundHighId );
                }
            }
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException(
                    "Unable to rebuild id generator " + getStorageFileName(), e );
        }

        log.debug( "[" + getStorageFileName() + "] high id=" + getHighId()
                            + " (defragged=" + defraggedCount + ")" );
        log.debug( getStorageFileName() + " rebuild id generator, highId=" + getHighId() +
                                 " defragged count=" + defraggedCount );

        if ( !fastRebuild )
        {
            closeIdGenerator();
            openIdGenerator();
        }
    }

    private long rebuildIdGeneratorSlow( PageCursor cursor, int recordsPerPage, int blockSize,
                                         long foundHighId )
            throws IOException
    {
        long defragCount = 0;
        long[] freedBatch = new long[recordsPerPage]; // we process in batches of one page worth of records
        int startingId = getNumberOfReservedLowIds();
        int defragged;

        boolean done = false;
        while ( !done && cursor.next() )
        {
            long idPageOffset = (cursor.getCurrentPageId() * recordsPerPage);

            do
            {
                defragged = 0;
                done = false;
                for ( int i = startingId; i < recordsPerPage; i++ )
                {
                    int offset = i * blockSize;
                    cursor.setOffset( offset );
                    long recordId = idPageOffset + i;
                    if ( recordId >= foundHighId )
                    {   // We don't have to go further than the high id we found earlier
                        done = true;
                        break;
                    }

                    if ( !isRecordInUse( cursor ) )
                    {
                        freedBatch[defragged++] = recordId;
                    }
                    else if ( isRecordReserved( cursor ) )
                    {
                        cursor.setOffset( offset );
                        cursor.putByte( Record.NOT_IN_USE.byteValue() );
                        cursor.putInt( 0 );
                        freedBatch[defragged++] = recordId;
                    }
                }
            }
            while ( cursor.shouldRetry() );

            for ( int i = 0; i < defragged; i++ )
            {
                freeId( freedBatch[i] );
            }
            defragCount += defragged;
            startingId = 0;
        }
        return defragCount;
    }

    protected boolean doFastIdGeneratorRebuild()
    {
        return configuration.get( Configuration.rebuild_idgenerators_fast );
    }

    /**
     * This method should close/release all resources that the implementation of
     * this store has allocated and is called just before the <CODE>close()</CODE>
     * method returns. Override this method to clean up stuff the constructor.
     * <p>
     * This default implementation does nothing.
     * <p>
     * Note: This method runs before the store file is unmapped from the page cache,
     * and is therefore not allowed to operate on the store files directly.
     */
    protected void closeStorage()
    {
    }

    /**
     * Marks this store as "not ok".
     */
    protected void setStoreNotOk( Throwable cause )
    {
        storeOk = false;
        causeOfStoreNotOk = cause;
        idGenerator = null; // since we will rebuild it later
    }

    /**
     * If store is "not ok" <CODE>false</CODE> is returned.
     *
     * @return True if this store is ok
     */
    protected boolean getStoreOk()
    {
        return storeOk;
    }

    /**
     * Throws cause of not being OK if {@link #getStoreOk()} returns {@code false}.
     */
    protected void checkStoreOk()
    {
        if ( !storeOk )
        {
            throw launderedException( causeOfStoreNotOk );
        }
    }

    /**
     * Returns the next id for this store's {@link IdGenerator}.
     *
     * @return The next free id
     */
    @Override
    public long nextId()
    {
        return idGenerator.nextId();
    }

    /**
     * Frees an id for this store's {@link IdGenerator}.
     *
     * @param id The id to free
     */
    public void freeId( long id )
    {
        if ( idGenerator != null )
        {
            idGenerator.freeId( id );
        }
        // else we're deleting records as part of applying transactions during recovery, and that's fine
    }

    /**
     * Return the highest id in use.
     *
     * @return The highest id in use.
     */
    public long getHighId()
    {
        return idGenerator != null ? idGenerator.getHighId() : -1;
    }

    /**
     * Sets the high id, i.e. highest id in use + 1 (use this when rebuilding id generator).
     *
     * @param highId The high id to set.
     */
    public void setHighId( long highId )
    {
        // This method might get called during recovery, where we don't have a reliable id generator yet,
        // so ignore these calls and let rebuildIdGenerators() figure out the high id after recovery.
        if ( idGenerator != null )
        {
            synchronized ( idGenerator )
            {
                if ( highId > idGenerator.getHighId() )
                {
                    idGenerator.setHighId( highId );
                }
            }
        }
    }

    /**
     * If store is not ok a call to this method will rebuild the {@link
     * IdGenerator} used by this store and if successful mark it as
     * <CODE>ok</CODE>.
     */
    public void makeStoreOk()
    {
        if ( !storeOk )
        {
            rebuildIdGenerator();
            storeOk = true;
            causeOfStoreNotOk = null;
        }
    }

    /**
     * Returns the name of this store.
     *
     * @return The name of this store
     */
    public File getStorageFileName()
    {
        return storageFileName;
    }

    private File getIdFileName()
    {
        return new File( getStorageFileName().getPath() + ".id" );
    }

    /**
     * Opens the {@link IdGenerator} used by this store.
     * <p>
     * Note: This method may be called both while the store has the store file mapped in the
     * page cache, and while the store file is not mapped. Implementers must therefore
     * map their own temporary PagedFile for the store file, and do their file IO through that,
     * if they need to access the data in the store file.
     */
    protected void openIdGenerator()
    {
        idGenerator = openIdGenerator( getIdFileName(), idType.getGrabSize() );
    }

    /**
     * Opens the {@link IdGenerator} given by the fileName.
     * <p>
     * Note: This method may be called both while the store has the store file mapped in the
     * page cache, and while the store file is not mapped. Implementers must therefore
     * map their own temporary PagedFile for the store file, and do their file IO through that,
     * if they need to access the data in the store file.
     */
    protected IdGenerator openIdGenerator( File fileName, int grabSize )
    {
        try
        {
            return idGeneratorFactory.open( fileName, grabSize, getIdType(), findHighIdBackwards() );
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException(
                    "Unable to find high id by scanning backwards " + getStorageFileName(), e );
        }
    }

    protected long findHighIdBackwards() throws IOException
    {
        try ( PageCursor cursor = storeFile.io( 0, PF_SHARED_LOCK ) )
        {
            long nextPageId = storeFile.getLastPageId();
            int recordsPerPage = recordsPerPage();
            int recordSize = getRecordSize();
            while ( nextPageId >= 0 && cursor.next( nextPageId ) )
            {
                nextPageId--;
                do
                {
                    int currentRecord = recordsPerPage;
                    while ( currentRecord-- > 0 )
                    {
                        cursor.setOffset( currentRecord * recordSize );
                        long recordId = (cursor.getCurrentPageId() * recordsPerPage) + currentRecord;
                        if ( isRecordInUse( cursor ) )
                        {
                            // We've found the highest id in use
                            return recordId + 1 /*+1 since we return the high id*/;
                        }
                    }
                }
                while ( cursor.shouldRetry() );
            }

            return getNumberOfReservedLowIds();
        }
    }

    public abstract int getRecordSize();

    protected boolean isRecordInUse( PageCursor cursor )
    {
        return isInUse( cursor.getByte() );
    }

    protected boolean isRecordReserved( PageCursor cursor )
    {
        return false;
    }

    protected void createIdGenerator( File fileName )
    {
        idGeneratorFactory.create( fileName, 0, false );
    }

    /** Closed the {@link IdGenerator} used by this store */
    protected void closeIdGenerator()
    {
        if ( idGenerator != null )
        {
            idGenerator.close();
        }
    }

    public void flush()
    {
        try
        {
            storeFile.flushAndForce();
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Failed to flush", e );
        }
    }

    /**
     * Closes this store. This will cause all buffers and channels to be closed.
     * Requesting an operation from after this method has been invoked is
     * illegal and an exception will be thrown.
     * <p>
     * This method will start by invoking the {@link #closeStorage} method
     * giving the implementing store way to do anything that it needs to do
     * before the fileChannel is closed.
     */
    @Override
    public void close()
    {
        if ( fileChannel == null )
        {
            return;
        }
        closeStorage();
        try
        {
            storeFile.close();
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Failed to close store file: " + getStorageFileName(), e );
        }
        if ( idGenerator == null || !storeOk )
        {
            releaseFileLockAndCloseFileChannel();
            return;
        }
        final long highId = idGenerator.getHighId();
        final int recordSize = getEffectiveRecordSize();
        idGenerator.close();
        IOException storedIoe = null;
        // hack for WINBLOWS
        try
        {
            windowsSafeIOOperation( new FileOperation()
            {
                @Override
                public void perform() throws IOException
                {
                    fileChannel.position( highId * recordSize );
                    ByteBuffer buffer = wrap( encode( versionMismatchHandler.trailerToWrite( getTypeAndVersionDescriptor(), readTypeDescriptorAndVersion ) ) );
                    fileChannel.write( buffer );
                    log.debug( "Closing " + storageFileName + ", truncating at " + fileChannel.position() +
                                        " vs file size " + fileChannel.size() );
                    fileChannel.truncate( fileChannel.position() );
                    fileChannel.force( false );
                    releaseFileLockAndCloseFileChannel();
                }
            } );
        }
        catch ( IOException e )
        {
            storedIoe = e;
        }

        if ( storedIoe != null )
        {
            throw new UnderlyingStorageException( "Unable to close store " + getStorageFileName(), storedIoe );
        }
    }

    protected void releaseFileLockAndCloseFileChannel()
    {
        try
        {
            if ( fileLock != null )
            {
                fileLock.release();
            }
            if ( fileChannel != null )
            {
                fileChannel.close();
            }
        }
        catch ( IOException e )
        {
            log.warn( "Could not close [" + storageFileName + "]", e );
        }
        fileChannel = null;
    }

    /**
     * Returns a <CODE>StoreChannel</CODE> to this storage's file. If
     * <CODE>close()</CODE> method has been invoked <CODE>null</CODE> will be
     * returned.
     * <p>
     * Note: You can only operate directly on the StoreChannel while the file
     * is not mapped in the page cache.
     *
     * @return A file channel to this storage
     */
    protected final StoreChannel getFileChannel()
    {
        return fileChannel;
    }

    /** @return The highest possible id in use, -1 if no id in use. */
    public long getHighestPossibleIdInUse()
    {
        if ( idGenerator != null )
        {
            return idGenerator.getHighestPossibleIdInUse();
        }
        else
        {   // If we ask for this before we've recovered we can only make a best-effort guess
            // about the highest possible id in use.
            return calculateHighestIdInUseByLookingAtFileSize();
        }
    }

    /**
     * Sets the highest id in use. After this call highId will be this given id + 1.
     *
     * @param highId The highest id in use to set.
     */
    public void setHighestPossibleIdInUse( long highId )
    {
        setHighId( highId + 1 );
    }

    private long calculateHighestIdInUseByLookingAtFileSize()
    {
        try
        {
            return getFileChannel().size() / getRecordSize();
        }
        catch ( IOException e )
        {
            throw new RuntimeException( e );
        }
    }

    /** @return The total number of ids in use. */
    public long getNumberOfIdsInUse()
    {
        return idGenerator.getNumberOfIdsInUse();
    }

    /**
     * @return the number of records at the beginning of the store file that are reserved for other things
     * than actual records. Stuff like permanent configuration data.
     */
    public int getNumberOfReservedLowIds()
    {
        return 0;
    }

    public IdType getIdType()
    {
        return idType;
    }

    public void logVersions( Logger logger )
    {
        logger.log( "  " + getTypeAndVersionDescriptor() );
    }

    public void logIdUsage( Logger logger )
    {
        logger.log( String.format( "  %s: used=%s high=%s",
                getTypeDescriptor(), getNumberOfIdsInUse(), getHighestPossibleIdInUse() ) );
    }

    /**
     * Visits this store, and any other store managed by this store.
     * TODO this could, and probably should, replace all override-and-do-the-same-thing-to-all-my-managed-stores
     * methods like:
     * {@link #makeStoreOk()},
     * {@link #closeStorage()} (where that method could be deleted all together and do a visit in {@link #close()}),
     * {@link #logIdUsage(Logger)},
     * {@link #logVersions(Logger)}
     * For a good samaritan to pick up later.
     */
    public void visitStore( Visitor<CommonAbstractStore,RuntimeException> visitor )
    {
        visitor.visit( this );
    }

    @Override
    public String toString()
    {
        return getClass().getSimpleName();
    }

    public static abstract class Configuration
    {
        public static final Setting<Boolean> rebuild_idgenerators_fast =
                GraphDatabaseSettings.rebuild_idgenerators_fast;
    }
}


File: community/kernel/src/main/java/org/neo4j/kernel/impl/store/standard/StandardStore.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel.impl.store.standard;

import java.io.File;
import java.io.IOException;

import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.io.pagecache.PageCache;
import org.neo4j.io.pagecache.PageCursor;
import org.neo4j.io.pagecache.PagedFile;
import org.neo4j.kernel.impl.store.InvalidRecordException;
import org.neo4j.kernel.impl.store.format.Store;
import org.neo4j.kernel.lifecycle.LifecycleAdapter;
import org.neo4j.logging.LogProvider;

import static org.neo4j.io.pagecache.PagedFile.PF_EXCLUSIVE_LOCK;
import static org.neo4j.io.pagecache.PagedFile.PF_NO_GROW;
import static org.neo4j.io.pagecache.PagedFile.PF_SHARED_LOCK;

public class StandardStore<RECORD, CURSOR extends Store.RecordCursor> extends LifecycleAdapter
             implements Store<RECORD, CURSOR>
{
    private final StoreFormat<RECORD, CURSOR> storeFormat;
    private final StoreFormat.RecordFormat<RECORD> recordFormat;

    private final StoreIdGenerator idGenerator;
    private final PageCache pageCache;
    private final FileSystemAbstraction fs;
    private final File dbFileName;
    private final StoreOpenCloseCycle openCloseLogic;
    private final IdGeneratorRebuilder.Factory idGeneratorRebuilding;

    private StoreToolkit toolkit;
    private PagedFile file;

    /**
     * This MUST NOT be accessed while the store is in STARTED state, all interaction with the file while the store is
     * open must be done via {@link #file}.
     */
    private StoreChannel channel;

    public StandardStore( StoreFormat<RECORD, CURSOR> format, File dbFileName, StoreIdGenerator idGenerator,
                         PageCache pageCache, FileSystemAbstraction fs, LogProvider logProvider )
    {
        this(format, dbFileName, idGenerator, pageCache, fs,
                new IdGeneratorRebuilder.FindHighestInUseRebuilderFactory(),
                new StoreOpenCloseCycle( logProvider.getLog( StandardStore.class ), dbFileName, format, fs ) );
    }

    public StandardStore( StoreFormat<RECORD, CURSOR> format, File dbFileName, StoreIdGenerator idGenerator,
                          PageCache pageCache, FileSystemAbstraction fs,
                          IdGeneratorRebuilder.Factory idGeneratorRebuilding, StoreOpenCloseCycle openCloseCycle )
    {
        this.storeFormat = format;
        this.recordFormat = format.recordFormat();
        this.dbFileName = dbFileName;
        this.idGenerator = idGenerator;
        this.pageCache = pageCache;
        this.fs = fs;
        this.idGeneratorRebuilding = idGeneratorRebuilding;
        this.openCloseLogic = openCloseCycle;
    }

    @Override
    public CURSOR cursor( int flags )
    {
        return storeFormat.createCursor(file, toolkit, flags);
    }

    @Override
    public RECORD read( long id ) throws IOException
    {
        long pageId = toolkit.pageId( id );
        int offset = toolkit.recordOffset( id );

        try ( PageCursor cursor = file.io( pageId, PF_SHARED_LOCK | PF_NO_GROW ) )
        {
            if ( cursor.next() )
            {
                RECORD record = recordFormat.newRecord( id );
                do
                {
                    recordFormat.deserialize( cursor, offset, id, record );
                } while ( cursor.shouldRetry() );

                return record;
            }
            else
            {
                throw new InvalidRecordException( recordFormat.recordName() + "[" + id + "] not in use" );
            }
        }
    }

    @Override
    public void write( RECORD record ) throws IOException
    {
        long id = recordFormat.id( record );
        long pageId = toolkit.pageId( id );
        int offset = toolkit.recordOffset( id );

        try ( PageCursor cursor = file.io( pageId, PF_EXCLUSIVE_LOCK ) )
        {
            if ( cursor.next() )
            {
                do
                {
                    recordFormat.serialize( cursor, offset, record );
                } while ( cursor.shouldRetry() );
            }
        }
    }

    @Override
    public long allocate()
    {
        return idGenerator.allocate();
    }

    @Override
    public void free( long id )
    {
        idGenerator.free(id);
    }

    @Override
    public void start() throws Throwable
    {
        if(!fs.fileExists( dbFileName ))
        {
            createNewStore();
        }
        else
        {
            openExistingStore();
        }
    }

    @Override
    public void stop() throws Throwable
    {
        if(file != null)
        {
            file.close();
            file = null;
        }
        if( channel != null)
        {
            openCloseLogic.closeStore( channel, idGenerator.highestIdInUse() );
            channel.close();
            channel = null;
        }
    }

    private void openExistingStore() throws IOException
    {
        channel = fs.open(dbFileName, "rw");
        initializeToolkit();
        // We make sure to do the file truncation before we map the file with the page cache:
        boolean idGeneratorNeedsRebuilding = openCloseLogic.openStore( channel );
        file = pageCache.map( dbFileName, toolkit.pageSize() );
        if ( idGeneratorNeedsRebuilding )
        {
            IdGeneratorRebuilder rebuilder = idGeneratorRebuilding.newIdGeneratorRebuilder(
                    this, toolkit, idGenerator );
            rebuilder.rebuildIdGenerator();
        }
    }

    private void createNewStore() throws IOException
    {
        fs.mkdirs( dbFileName.getParentFile() );
        fs.create( dbFileName );
        channel = fs.open( dbFileName, "rw" );

        storeFormat.createStore( channel );

        initializeToolkit();
        file = pageCache.map( dbFileName, toolkit.pageSize() );

        // If this is the first time the store is started, and the store has a header, we need to reserve enough
        // initial records to make space for that header.
        int headerSize = storeFormat.headerSize();
        while(headerSize > 0)
        {
            // "Throw away" record slots at the beginning of the file until we've covered the full size of the header
            allocate();
            headerSize -= toolkit.recordSize();
        }
    }

    private void initializeToolkit() throws IOException
    {
        int recordSize = storeFormat.recordSize( channel );
        int headerSize = storeFormat.headerSize();
        int firstRecordId = headerSize == 0 ? 0 : (int) Math.ceil( headerSize / (1.0 * recordSize) );

        // Note that the store page size is always divisible by recordSize. Since the pageCache reuses pages across
        // stores, it has a larger in-memory page size, but it will honor the size we calculate here as the on-disk
        // size for our file. In any case, the calculation below tries to fit as many records as possible within
        // the page size used in-memory by the pageCache.
        int pageSize = pageCache.pageSize() - pageCache.pageSize() % recordSize;

        toolkit = new StoreToolkit( recordSize, pageSize, firstRecordId, channel, idGenerator );
    }
}


File: community/kernel/src/main/java/org/neo4j/kernel/impl/store/standard/StoreOpenCloseCycle.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel.impl.store.standard;

import static java.nio.ByteBuffer.wrap;
import static org.neo4j.helpers.UTF8.encode;
import static org.neo4j.io.fs.FileUtils.windowsSafeIOOperation;

import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.OverlappingFileLockException;

import org.neo4j.helpers.UTF8;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.FileUtils;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.kernel.impl.store.NotCurrentStoreVersionException;
import org.neo4j.kernel.impl.store.UnderlyingStorageException;
import org.neo4j.kernel.impl.util.Charsets;
import org.neo4j.logging.Log;

/**
 * Manages the "opening" and "closing" of store files. In this context, a "closed" store is one that has a footer
 * appended at the end of the file, while an "open" store has had that footer removed. Using this footer, we can
 * determine if a store was cleanly closed (contains footer) or not (no footer), as well as ensure that the format
 * is one we can read.
 *
 * The footer contains two values written to the end of the store on shutdown.
 *
 * - A store "type descriptor", such as "NodeStore", which does not change across versions
 * - A store version, which must change when store format changes. Must always be 6 bytes long when serialized to UTF-8,
 *   because of reasons.
 *
 * The various states and how to read them looks like:
 *
 *                   Correct type | Wrong/missing Type
 * Correct version      CLEAN     |      UNCLEAN
 *   Wrong version  WRONG_VERSION |      UNCLEAN
 *
 */
public class StoreOpenCloseCycle
{
    enum StoreState
    {
        /** Store has been correctly shut down, and can be used directly. */
        CLEAN,

        /** Store is correctly shut down, but has a version different from the one expected. */
        WRONG_VERSION,

        /**
         * Store is incorrectly shut down, and requires recovery. The version is unknown,
         * and must be securely determined by some other mechanism.
         */
        UNCLEAN
    }

    /**
     * Wraps a {@link StoreOpenCloseCycle.StoreState} with a description of the reason
     * for it, to help with error messages.
     */
    public static class StateDescription
    {
        private final StoreState state;
        private final String expectedFooter;
        private final String foundTypeAndVersion;

        public StateDescription( StoreState state, String expectedFooter, String foundTypeAndVersion )
        {
            this.state = state;
            this.expectedFooter = expectedFooter;
            this.foundTypeAndVersion = foundTypeAndVersion;
        }

        public StoreState state()
        {
            return state;
        }

        public String expectedFooter()
        {
            return expectedFooter;
        }

        public String foundFooter()
        {
            return foundTypeAndVersion;
        }
    }

    private final Log log;
    private final File dbFileName;
    private final StoreFormat<?, ?> format;
    private final FileSystemAbstraction fs;

    private FileLock fileLock;

    public StoreOpenCloseCycle( Log log, File dbFileName, StoreFormat<?, ?> format, FileSystemAbstraction fs )
    {
        this.log = log;
        this.dbFileName = dbFileName;
        this.format = format;
        this.fs = fs;
    }

    /**
     * Opens the store, truncating off the footer if it exists.
     * Returns 'true' if the store has not been cleanly shut down and the id
     * generator should be rebuilt, 'false' otherwise.
     */
    public boolean openStore( StoreChannel channel ) throws IOException
    {
        lock( channel );
        StateDescription result = determineState( channel );
        StoreState state = result.state();
        switch ( state )
        {
            case CLEAN:
                // Cut off the footer, indicating the store is open
                channel.truncate( channel.size() - UTF8.encode( footer() ).length );
                return false;
            case UNCLEAN:
                // Store was not closed properly, indicating a crash or some other event causing the process
                // to exit without running shut down procedures. We need to rebuild our id generator at this point.
                return true;
            case WRONG_VERSION:
                throw new NotCurrentStoreVersionException( result.expectedFooter(), result.foundFooter(), "", false );
            default:
                throw new IllegalStateException( "Unknown store state: " + state );
        }
    }

    public void closeStore( final StoreChannel channel, final long highestIdInUse ) throws IOException
    {
        windowsSafeIOOperation( new FileUtils.FileOperation()
        {
            @Override
            public void perform() throws IOException
            {
                channel.position( highestIdInUse * format.recordSize( channel ) );
                ByteBuffer buffer = wrap( encode( footer() ) );
                channel.write( buffer );
                log.debug( "Closing " + dbFileName + ", truncating at " + channel.position() +
                        " vs file size " + channel.size() );
                channel.truncate( channel.position() );
                channel.force( false );
                if ( fileLock != null )
                {
                    fileLock.release();
                    fileLock = null;
                }
            }
        } );
    }

    private void lock( StoreChannel channel )
    {
        try
        {
            this.fileLock = fs.tryLock( dbFileName, channel );
        }
        catch ( IOException e )
        {
            throw new UnderlyingStorageException( "Unable to lock store[" + dbFileName + "]", e );
        }
        catch ( OverlappingFileLockException e )
        {
            throw new IllegalStateException( "Unable to lock store [" + dbFileName +
                    "], this is usually caused by another Neo4j kernel already running in " +
                    "this JVM for this particular store" );
        }
    }

    private StateDescription determineState( StoreChannel channel ) throws IOException
    {
        assert format.version().getBytes( Charsets.UTF_8 ).length == 6: "Version must, for historical reasons, be 6 bytes long.";

        String expectedTypeAndVersion = footer();

        long fileSize = channel.size();
        byte[] expected = expectedTypeAndVersion.getBytes( Charsets.UTF_8 );
        byte[] found = new byte[expected.length];

        ByteBuffer buffer = ByteBuffer.wrap( found );

        if ( fileSize < expected.length )
        {
            // File is too small to have a footer, must be unclean
            return new StateDescription(StoreState.UNCLEAN, expectedTypeAndVersion, "None" );
        }

        int recordSize = format.recordSize( channel );
        if( recordSize != 0 && (fileSize - expected.length) % recordSize != 0)
        {
            return new StateDescription(StoreState.UNCLEAN, expectedTypeAndVersion, "None" );
        }

        channel.position( fileSize - expected.length );
        channel.read( buffer );

        String foundTypeAndVersion = UTF8.decode( found );

        if ( !expectedTypeAndVersion.equals( foundTypeAndVersion ) )
        {
            if ( foundTypeAndVersion.startsWith( format.type() ) )
            {
                return new StateDescription( StoreState.WRONG_VERSION, expectedTypeAndVersion, foundTypeAndVersion );
            }
            else
            {
                return new StateDescription( StoreState.UNCLEAN, expectedTypeAndVersion, foundTypeAndVersion );
            }
        }

        return new StateDescription( StoreState.CLEAN, expectedTypeAndVersion, foundTypeAndVersion );
    }

    private String footer()
    {
        return format.type() + " " + format.version();
    }
}


File: community/kernel/src/test/java/org/neo4j/kernel/StoreLockerTest.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel;

import org.junit.Rule;
import org.junit.Test;

import java.io.File;
import java.io.IOException;

import org.neo4j.graphdb.mockfs.DelegatingFileSystemAbstraction;
import org.neo4j.io.fs.DefaultFileSystemAbstraction;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.test.TargetDirectory;

import static java.lang.String.format;
import static org.hamcrest.CoreMatchers.containsString;
import static org.hamcrest.core.Is.is;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.fail;
import static org.neo4j.kernel.StoreLocker.STORE_LOCK_FILENAME;

public class StoreLockerTest
{
    @Rule
    public TargetDirectory.TestDirectory target = TargetDirectory.testDirForTest( StoreLockerTest.class );

    @Test
    public void shouldObtainLockWhenStoreFileNotLocked() throws Exception
    {
        FileSystemAbstraction fileSystemAbstraction = new DelegatingFileSystemAbstraction( new DefaultFileSystemAbstraction() )
        {
            @Override
            public boolean fileExists( File fileName )
            {
                return true;
            }
        };
        StoreLocker storeLocker = new StoreLocker( fileSystemAbstraction );

        try
        {
            storeLocker.checkLock( target.directory( "unused" ) );

            // Ok
        }
        catch ( StoreLockException e )
        {
            fail();
        }
        finally
        {
            storeLocker.release();
        }
    }

    @Test
    public void shouldCreateStoreDirAndObtainLockWhenStoreDirDoesNotExist() throws Exception
    {
        FileSystemAbstraction fileSystemAbstraction = new DelegatingFileSystemAbstraction( new DefaultFileSystemAbstraction() )
        {
            @Override
            public boolean fileExists( File fileName )
            {
                return false;
            }
        };
        StoreLocker storeLocker = new StoreLocker( fileSystemAbstraction );

        try
        {
            storeLocker.checkLock( target.directory( "unused" ) );
            // Ok
        }
        catch ( StoreLockException e )
        {
            fail();
        }
        finally
        {
            storeLocker.release();
        }
    }

    @Test
    public void shouldNotObtainLockWhenStoreDirCannotBeCreated() throws Exception
    {
        FileSystemAbstraction fileSystemAbstraction = new DelegatingFileSystemAbstraction( new DefaultFileSystemAbstraction() )
        {
            @Override
            public void mkdirs( File fileName ) throws IOException
            {
                throw new IOException( "store dir could not be created" );
            }

            @Override
            public boolean fileExists( File fileName )
            {
                return false;
            }
        };
        StoreLocker storeLocker = new StoreLocker( fileSystemAbstraction );
        File storeDir = target.directory( "unused" );

        try
        {
            storeLocker.checkLock( storeDir );
            fail();
        }
        catch ( StoreLockException e )
        {
            String msg = format( "Unable to create path for store dir: %s. Please ensure no other process is using this database, and that the directory is writable (required even for read-only access)", storeDir );
            assertThat( e.getMessage(), is( msg ) );
        }
        finally
        {
            storeLocker.release();
        }
    }

    @Test
    public void shouldNotObtainLockWhenUnableToOpenLockFile() throws Exception
    {
        FileSystemAbstraction fileSystemAbstraction = new DelegatingFileSystemAbstraction( new DefaultFileSystemAbstraction() )
        {
            @Override
            public StoreChannel open( File fileName, String mode ) throws IOException
            {
                throw new IOException( "cannot open lock file" );
            }

            @Override
            public boolean fileExists( File fileName )
            {
                return false;
            }
        };
        StoreLocker storeLocker = new StoreLocker( fileSystemAbstraction );
        File storeDir = target.directory( "unused" );

        try
        {
            storeLocker.checkLock( storeDir );
            fail();
        }
        catch ( StoreLockException e )
        {
            String msg = format( "Unable to obtain lock on store lock file: %s. Please ensure no other process is using this database, and that the directory is writable (required even for read-only access)", new File( storeDir,
                    STORE_LOCK_FILENAME ) );
            assertThat( e.getMessage(), is( msg ) );
        }
        finally
        {
            storeLocker.release();
        }
    }

    @Test
    public void shouldNotObtainLockWhenStoreAlreadyInUse() throws Exception
    {
        FileSystemAbstraction fileSystemAbstraction = new DelegatingFileSystemAbstraction( new DefaultFileSystemAbstraction() )
        {
            @Override
            public boolean fileExists( File fileName )
            {
                return false;
            }

            @Override
            public FileLock tryLock( File fileName, StoreChannel channel ) throws IOException
            {
                throw new IOException( "Unable to create lock file " + fileName );
            }
        };
        StoreLocker storeLocker = new StoreLocker( fileSystemAbstraction );

        try
        {
            storeLocker.checkLock( target.directory( "unused" ) );
            fail();
        }
        catch ( StoreLockException e )
        {
            assertThat( e.getMessage(), containsString( "Unable to obtain lock on store lock file" ) );
        }
        finally
        {
            storeLocker.release();
        }
    }
}


File: community/kernel/src/test/java/org/neo4j/kernel/impl/store/TestOsSpecificLocks.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel.impl.store;

import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.TestName;

import java.io.File;
import java.io.IOException;

import org.neo4j.graphdb.GraphDatabaseService;
import org.neo4j.graphdb.Transaction;
import org.neo4j.helpers.Settings;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.kernel.DefaultFileSystemAbstraction;
import org.neo4j.kernel.StoreLocker;
import org.neo4j.test.TargetDirectory;
import org.neo4j.test.TestGraphDatabaseFactory;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.junit.Assume.assumeTrue;

public class TestOsSpecificLocks
{
    private File path;

    @Rule
    public TestName name = new TestName();
    @Rule
    public TargetDirectory.TestDirectory testDirectory = TargetDirectory.testDirForTest( getClass() );

    @Before
    public void doBefore()
    {
        path = testDirectory.directory( name.getMethodName() );
    }

    @Test
    public void sanityCheck() throws Exception
    {
        assumeTrue( Settings.osIsWindows() );
        FileSystemAbstraction fs = new DefaultFileSystemAbstraction();
        // Must grab locks only on store_lock file
        File fileName = new File( path, StoreLocker.STORE_LOCK_FILENAME );
        StoreChannel channel = fs.open( fileName, "rw" );
        // Lock this sucker!
        FileLock lock = fs.tryLock( fileName, channel );
        assertTrue( new File( path, "lock" ).exists() );

        try
        {
            fs.tryLock( fileName, channel );
            fail( "Should have thrown IOException" );
        }
        catch ( IOException e )
        {   // Good, expected
        }

        // But the rest of the files should return non null (placebos,
        // actually)
        StoreChannel tempChannel = fs.open( new File( fileName.getPath() + "1" ), "rw" );
        FileLock tempLock = fs.tryLock( new File( fileName.getPath() + "1"), tempChannel );
        assertNotNull( tempLock );
        tempLock.release();
        tempChannel.close();

        // Release and retry, should succeed
        lock.release();
        assertFalse( new File( path, "lock" ).exists() );
        fs.tryLock( fileName, channel ).release(); // NPE on fail here
        assertFalse( new File( path, "lock" ).exists() );
    }

    @Test
    public void testDatabaseLocking()
    {
        assumeTrue( Settings.osIsWindows() );
        GraphDatabaseService db = new TestGraphDatabaseFactory().newEmbeddedDatabase( path.getPath() );
        Transaction tx = db.beginTx();
        db.createNode();
        tx.success();
        tx.close();
        assertTrue( new File( path, "lock" ).exists() );
        try
        {
            new TestGraphDatabaseFactory().newEmbeddedDatabase( path.getPath() );
            fail("Should not be able to start up another db in the same dir");
        }
        catch ( Exception e )
        {
            // Good
        }
        db.shutdown();
    }
}


File: community/kernel/src/test/java/org/neo4j/kernel/impl/store/impl/StoreOpenCloseCycleTest.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.kernel.impl.store.impl;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;

import java.io.File;
import java.io.IOException;

import org.junit.Rule;
import org.junit.Test;
import org.neo4j.graphdb.mockfs.EphemeralFileSystemAbstraction;
import org.neo4j.io.fs.FileLock;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.StoreChannel;
import org.neo4j.kernel.impl.store.format.TestHeaderlessStoreFormat;
import org.neo4j.kernel.impl.store.standard.IdGeneratorRebuilder;
import org.neo4j.kernel.impl.store.standard.StoreFormat;
import org.neo4j.kernel.impl.store.standard.StoreOpenCloseCycle;
import org.neo4j.logging.NullLog;
import org.neo4j.test.EphemeralFileSystemRule;

public class StoreOpenCloseCycleTest
{
    @Rule
    public EphemeralFileSystemRule fsRule = new EphemeralFileSystemRule();

    @Test
    public void shouldLockAndUnlock() throws Exception
    {
        // Given
        StoreFormat<?,?> format = mock(StoreFormat.class);
        when(format.version()).thenReturn( "v1.0.0" );
        when(format.type()).thenReturn( "SomeFormat" );

        File dbFileName = new File( "/store" );
        StoreChannel channel = mock(StoreChannel.class);

        FileLock lock = mock(FileLock.class);

        FileSystemAbstraction fs = mock(FileSystemAbstraction.class);
        when(fs.tryLock( dbFileName, channel )).thenReturn( lock );

        StoreOpenCloseCycle logic = new StoreOpenCloseCycle( NullLog.getInstance(),
                dbFileName, format, fs );

        // When
        logic.openStore(channel );

        // Then
        verify( fs ).tryLock(dbFileName, channel );

        // And when
        logic.closeStore( channel, 0 );

        // Then
        verify( lock ).release();
    }

    @Test
    public void shouldReturnTrueIfStoreIsNotClean() throws Exception
    {
        // Given
        File storeFile = new File( "store" );
        EphemeralFileSystemAbstraction fs = fsRule.get();
        TestHeaderlessStoreFormat format = new TestHeaderlessStoreFormat();

        StoreOpenCloseCycle cycle = new StoreOpenCloseCycle( NullLog.getInstance(),
                storeFile, format, fs );

        // And given the file exists (but contains no headers, and should thus be considered unclean)
        fs.create( storeFile );
        StoreChannel channel = fs.open( storeFile, "rw" );

        // When
        boolean uncleanShutdown = cycle.openStore( channel );

        // Then
        assertTrue( uncleanShutdown );
    }

    @Test
    public void cleanlyShutdownStoreShouldNotHaveIdGeneratorRebuilt() throws Exception
    {
        // Given
        File storeFile = new File( "store" );
        EphemeralFileSystemAbstraction fs = fsRule.get();

        StoreChannel channel = newCleanStore( storeFile );

        IdGeneratorRebuilder idGenRebuilder = mock( IdGeneratorRebuilder.class );
        StoreOpenCloseCycle cycle = new StoreOpenCloseCycle( NullLog.getInstance(),
                storeFile, new TestHeaderlessStoreFormat(), fs );

        // When
        boolean uncleanShutdown = cycle.openStore( channel );

        // Then
        assertFalse( uncleanShutdown );
    }

    private StoreChannel newCleanStore( File storeFile ) throws IOException
    {
        EphemeralFileSystemAbstraction fs = fsRule.get();
        StoreOpenCloseCycle cycle = new StoreOpenCloseCycle( NullLog.getInstance(),
                storeFile, new TestHeaderlessStoreFormat(), fs);

        // And given a cleanly shut down store
        fs.create( storeFile );
        StoreChannel channel = fs.open( storeFile, "rw" );
        cycle.openStore( channel );
        cycle.closeStore( channel, 1 );
        return channel;
    }
}


File: community/lucene-index/src/test/java/org/neo4j/index/recovery/UniqueIndexRecoveryTests.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.index.recovery;

import org.junit.After;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;

import java.io.File;
import java.io.FileFilter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.Random;

import org.neo4j.graphdb.Label;
import org.neo4j.graphdb.Node;
import org.neo4j.graphdb.Transaction;
import org.neo4j.graphdb.schema.ConstraintDefinition;
import org.neo4j.io.fs.FileUtils;
import org.neo4j.kernel.GraphDatabaseAPI;
import org.neo4j.kernel.api.impl.index.LuceneLabelScanStoreExtension;
import org.neo4j.kernel.api.impl.index.LuceneSchemaIndexProviderFactory;
import org.neo4j.kernel.extension.KernelExtensionFactory;
import org.neo4j.kernel.impl.api.index.inmemory.InMemoryIndexProviderFactory;
import org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointer;
import org.neo4j.kernel.impl.transaction.log.rotation.LogRotation;
import org.neo4j.kernel.impl.transaction.log.rotation.StoreFlusher;
import org.neo4j.test.TargetDirectory;
import org.neo4j.test.TestGraphDatabaseFactory;

import static java.util.Arrays.asList;
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.junit.Assert.assertFalse;
import static org.neo4j.graphdb.DynamicLabel.label;

/**
 * Arbitrary recovery scenarios boiled down to as small tests as possible
 */
@RunWith(Parameterized.class)
public class UniqueIndexRecoveryTests
{
    @Test
    public void shouldRecoverCreationOfUniquenessConstraintFollowedByDeletionOfThatSameConstraint() throws Exception
    {
        // given
        createUniqueConstraint();
        dropConstraints();

        // when - perform recovery
        restart( snapshot( storeDir.absolutePath() ) );

        // then - just make sure the constraint is gone
        try ( Transaction tx = db.beginTx() )
        {
            assertFalse( db.schema().getConstraints( LABEL ).iterator().hasNext() );
            tx.success();
        }
    }

    @Test
    public void shouldRecoverWhenCommandsTemporarilyViolateConstraints() throws Exception
    {
        // GIVEN
        Node unLabeledNode = createUnLabeledNode();
        Node labeledNode = createLabeledNode();
        createUniqueConstraint();
        rotateLogAndCheckPoint(); // snapshot
        setPropertyOnLabeledNode( labeledNode );
        deletePropertyOnLabeledNode( labeledNode );
        addLabelToUnLabeledNode( unLabeledNode );
        flushAll(); // persist - recovery will do everything since last log rotate

        // WHEN recovery is triggered
        restart( snapshot( storeDir.absolutePath() ) );

        // THEN
        // it should just not blow up!
        try ( Transaction tx = db.beginTx() )
        {
            assertThat(
                    db.findNode( LABEL, PROPERTY_KEY, PROPERTY_VALUE ),
                    equalTo( unLabeledNode ) );
            tx.success();
        }
    }

    private void restart( File newStore )
    {
        db.shutdown();
        db = (GraphDatabaseAPI) factory.newEmbeddedDatabase( newStore.getAbsolutePath() );
    }

    private File snapshot( final String path ) throws IOException
    {
        File snapshotDir = new File( path, "snapshot-" + new Random().nextInt() );
        FileUtils.copyRecursively( new File( path ), snapshotDir, new FileFilter()
        {
            @Override
            public boolean accept( File pathName )
            {
                String subPath = pathName.getAbsolutePath().substring( path.length() ).replace( File.separatorChar, '/' );
                if ( "/lock".equals( subPath ) )
                {
                    return false; // since the db is running, exclude the 'lock' file
                }
                if ( subPath.startsWith( "/schema/index/lucene/" ) || subPath.startsWith( "/schema/label/lucene/" ) )
                {
                    return !subPath.endsWith( "/write.lock" ); // since the db is running, exclude lucene lock files
                }
                return true;
            }
        } );
        return snapshotDir;
    }

    private void addLabelToUnLabeledNode( Node unLabeledNode )
    {
        try ( Transaction tx = db.beginTx() )
        {
            unLabeledNode.addLabel( LABEL );
            tx.success();
        }
    }

    private void setPropertyOnLabeledNode( Node labeledNode )
    {
        try ( Transaction tx = db.beginTx() )
        {
            labeledNode.setProperty( PROPERTY_KEY, PROPERTY_VALUE );
            tx.success();
        }
    }

    private void deletePropertyOnLabeledNode( Node labeledNode )
    {
        try ( Transaction tx = db.beginTx() )
        {
            labeledNode.removeProperty( PROPERTY_KEY );
            tx.success();
        }
    }

    private void createUniqueConstraint()
    {
        try ( Transaction tx = db.beginTx() )
        {
            db.schema().constraintFor( LABEL ).assertPropertyIsUnique( PROPERTY_KEY ).create();
            tx.success();
        }
    }

    private Node createLabeledNode()
    {
        try ( Transaction tx = db.beginTx() )
        {
            Node node = db.createNode( LABEL );
            tx.success();
            return node;
        }
    }

    private Node createUnLabeledNode()
    {
        try ( Transaction tx = db.beginTx() )
        {
            Node node = db.createNode();
            node.setProperty( PROPERTY_KEY, PROPERTY_VALUE );
            tx.success();
            return node;
        }
    }

    private void dropConstraints()
    {
        try ( Transaction tx = db.beginTx() )
        {
            for ( ConstraintDefinition constraint : db.schema().getConstraints( LABEL ) )
            {
                constraint.drop();
            }
            tx.success();
        }
    }

    @Parameterized.Parameters(name = "{0}")
    public static Collection<Object[]> parameters()
    {
        return asList(
                new Object[]{new LuceneSchemaIndexProviderFactory()},
                new Object[]{new InMemoryIndexProviderFactory()} );
    }

    @Parameterized.Parameter(0)
    public KernelExtensionFactory<?> kernelExtensionFactory;

    @Rule
    public final TargetDirectory.TestDirectory storeDir =
            TargetDirectory.testDirForTest( UniqueIndexRecoveryTests.class );

    private static final String PROPERTY_KEY = "key";
    private static final String PROPERTY_VALUE = "value";
    private static final Label LABEL = label( "label" );

    private final TestGraphDatabaseFactory factory = new TestGraphDatabaseFactory();
    private GraphDatabaseAPI db;

    @Before
    public void before()
    {
        List<KernelExtensionFactory<?>> extensionFactories = new ArrayList<>();
        extensionFactories.add( kernelExtensionFactory );
        extensionFactories.add(new LuceneLabelScanStoreExtension());
        factory.setKernelExtensions( extensionFactories );
        db = (GraphDatabaseAPI) factory.newEmbeddedDatabase( storeDir.absolutePath() );
    }

    @After
    public void after()
    {
        db.shutdown();
    }

    private void rotateLogAndCheckPoint() throws IOException
    {
        db.getDependencyResolver().resolveDependency( LogRotation.class ).rotateLogFile();
        db.getDependencyResolver().resolveDependency( CheckPointer.class ).forceCheckPoint();
    }

    private void flushAll()
    {
        db.getDependencyResolver().resolveDependency( StoreFlusher.class ).forceEverything();
    }
}


File: enterprise/backup/src/test/java/org/neo4j/backup/BackupServiceIT.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program. If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.backup;

import org.hamcrest.BaseMatcher;
import org.hamcrest.Description;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;

import java.io.File;
import java.io.FileFilter;
import java.io.IOException;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

import org.neo4j.com.storecopy.StoreCopyServer;
import org.neo4j.graphdb.GraphDatabaseService;
import org.neo4j.graphdb.Node;
import org.neo4j.graphdb.Transaction;
import org.neo4j.graphdb.factory.GraphDatabaseSettings;
import org.neo4j.graphdb.index.Index;
import org.neo4j.io.fs.DefaultFileSystemAbstraction;
import org.neo4j.io.fs.FileSystemAbstraction;
import org.neo4j.io.fs.FileUtils;
import org.neo4j.io.pagecache.PageCache;
import org.neo4j.kernel.GraphDatabaseAPI;
import org.neo4j.kernel.NeoStoreDataSource;
import org.neo4j.kernel.configuration.Config;
import org.neo4j.kernel.impl.store.MismatchingStoreIdException;
import org.neo4j.kernel.impl.store.NeoStore;
import org.neo4j.kernel.impl.store.NeoStore.Position;
import org.neo4j.kernel.impl.store.StoreFactory;
import org.neo4j.kernel.impl.storemigration.LogFiles;
import org.neo4j.kernel.impl.storemigration.StoreFile;
import org.neo4j.kernel.impl.transaction.CommittedTransactionRepresentation;
import org.neo4j.kernel.impl.transaction.log.IOCursor;
import org.neo4j.kernel.impl.transaction.log.LogFile;
import org.neo4j.kernel.impl.transaction.log.LogicalTransactionStore;
import org.neo4j.kernel.impl.transaction.log.PhysicalLogFiles;
import org.neo4j.kernel.impl.transaction.log.ReadOnlyTransactionStore;
import org.neo4j.kernel.impl.transaction.log.TransactionIdStore;
import org.neo4j.kernel.impl.transaction.log.checkpoint.CheckPointer;
import org.neo4j.kernel.impl.transaction.log.entry.LogHeader;
import org.neo4j.kernel.impl.transaction.log.entry.LogHeaderReader;
import org.neo4j.kernel.impl.transaction.log.rotation.LogRotation;
import org.neo4j.kernel.impl.transaction.state.DataSourceManager;
import org.neo4j.kernel.impl.transaction.state.NeoStoreSupplier;
import org.neo4j.kernel.impl.util.Dependencies;
import org.neo4j.kernel.impl.util.DependenciesProxy;
import org.neo4j.kernel.lifecycle.LifeSupport;
import org.neo4j.kernel.monitoring.Monitors;
import org.neo4j.logging.FormattedLogProvider;
import org.neo4j.logging.NullLogProvider;
import org.neo4j.test.Barrier;
import org.neo4j.test.DatabaseRule;
import org.neo4j.test.DbRepresentation;
import org.neo4j.test.EmbeddedDatabaseRule;
import org.neo4j.test.PageCacheRule;
import org.neo4j.test.SuppressOutput;
import org.neo4j.test.TargetDirectory;

import static org.hamcrest.CoreMatchers.containsString;
import static org.hamcrest.CoreMatchers.equalTo;
import static org.hamcrest.CoreMatchers.instanceOf;
import static org.hamcrest.MatcherAssert.assertThat;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;

import static java.util.concurrent.TimeUnit.SECONDS;

import static org.neo4j.backup.BackupServiceStressTestingBuilder.untilTimeExpired;

public class BackupServiceIT
{
    private static final class StoreSnoopingMonitor extends StoreCopyServer.Monitor.Adapter
    {
        private final Barrier barrier;

        private StoreSnoopingMonitor( Barrier barrier )
        {
            this.barrier = barrier;
        }

        @Override
        public void finishStreamingStoreFile( File storefile )
        {
            if ( storefile.getAbsolutePath().contains( NODE_STORE ) ||
                 storefile.getAbsolutePath().contains( RELATIONSHIP_STORE ) )
            {
                barrier.reached(); // multiple calls to this barrier will not block
            }
        }
    }

    @Rule
    public final TargetDirectory.TestDirectory target = TargetDirectory.testDirForTest( BackupServiceIT.class );
    private static final String NODE_STORE = StoreFactory.NODE_STORE_NAME;
    private static final String RELATIONSHIP_STORE = StoreFactory.RELATIONSHIP_STORE_NAME;
    private static final String BACKUP_HOST = "localhost";

    private final FileSystemAbstraction fileSystem = new DefaultFileSystemAbstraction();
    private final Monitors monitors = new Monitors();
    private File storeDir;
    private File backupDir;
    public int backupPort = 8200;

    @Rule
    public EmbeddedDatabaseRule dbRule = new EmbeddedDatabaseRule( getClass() ).startLazily();
    @Rule
    public SuppressOutput suppressOutput = SuppressOutput.suppressAll();
    @Rule
    public final PageCacheRule pageCacheRule = new PageCacheRule();

    @Before
    public void setup()
    {
        backupPort = backupPort + 1;
        storeDir = dbRule.getStoreDirFile();
        backupDir = target.directory( "backup_dir" );
    }

    private BackupService backupService()
    {
        return new BackupService( fileSystem, FormattedLogProvider.toOutputStream( System.out ), new Monitors() );
    }

    @Test
    public void shouldThrowExceptionWhenDoingFullBackupOnADirectoryContainingANeoStore() throws Exception
    {
        // given
        fileSystem.mkdir( backupDir );
        fileSystem.create( new File( backupDir, NeoStore.DEFAULT_NAME ) ).close();

        try
        {
            // when
            backupService().doFullBackup( "", 0, backupDir.getAbsoluteFile(), true, new Config(),
                    BackupClient.BIG_READ_TIMEOUT, false );
        }
        catch ( RuntimeException ex )
        {
            // then
            assertThat( ex.getMessage(), containsString( "already contains a database" ) );
        }
    }

    @Test
    public void shouldCopyStoreFiles() throws Throwable
    {
        // given
        defaultBackupPortHostParams();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        createAndIndexNode( db, 1 );

        // when
        BackupService backupService = backupService();
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, dbRule.getConfigCopy(),
                BackupClient.BIG_READ_TIMEOUT, false );
        db.shutdown();

        // then
        File[] files = fileSystem.listFiles( backupDir );

        for ( final StoreFile storeFile : StoreFile.values() )
        {
            assertThat( files, hasFile( storeFile.storeFileName() ) );
        }

        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
    }

    @Test
    public void shouldBeAbleToBackupEvenIfTransactionLogsAreIncomplete() throws Throwable
    {
        /*
        * This test deletes the old persisted log file and expects backup to still be functional. It
        * should not be assumed that the log files have any particular length of history. They could
        * for example have been mangled during backups or removed during pruning.
        */

        // given
        defaultBackupPortHostParams();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();

        for ( int i = 0; i < 100; i++ )
        {
            createAndIndexNode( db, i );
        }

        final File oldLog = db.getDependencyResolver().resolveDependency( LogFile.class ).currentLogFile();
        rotateAndCheckPoint( db );

        for ( int i = 0; i < 1; i++ )
        {
            createAndIndexNode( db, i );
        }
        rotateAndCheckPoint( db );

        long lastCommittedTxBefore = db.getDependencyResolver().resolveDependency( NeoStore.class )
                .getLastCommittedTransactionId();

        db = dbRule.restartDatabase( new DatabaseRule.RestartAction()
        {
            @Override
            public void run( FileSystemAbstraction fs, File storeDirectory ) throws IOException
            {
                FileUtils.deleteFile( oldLog );
            }
        } );

        long lastCommittedTxAfter = db.getDependencyResolver().resolveDependency( NeoStore.class )
                .getLastCommittedTransactionId();

        // when
        BackupService backupService = backupService();
        BackupService.BackupOutcome outcome = backupService.doFullBackup( BACKUP_HOST, backupPort,
                backupDir.getAbsoluteFile(), true, dbRule.getConfigCopy(), BackupClient.BIG_READ_TIMEOUT, false );

        db.shutdown();

        // then
        assertEquals( lastCommittedTxBefore, lastCommittedTxAfter );
        assertTrue( outcome.isConsistent() );
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
    }

    @Test
    public void shouldFindTransactionLogContainingLastNeoStoreTransactionInAnEmptyStore()
    {
        // This test highlights a special case where an empty store can return transaction metadata for transaction 0.

        // given
        defaultBackupPortHostParams();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();

        // when
        BackupService backupService = backupService();
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, dbRule.getConfigCopy(),
                BackupClient.BIG_READ_TIMEOUT, false );
        db.shutdown();

        // then
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );

        assertEquals( 0, getLastTxChecksum( pageCacheRule.getPageCache( fileSystem ) ) );
    }

    @Test
    public void shouldFindTransactionLogContainingLastNeoStoreTransaction() throws Throwable
    {
        // given
        defaultBackupPortHostParams();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        createAndIndexNode( db, 1 );

        // when
        BackupService backupService = backupService();
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, dbRule.getConfigCopy(),
                BackupClient.BIG_READ_TIMEOUT, false );
        db.shutdown();

        // then
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
        assertNotEquals( 0, getLastTxChecksum( pageCacheRule.getPageCache( fileSystem ) ) );
    }

    @Test
    public void shouldFindValidPreviousCommittedTxIdInFirstNeoStoreLog() throws Throwable
    {
        // given
        defaultBackupPortHostParams();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        createAndIndexNode( db, 1 );
        createAndIndexNode( db, 2 );
        createAndIndexNode( db, 3 );
        createAndIndexNode( db, 4 );

        NeoStore neoStore = db.getDependencyResolver().resolveDependency( NeoStore.class );
        neoStore.flush();
        long txId = neoStore.getLastCommittedTransactionId();

        // when
        BackupService backupService = backupService();
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, dbRule.getConfigCopy(),
                BackupClient.BIG_READ_TIMEOUT, false );
        db.shutdown();

        // then
        checkPreviousCommittedTxIdFromLog( 0, TransactionIdStore.BASE_TX_ID );
    }

    @Test
    public void shouldFindTransactionLogContainingLastLuceneTransaction() throws Throwable
    {
        // given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        createAndIndexNode( db, 1 );

        // when
        BackupService backupService = backupService();
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, defaultConfig,
                BackupClient.BIG_READ_TIMEOUT, false );
        db.shutdown();

        // then
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
        assertNotEquals( 0, getLastTxChecksum( pageCacheRule.getPageCache( fileSystem ) ) );
    }

    @Test
    public void shouldGiveHelpfulErrorMessageIfLogsPrunedPastThePointOfNoReturn() throws Exception
    {
        // Given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        dbRule.setConfig( GraphDatabaseSettings.keep_logical_logs, "false" );
        // have logs rotated on every transaction
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        BackupService backupService = backupService();

        createAndIndexNode( db, 1 );
        rotateAndCheckPoint( db );

        // A full backup
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(),
                false, defaultConfig, BackupClient.BIG_READ_TIMEOUT, false );

        // And the log the backup uses is rotated out
        createAndIndexNode( db, 2 );
        rotateAndCheckPoint( db );
        createAndIndexNode( db, 3 );
        rotateAndCheckPoint( db );
        createAndIndexNode( db, 4 );
        rotateAndCheckPoint( db );
        createAndIndexNode( db, 5 );
        rotateAndCheckPoint( db );

        // when
        try
        {
            backupService.doIncrementalBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(),
                    false, BackupClient.BIG_READ_TIMEOUT, defaultConfig );
            fail( "Should have thrown exception." );
        }
        // Then
        catch ( IncrementalBackupNotPossibleException e )
        {
            assertThat( e.getMessage(), equalTo( BackupService.TOO_OLD_BACKUP ) );
        }
    }

    @Test
    public void shouldFallbackToFullBackupIfIncrementalFailsAndExplicitlyAskedToDoThis() throws Exception
    {
        // Given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        dbRule.setConfig( GraphDatabaseSettings.keep_logical_logs, "false" );
        // have logs rotated on every transaction
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        BackupService backupService = backupService();

        createAndIndexNode( db, 1 );

        // A full backup
        backupService.doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(),
                false, defaultConfig, BackupClient.BIG_READ_TIMEOUT, false );

        // And the log the backup uses is rotated out
        createAndIndexNode( db, 2 );
        rotateAndCheckPoint( db );
        createAndIndexNode( db, 3 );
        rotateAndCheckPoint( db );
        createAndIndexNode( db, 4 );
        rotateAndCheckPoint( db );

        // when
        backupService.doIncrementalBackupOrFallbackToFull(
                BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, defaultConfig,
                BackupClient.BIG_READ_TIMEOUT, false );

        // Then
        db.shutdown();
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
    }

    private void rotateAndCheckPoint( GraphDatabaseAPI db ) throws IOException
    {
        db.getDependencyResolver().resolveDependency( LogRotation.class ).rotateLogFile();
        db.getDependencyResolver().resolveDependency( CheckPointer.class ).forceCheckPoint();
    }

    @Test
    public void shouldHandleBackupWhenLogFilesHaveBeenDeleted() throws Exception
    {
        // Given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        dbRule.setConfig( GraphDatabaseSettings.keep_logical_logs, "false" );
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        BackupService backupService = backupService();

        createAndIndexNode( db, 1 );

        // A full backup
        backupService.doIncrementalBackupOrFallbackToFull(
                BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, defaultConfig,
                BackupClient.BIG_READ_TIMEOUT, false );

        // And the log the backup uses is rotated out
        createAndIndexNode( db, 2 );
        db = deleteLogFilesAndRestart();

        createAndIndexNode( db, 3 );
        db = deleteLogFilesAndRestart();

        // when
        backupService.doIncrementalBackupOrFallbackToFull(
                BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, defaultConfig,
                BackupClient.BIG_READ_TIMEOUT, false );

        // Then
        db.shutdown();
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
    }

    private GraphDatabaseAPI deleteLogFilesAndRestart()
            throws IOException
    {
        final FileFilter logFileFilter = new FileFilter()
        {
            @Override
            public boolean accept( File pathname )
            {
                return pathname.getName().contains( "logical" );
            }
        };
        return dbRule.restartDatabase( new DatabaseRule.RestartAction()
        {
            @Override
            public void run( FileSystemAbstraction fs, File storeDirectory ) throws IOException
            {
                for ( File logFile : storeDir.listFiles( logFileFilter ) )
                {
                    logFile.delete();
                }
            }
        } );
    }

    @Test
    public void shouldDoFullBackupOnIncrementalFallbackToFullIfNoBackupFolderExists() throws Exception
    {
        // Given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        dbRule.setConfig( GraphDatabaseSettings.keep_logical_logs, "false" );
        GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();
        BackupService backupService = backupService();

        createAndIndexNode( db, 1 );

        // when
        backupService.doIncrementalBackupOrFallbackToFull(
                BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false, defaultConfig,
                BackupClient.BIG_READ_TIMEOUT, false );

        // then
        db.shutdown();
        assertEquals( DbRepresentation.of( storeDir ), DbRepresentation.of( backupDir ) );
    }

    @Test
    public void shouldContainTransactionsThatHappenDuringBackupProcess() throws Throwable
    {
        // given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        dbRule.setConfig( OnlineBackupSettings.online_backup_enabled, "false" );
        Config withOnlineBackupEnabled = dbRule.getConfigCopy();

        final Barrier.Control barrier = new Barrier.Control();
        final GraphDatabaseAPI db = dbRule.getGraphDatabaseAPI();

        createAndIndexNode( db, 1 ); // create some data

        NeoStoreDataSource ds = db.getDependencyResolver().resolveDependency( DataSourceManager.class ).getDataSource();
        long expectedLastTxId = ds.getNeoStore().getLastCommittedTransactionId();

        // This monitor is added server-side...
        monitors.addMonitorListener( new StoreSnoopingMonitor( barrier ) );

        Dependencies dependencies = new Dependencies(db.getDependencyResolver());
        dependencies.satisfyDependencies( defaultConfig, monitors, NullLogProvider.getInstance() );

        OnlineBackupKernelExtension backup = (OnlineBackupKernelExtension) new OnlineBackupExtensionFactory().newKernelExtension(
                DependenciesProxy.dependencies(dependencies, OnlineBackupExtensionFactory.Dependencies.class));
        backup.start();

        // when
        BackupService backupService =backupService();
        ExecutorService executor = Executors.newSingleThreadExecutor();
        executor.execute( new Runnable()
        {
            @Override
            public void run()
            {
                barrier.awaitUninterruptibly();

                createAndIndexNode( db, 1 );
                db.getDependencyResolver().resolveDependency( NeoStoreSupplier.class ).get().flush();

                barrier.release();
            }
        } );

        BackupService.BackupOutcome backupOutcome = backupService.doFullBackup( BACKUP_HOST, backupPort,
                backupDir.getAbsoluteFile(), true, withOnlineBackupEnabled, BackupClient.BIG_READ_TIMEOUT, false );

        backup.stop();
        executor.shutdown();
        executor.awaitTermination( 30, TimeUnit.SECONDS );

        // then
        checkPreviousCommittedTxIdFromLog( 0, expectedLastTxId );
        checkLastCommittedTxIdInLogAndNeoStore( expectedLastTxId+1 );
        assertEquals( DbRepresentation.of( db ), DbRepresentation.of( backupDir ) );
        assertTrue( backupOutcome.isConsistent() );
    }

    @Test
    public void incrementalBackupShouldFailWhenTargetDirContainsDifferentStore() throws IOException
    {
        // Given
        defaultBackupPortHostParams();
        Config defaultConfig = dbRule.getConfigCopy();
        GraphDatabaseAPI db1 = dbRule.getGraphDatabaseAPI();
        createAndIndexNode( db1, 1 );

        backupService().doFullBackup( BACKUP_HOST, backupPort, backupDir.getAbsoluteFile(), false,
                defaultConfig, BackupClient.BIG_READ_TIMEOUT, false );

        // When
        GraphDatabaseAPI db2 = dbRule.restartDatabase( new DatabaseRule.RestartAction()
        {
            @Override
            public void run( FileSystemAbstraction fs, File storeDirectory ) throws IOException
            {
                deleteAllBackedUpTransactionLogs();

                fileSystem.deleteRecursively( storeDir );
                fileSystem.mkdir( storeDir );
            }
        } );
        createAndIndexNode( db2, 2 );

        try
        {
            backupService().doIncrementalBackupOrFallbackToFull( BACKUP_HOST, backupPort,
                    backupDir.getAbsoluteFile(), false, defaultConfig, BackupClient.BIG_READ_TIMEOUT, false );

            fail( "Should have thrown exception about mismatching store ids" );
        }
        catch ( RuntimeException e )
        {
            // Then
            assertThat( e.getMessage(), equalTo( BackupService.DIFFERENT_STORE ) );
            assertThat( e.getCause(), instanceOf( MismatchingStoreIdException.class ) );
        }
    }

    @Test
    public void theBackupServiceShouldBeHappyUnderStress() throws Exception
    {
        Callable<Integer> callable = new BackupServiceStressTestingBuilder()
                .until( untilTimeExpired( 10, SECONDS ) )
                .withStore( storeDir )
                .withWorkingDirectory( backupDir )
                .withBackupAddress( BACKUP_HOST, backupPort )
                .build();

        int brokenStores = callable.call();
        assertEquals( 0, brokenStores );
    }

    private void defaultBackupPortHostParams()
    {
        dbRule.setConfig( OnlineBackupSettings.online_backup_server, BACKUP_HOST + ":" + backupPort );
    }

    private void createAndIndexNode( GraphDatabaseService db, int i )
    {
        try ( Transaction tx = db.beginTx() )
        {
            Index<Node> index = db.index().forNodes( "delete_me" );
            Node node = db.createNode();
            node.setProperty( "id", System.currentTimeMillis() + i );
            index.add( node, "delete", "me" );
            tx.success();
        }
    }

    private BaseMatcher<File[]> hasFile( final String fileName )
    {
        return new BaseMatcher<File[]>()
        {
            @Override
            public boolean matches( Object o )
            {
                File[] files = (File[]) o;
                if ( files == null )
                {
                    return false;
                }
                for ( File file : files )
                {
                    if ( file.getAbsolutePath().contains( fileName ) )
                    {
                        return true;
                    }
                }
                return false;
            }

            @Override
            public void describeTo( Description description )
            {
                description.appendText( String.format( "[%s] in list of copied files", fileName ) );
            }
        };
    }

    private void checkPreviousCommittedTxIdFromLog( long logVersion, long txId ) throws IOException
    {
        // Assert header of specified log version containing correct txId
        PhysicalLogFiles logFiles = new PhysicalLogFiles( backupDir, fileSystem );
        LogHeader logHeader = LogHeaderReader.readLogHeader( fileSystem, logFiles.getLogFileForVersion( logVersion ) );
        assertEquals( txId, logHeader.lastCommittedTxId );
    }

    private void checkLastCommittedTxIdInLogAndNeoStore( long txId ) throws IOException
    {
        // Assert last committed transaction can be found in tx log and is the last tx in the log
        LifeSupport life = new LifeSupport();
        PageCache pageCache = pageCacheRule.getPageCache( fileSystem );
        LogicalTransactionStore transactionStore =
                life.add( new ReadOnlyTransactionStore( pageCache, fileSystem, backupDir, monitors ) );
        life.start();
        try ( IOCursor<CommittedTransactionRepresentation> cursor =
                      transactionStore.getTransactions( txId ) )
        {
            assertTrue( cursor.next() );
            assertEquals( txId, cursor.get().getCommitEntry().getTxId() );
            assertFalse( cursor.next() );
        }
        finally
        {
            life.shutdown();
        }

        // Assert last committed transaction is correct in neostore
        File neoStore = new File( storeDir, NeoStore.DEFAULT_NAME );
        assertEquals( txId, NeoStore.getRecord( pageCache, neoStore, Position.LAST_TRANSACTION_ID ) );
    }

    private long getLastTxChecksum( PageCache pageCache )
    {
        File neoStore = new File( backupDir, NeoStore.DEFAULT_NAME );
        return NeoStore.getRecord( pageCache, neoStore, Position.LAST_TRANSACTION_CHECKSUM );
    }

    private void deleteAllBackedUpTransactionLogs()
    {
        for ( File log : fileSystem.listFiles( backupDir, LogFiles.FILENAME_FILTER ) )
        {
            fileSystem.deleteFile( log );
        }
    }
}


File: enterprise/com/src/test/java/org/neo4j/com/storecopy/StoreCopyClientTest.java
/*
 * Copyright (c) 2002-2015 "Neo Technology,"
 * Network Engine for Objects in Lund AB [http://neotechnology.com]
 *
 * This file is part of Neo4j.
 *
 * Neo4j is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program. If not, see <http://www.gnu.org/licenses/>.
 */
package org.neo4j.com.storecopy;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.atomic.AtomicBoolean;

import org.junit.Assert;
import org.junit.Rule;
import org.junit.Test;

import org.neo4j.com.RequestContext;
import org.neo4j.com.Response;
import org.neo4j.function.Supplier;
import org.neo4j.graphdb.GraphDatabaseService;
import org.neo4j.graphdb.Transaction;
import org.neo4j.helpers.CancellationRequest;
import org.neo4j.helpers.Service;
import org.neo4j.helpers.collection.Iterables;
import org.neo4j.io.pagecache.PageCache;
import org.neo4j.kernel.DefaultFileSystemAbstraction;
import org.neo4j.kernel.GraphDatabaseAPI;
import org.neo4j.kernel.NeoStoreDataSource;
import org.neo4j.kernel.configuration.Config;
import org.neo4j.kernel.extension.KernelExtensionFactory;
import org.neo4j.kernel.impl.store.NeoStore;
import org.neo4j.kernel.impl.store.StoreId;
import org.neo4j.kernel.impl.transaction.log.entry.LogHeader;
import org.neo4j.kernel.impl.transaction.log.rotation.StoreFlusher;
import org.neo4j.kernel.impl.transaction.log.LogicalTransactionStore;
import org.neo4j.kernel.impl.transaction.log.TransactionIdStore;
import org.neo4j.kernel.impl.transaction.state.NeoStoreSupplier;
import org.neo4j.kernel.monitoring.Monitors;
import org.neo4j.logging.NullLogProvider;
import org.neo4j.test.PageCacheRule;
import org.neo4j.test.TargetDirectory;
import org.neo4j.test.TestGraphDatabaseFactory;
import org.neo4j.tooling.GlobalGraphOperations;

import static org.hamcrest.Matchers.equalTo;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertThat;
import static org.mockito.Mockito.spy;
import static org.mockito.Mockito.times;
import static org.mockito.Mockito.verify;

import static org.neo4j.graphdb.DynamicLabel.label;

public class StoreCopyClientTest
{
    @Rule
    public TargetDirectory.TestDirectory testDir = TargetDirectory.testDirForTest( getClass() );
    @Rule
    public PageCacheRule pageCacheRule = new PageCacheRule();

    private final DefaultFileSystemAbstraction fs = new DefaultFileSystemAbstraction();

    @Test
    public void shouldCopyStoreFilesAcrossIfACancellationRequestHappensAfterTheTempStoreHasBeenRecovered()
            throws IOException
    {
        // given
        final File copyDir = new File( testDir.directory(), "copy" );
        final File originalDir = new File( testDir.directory(), "original" );

        final AtomicBoolean cancelStoreCopy = new AtomicBoolean( false );
        CancellationRequest cancellationRequest = new CancellationRequest()
        {
            @Override
            public boolean cancellationRequested()
            {
                return cancelStoreCopy.get();
            }
        };

        StoreCopyClient.Monitor storeCopyMonitor = new StoreCopyClient.Monitor.Adapter()
        {
            @Override
            public void finishRecoveringStore()
            {
                // simulate a cancellation request
                cancelStoreCopy.set( true );
            }
        };

        PageCache pageCache = pageCacheRule.getPageCache( fs );
        StoreCopyClient copier =
                new StoreCopyClient( copyDir, new Config(), loadKernelExtensions(), NullLogProvider.getInstance(), fs, pageCache, storeCopyMonitor,
                        false );

        final GraphDatabaseAPI original =
                (GraphDatabaseAPI) startDatabase( originalDir );

        try ( Transaction tx = original.beginTx() )
        {
            original.createNode( label( "BeforeCopyBegins" ) );
            tx.success();
        }

        StoreCopyClient.StoreCopyRequester storeCopyRequest = storeCopyRequest( originalDir, original );


        // when
        copier.copyStore( storeCopyRequest, cancellationRequest );

        // Then
        GraphDatabaseService copy = startDatabase( copyDir );

        try ( Transaction tx = copy.beginTx() )
        {
            GlobalGraphOperations globalOps = GlobalGraphOperations.at( copy );

            long nodesCount = Iterables.count( globalOps.getAllNodesWithLabel( label( "BeforeCopyBegins" ) ) );
            assertThat( nodesCount, equalTo( 1l ) );

            assertThat( Iterables.single( globalOps.getAllNodesWithLabel( label( "BeforeCopyBegins" ) ) ).getId(),
                    equalTo( 0l ) );

            tx.success();
        }
        finally
        {
            copy.shutdown();
            original.shutdown();
        }

        verify( storeCopyRequest, times( 1 ) ).done();
    }

    @Test
    public void shouldEndUpWithAnEmptyStoreIfCancellationRequestIssuedJustBeforeRecoveryTakesPlace()
            throws IOException
    {
        // given
        final File copyDir = new File( testDir.directory(), "copy" );
        final File originalDir = new File( testDir.directory(), "original" );

        final AtomicBoolean cancelStoreCopy = new AtomicBoolean( false );
        CancellationRequest cancellationRequest = new CancellationRequest()
        {
            @Override
            public boolean cancellationRequested()
            {
                return cancelStoreCopy.get();
            }
        };

        StoreCopyClient.Monitor storeCopyMonitor = new StoreCopyClient.Monitor.Adapter()
        {
            @Override
            public void finishReceivingStoreFiles()
            {
                // simulate a cancellation request
                cancelStoreCopy.set( true );
            }
        };

        PageCache pageCache = pageCacheRule.getPageCache( fs );
        StoreCopyClient copier =
                new StoreCopyClient( copyDir, new Config(), loadKernelExtensions(), NullLogProvider.getInstance(), fs, pageCache, storeCopyMonitor,
                        false );

        final GraphDatabaseAPI original = (GraphDatabaseAPI) startDatabase( originalDir );

        try ( Transaction tx = original.beginTx() )
        {
            original.createNode( label( "BeforeCopyBegins" ) );
            tx.success();
        }

        StoreCopyClient.StoreCopyRequester storeCopyRequest = storeCopyRequest( originalDir, original );


        // when
        copier.copyStore( storeCopyRequest, cancellationRequest );

        // Then
        GraphDatabaseService copy = startDatabase( copyDir );

        try ( Transaction tx = copy.beginTx() )
        {
            GlobalGraphOperations globalOps = GlobalGraphOperations.at( copy );

            long nodesCount = Iterables.count( globalOps.getAllNodesWithLabel( label( "BeforeCopyBegins" ) ) );
            assertThat( nodesCount, equalTo( 0l ) );

            tx.success();
        }
        finally
        {
            copy.shutdown();
            original.shutdown();
        }

        verify( storeCopyRequest, times( 1 ) ).done();
    }

    @Test
    public void shouldResetNeoStoreLastTransactionOffsetForNonForensicCopy() throws Exception
    {
        // GIVEN
        File initialStore = testDir.directory( "initialStore" );
        File backupStore = testDir.directory( "backupStore" );

        PageCache pageCache = pageCacheRule.getPageCache( fs );
        GraphDatabaseService initialDatabase = null;
        try
        {
            initialDatabase = startDatabase( initialStore );
            for ( int i = 0; i < 10; i++ )
            try ( Transaction tx = initialDatabase.beginTx() )
            {
                initialDatabase.createNode( label( "Neo" + i ) );
                tx.success();
            }
            initialDatabase.shutdown();

            initialDatabase = startDatabase( initialStore );
            long originalTransactionOffset =
                    NeoStore.getRecord( pageCache, new File( initialStore, NeoStore.DEFAULT_NAME ),
                            NeoStore.Position.LAST_CLOSED_TRANSACTION_LOG_BYTE_OFFSET );

            StoreCopyClient copier =
                    new StoreCopyClient( backupStore, new Config(), loadKernelExtensions(), NullLogProvider
                            .getInstance(), fs, pageCache, new StoreCopyClient.Monitor.Adapter(), false );
            CancellationRequest falseCancellationRequest = new CancellationRequest()
            {
                @Override
                public boolean cancellationRequested()
                {
                    return false;
                }
            };
            StoreCopyClient.StoreCopyRequester storeCopyRequest = storeCopyRequest( initialStore, (GraphDatabaseAPI)
                    initialDatabase );

            // WHEN
            copier.copyStore( storeCopyRequest, falseCancellationRequest );

            // THEN
            long updatedTransactionOffset =
                    NeoStore.getRecord( pageCache, new File( backupStore, NeoStore.DEFAULT_NAME ), NeoStore.Position
                            .LAST_CLOSED_TRANSACTION_LOG_BYTE_OFFSET );
            Assert.assertNotEquals( originalTransactionOffset, updatedTransactionOffset );
            Assert.assertEquals( LogHeader.LOG_HEADER_SIZE, updatedTransactionOffset );
        }
        finally
        {
            if (initialDatabase != null)
            {
                initialDatabase.shutdown();
            }
        }
    }

    private GraphDatabaseService startDatabase( File storeDir )
    {
        return new TestGraphDatabaseFactory().newEmbeddedDatabase( storeDir );
    }

    private StoreCopyClient.StoreCopyRequester storeCopyRequest( final File originalDir,
            final GraphDatabaseAPI original )
    {
        return spy( new StoreCopyClient.StoreCopyRequester()
            {
                public Response<?> response;

                @Override
                public Response<?> copyStore( StoreWriter writer )
                {
                    NeoStoreDataSource neoStoreDataSource =
                            original.getDependencyResolver().resolveDependency( NeoStoreDataSource.class );

                    TransactionIdStore transactionIdStore = original.getDependencyResolver().resolveDependency(
                            TransactionIdStore.class );

                    LogicalTransactionStore logicalTransactionStore  = original.getDependencyResolver().resolveDependency(
                            LogicalTransactionStore.class );

                    StoreFlusher storeFlusher = original.getDependencyResolver().resolveDependency(
                            StoreFlusher.class );

                    RequestContext requestContext = new StoreCopyServer(transactionIdStore, neoStoreDataSource,
                            storeFlusher, fs, originalDir, new Monitors().newMonitor( StoreCopyServer.Monitor.class ) )
                            .flushStoresAndStreamStoreFiles( writer, false );

                    final StoreId storeId = original.getDependencyResolver().resolveDependency( NeoStoreSupplier.class ).get().getStoreId();

                    ResponsePacker responsePacker = new ResponsePacker( logicalTransactionStore,
                            transactionIdStore, new Supplier<StoreId>()
                    {
                        @Override
                        public StoreId get()
                        {
                            return storeId;
                        }
                    } );


                    response = spy(responsePacker.packTransactionStreamResponse( requestContext, null ));
                    return response;

                }

                @Override
                public void done()
                {
                    // Ensure response is closed before this method is called
                    assertNotNull( response );
                    verify( response, times( 1 ) ).close();
                }
            } );
    }

    private static List<KernelExtensionFactory<?>> loadKernelExtensions()
    {
        List<KernelExtensionFactory<?>> kernelExtensions = new ArrayList<>();
        for ( KernelExtensionFactory<?> factory : Service.load( KernelExtensionFactory.class ) )
        {
            kernelExtensions.add( factory );
        }
        return kernelExtensions;
    }
}
