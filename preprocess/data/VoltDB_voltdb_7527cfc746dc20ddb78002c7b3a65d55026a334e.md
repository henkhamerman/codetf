Refactoring Types: ['Move Class']
erationMode.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb;

/**
 * All the operational modes VoltDB can be in
 */
public enum OperationMode {
    INITIALIZING, RUNNING, PAUSED, SHUTTINGDOWN;

    /**
     * Get the operation mode from its ordinal value.
     * @param val
     * @return
     */
    public static OperationMode get(byte val) {
        for (OperationMode mode : OperationMode.values()) {
            if (mode.ordinal() == val) {
                return mode;
            }
        }
        throw new AssertionError("Unknown mode: " + val);
    }
}


File: src/frontend/org/voltdb/importclient/kafka/KafkaStreamImporter.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */
package org.voltdb.importclient.kafka;

import java.net.URI;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import kafka.api.FetchRequestBuilder;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import kafka.javaapi.consumer.SimpleConsumer;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import java.util.SortedSet;
import java.util.TreeSet;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import kafka.api.ConsumerMetadataRequest;
import kafka.api.FetchRequest;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.cluster.Broker;
import kafka.common.ErrorMapping;
import kafka.common.OffsetAndMetadata;
import kafka.common.TopicAndPartition;
import kafka.javaapi.ConsumerMetadataResponse;
import kafka.javaapi.FetchResponse;
import kafka.javaapi.OffsetCommitRequest;
import kafka.javaapi.OffsetCommitResponse;
import kafka.javaapi.OffsetResponse;
import kafka.javaapi.PartitionMetadata;
import kafka.javaapi.TopicMetadata;
import kafka.javaapi.TopicMetadataRequest;
import kafka.message.MessageAndOffset;
import kafka.network.BlockingChannel;

import org.osgi.framework.BundleActivator;
import org.osgi.framework.BundleContext;
import org.voltdb.VoltDB;
import org.voltdb.client.ClientResponse;
import org.voltdb.client.ProcedureCallback;
import org.voltdb.importer.CSVInvocation;
import org.voltdb.importer.ImportHandlerProxy;

/**
 * Based on SimpleConsumer Implement a BundleActivator interface and extend ImportHandlerProxy.
 * For each partition for a topic a thread is launched to pull data and submit transactions.
 *
 * @author akhanzode
 */
public class KafkaStreamImporter extends ImportHandlerProxy implements BundleActivator {

    //Properties for the importer
    private Properties m_properties;
    //Group id
    private String m_groupId;
    //Procedure to be invoked with params.
    private String m_procedure;
    //List of topics form comma seperated list.
    private List<String> m_topicList;
    //List of brokers.
    private final List<HostAndPort> m_brokerList = new ArrayList<HostAndPort>();
    //kafka properties which has defaults use 2m row limit.
    private int m_fetchSize = (2*1024*1024);
    private int m_consumerSocketTimeout = 30000; //In milliseconds

    private static final String GROUP_ID = "voltdb";
    private static final String CLIENT_ID = "voltdb-importer";
    private static final int KAFKA_DEFAULT_BROKER_PORT = 9092;
    //readyForData is waiting for this released by shutdown
    private final Semaphore m_done = new Semaphore(0);
    private boolean m_stopping = false;

    //topic partition metadata
    private final Map<String, List<TopicMetadata>> m_topicPartitionMetaData = new HashMap<String, List<TopicMetadata>>();
    //Topic partitions
    private final Map<String, List<Integer>> m_topicPartitions = new HashMap<String, List<Integer>>();
    //topic partition leader
    private final Map<String, HostAndPort> m_topicPartitionLeader = new HashMap<String, HostAndPort>();
    private final Map<String, TopicPartitionFetcher> m_fetchers = new HashMap<String, TopicPartitionFetcher>();

    private ExecutorService m_es = null;

    //Simple Host and Port abstraction....dont want to use our big stuff here orgi bundle import nastiness.
    public static class HostAndPort {

        private final String m_host;
        private final int m_port;
        private final String m_connectionString;

        public HostAndPort(String h, int p) {
            m_host = h;
            m_port = p;
            m_connectionString = m_host + ":" + m_port;
        }

        public static HostAndPort fromString(String hap) {
            String s[] = hap.split(":");
            int p = KAFKA_DEFAULT_BROKER_PORT;
            if (s.length > 1 && s[1] != null && s[1].length() > 0) {
                p = Integer.parseInt(s[1].trim());
            }
            return new HostAndPort(s[0].trim(), p);
        }

        public String getHost() {
            return m_host;
        }

        public int getPort() {
            return m_port;
        }

        @Override
        public String toString() {
            return m_host + ":" + m_port;
        }

        @Override
        public int hashCode() {
            return m_connectionString.hashCode();
        }

        @Override
        public boolean equals(Object o) {
            if (!(o instanceof HostAndPort)) {
                return false;
            }
            HostAndPort hap = (HostAndPort )o;
            if (hap == this) {
                return true;
            }
            if (hap.getHost().equals(getHost()) && hap.getPort() == getPort()) {
                return true;
            }
            return false;
        }
    }

    // Register ImportHandlerProxy service.
    @Override
    public void start(BundleContext context) throws Exception {
        context.registerService(this.getClass().getName(), this, null);
    }

    @Override
    public void stop(BundleContext context) throws Exception {
        //Do any bundle related cleanup.
    }

    @Override
    public boolean isRunEveryWhere() {
        //This is not a run everywhere importer only allocated resources are polled and consumed.
        return false;
    }

    //This is called to get all available resources. So called once during startup or catalog update.
    private Set<URI> buildTopicLeaderMetadata(SimpleConsumer consumer) {

        //For all topics connect and get metadata.
        Set<URI> availableResources = new TreeSet<URI>();
        for (String topic : m_topicList) {
            TopicMetadataRequest req = new TopicMetadataRequest(Collections.singletonList(topic));
            kafka.javaapi.TopicMetadataResponse resp = null;
            try {
                resp = consumer.send(req);
            } catch (Exception ex) {
                error("Failed to send topic metada request for topic " + topic, ex);
                continue;
            }

            List<TopicMetadata> metaData = resp.topicsMetadata();
            if (metaData == null) {
                error("Failed to get topic metadata for topic " + topic);
                continue;
            }
            m_topicPartitionMetaData.put(topic, metaData);
            List<Integer> partitions = m_topicPartitions.get(topic);
            if (partitions == null) {
                partitions = new ArrayList<Integer>();
                m_topicPartitions.put(topic, partitions);
            }
            for (TopicMetadata item : metaData) {
                for (PartitionMetadata part : item.partitionsMetadata()) {
                    partitions.add(part.partitionId());
                    for (kafka.cluster.Broker replica : part.replicas()) {
                        String leaderKey = topic + "-" + part.partitionId();
                        m_topicPartitionLeader.put(leaderKey, new HostAndPort(replica.host(), replica.port()));
                        URI uri = URI.create("kafka:/" + topic + "/partition/" + part.partitionId());
                        availableResources.add(uri);
                    }
                }
            }
        }

        info("Available Channels are: " + availableResources);
        //Create an executor serice with Queue.
        m_es = Executors.newFixedThreadPool(availableResources.size() + 1);
        return availableResources;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        SimpleConsumer simpleConsumer = null;
        Set<URI> availableResources = new TreeSet<URI>();
        try {
            simpleConsumer = new SimpleConsumer(m_brokerList.get(0).getHost(), m_brokerList.get(0).getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
            //Build all available topic URIs
            availableResources = buildTopicLeaderMetadata(simpleConsumer);
        } catch (Exception ex) {
            VoltDB.crashLocalVoltDB("Failed to get available resources for kafka importer", true, ex);
        } finally {
            closeConsumer(simpleConsumer);
        }
        return availableResources;
    }

    @Override
    public void stop() {
        m_stopping = true;
        //Stop all the fetchers.
        for (TopicPartitionFetcher fetcher : m_fetchers.values()) {
            fetcher.shutdown();
        }
        m_done.release();
        if (m_es != null) {
            //Now wait for fetchers to break out.
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException ex) {
                //Should never come here.
                ex.printStackTrace();
            }
        }
        m_fetchers.clear();
    }

    /**
     * Return a name for VoltDB to log with friendly name.
     *
     * @return name of the importer.
     */
    @Override
    public String getName() {
        return "KafkaImporter82";
    }

    /**
     * This is called with the properties that are supplied in the deployment.xml Do any initialization here.
     *
     * @param p
     */
    @Override
    public void configure(Properties p) {
        m_properties = (Properties) p.clone();
        m_procedure = m_properties.getProperty("procedure", "").trim();
        if (m_procedure.isEmpty()) {
            throw new RuntimeException("Missing procedure.");
        }
        //pipe seperated list of topics.
        String topics = m_properties.getProperty("topics", "").trim();
        if (topics.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
        m_topicList = Arrays.asList(topics.split("\\s*,\\s*"));
        if (m_topicList == null || m_topicList.isEmpty()) {
            throw new RuntimeException("Missing topic(s).");
        }
       String brokers = m_properties.getProperty("brokers", "").trim();
        if (brokers.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        List<String> brokerList = Arrays.asList(brokers.split("\\s*,\\s*"));
        if (brokerList == null || brokerList.isEmpty()) {
            throw new RuntimeException("Missing kafka broker");
        }
        for (String broker : brokerList) {
            HostAndPort hap = HostAndPort.fromString(broker);
            m_brokerList.add(hap);
        }
        if (m_brokerList.isEmpty()) {
            throw new RuntimeException("Missing or misconfigured kafka broker list. See brokers property");
        }
        m_groupId = m_properties.getProperty("groupid", GROUP_ID).trim();
        //These are defaults picked up from kafka we save them so that they are passed around.
        m_fetchSize = Integer.parseInt(m_properties.getProperty("fetch.message.max.bytes", "65536"));
        m_consumerSocketTimeout = Integer.parseInt(m_properties.getProperty("socket.timeout.ms", "30000"));
    }

    //Per topic per partition that we are responsible for.
    private class TopicPartitionFetcher implements Runnable {

        //URL for this fetcher.
        private final URI m_url;
        //Leafer for fetching data
        private final HostAndPort m_leader;
        //coordinator for offset management.
        private HostAndPort m_coordinator;
        private boolean m_shutdown = false;
        private final int m_fetchSize;
        //Available brokers.
        private final List<HostAndPort> m_brokers;
        private final int m_consumerSocketTimeout;
        //Start with invalid so consumer will fetch it.
        private final AtomicLong m_currentOffset = new AtomicLong(-1);
        private final SortedSet<Long> m_pendingOffsets = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final SortedSet<Long> m_seenOffset = Collections.synchronizedSortedSet(new TreeSet<Long>());
        private final int m_perTopicPendingLimit = Integer.getInteger("voltdb.kafka.pertopicPendingLimit", 50000);
        private final AtomicReference<SimpleConsumer> m_offsetManager = new AtomicReference<SimpleConsumer>();
        private final TopicAndPartition m_topicAndPartition;

        public TopicPartitionFetcher(List<HostAndPort> brokers, URI uri, String topic, int partition, HostAndPort leader, int fetchSize, int consumerSocketTimeout) {
            m_url = uri;
            m_brokers = brokers;
            m_leader = leader;
            m_coordinator = leader;
            m_fetchSize = fetchSize;
            m_consumerSocketTimeout = consumerSocketTimeout;
            m_topicAndPartition = new TopicAndPartition(topic, partition);
        }

        public final URI getUrl() {
            return m_url;
        }

        //Find leader for the topic+partition.
        private PartitionMetadata findLeader() {
            PartitionMetadata returnMetaData = null;
            loop:
            for (HostAndPort broker : m_brokers) {
                SimpleConsumer consumer = null;
                try {
                    consumer = new SimpleConsumer(broker.getHost(), broker.getPort(), m_consumerSocketTimeout, m_fetchSize, "findLeader");

                    List<String> topics = Collections.singletonList(m_topicAndPartition.topic());
                    TopicMetadataRequest req = new TopicMetadataRequest(topics);
                    kafka.javaapi.TopicMetadataResponse resp = consumer.send(req);

                    List<TopicMetadata> metaData = resp.topicsMetadata();
                    for (TopicMetadata item : metaData) {
                        for (PartitionMetadata part : item.partitionsMetadata()) {
                            if (part.partitionId() == m_topicAndPartition.partition()) {
                                returnMetaData = part;
                                break loop;
                            }
                        }
                    }
                } catch (Exception e) {
                    error("Error in finding leader for " + m_topicAndPartition, e);
                } finally {
                    closeConsumer(consumer);
                }
            }
            if (returnMetaData == null) {
                error("Failed to find Leader for " + m_topicAndPartition);
            }
            return returnMetaData;
        }

        //Find leader for this topic partition.
        private HostAndPort findNewLeader() {
            for (int i = 0; i < 3; i++) {
                boolean shouldSleep = false;
                PartitionMetadata metadata = findLeader();
                if (metadata == null) {
                    shouldSleep = true;
                } else if (metadata.leader() == null) {
                    shouldSleep = true;
                } else if (m_leader.getHost().equalsIgnoreCase(metadata.leader().host()) && i == 0) {
                    // first time through if the leader hasn't changed give ZooKeeper a second to recover
                    // second time, assume the broker did recover before failover, or it was a non-Broker issue
                    shouldSleep = true;
                } else {
                    return new HostAndPort(metadata.leader().host(), metadata.leader().port());
                }
                if (shouldSleep) {
                    backoffSleep(i+1);
                }
            }
            //Unable to find return null for recheck.
            info("Failed to find new leader for " + m_topicAndPartition);
            return null;
        }

        //Just set shutdown flag fetcher timeout will then exit the thread.
        public void shutdown() {
            m_shutdown = true;
        }

        public void getOffsetCoordinator() {
            BlockingChannel channel = null;
            for (int i = 0; i < 3; i++) {
                try {
                    //This can go to any broker
                    channel = new BlockingChannel(m_coordinator.getHost(), m_coordinator.getPort(),
                            BlockingChannel.UseDefaultBufferSize(),
                            BlockingChannel.UseDefaultBufferSize(),
                            m_consumerSocketTimeout /* read timeout in millis */);
                    channel.connect();
                    int correlationId = 0;
                    channel.send(new ConsumerMetadataRequest(m_groupId, ConsumerMetadataRequest.CurrentVersion(), correlationId++, CLIENT_ID));
                    ConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());

                    if (metadataResponse.errorCode() == ErrorMapping.NoError()) {
                        Broker offsetManager = metadataResponse.coordinator();
                        m_coordinator = new HostAndPort(offsetManager.host(), offsetManager.port());
                        SimpleConsumer consumer = m_offsetManager.getAndSet(new SimpleConsumer(m_coordinator.getHost(), m_coordinator.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                        closeConsumer(consumer);
                        consumer = null;
                        break;
                    }
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition + " Code: " + metadataResponse.errorCode());
                } catch (Exception e) {
                    // retry the query (after backoff)??=
                    error("Failed to get Offset Coordinator for " + m_topicAndPartition, e);
                    backoffSleep(i+1);
                } finally {
                    if (channel != null) {
                        channel.disconnect();
                    }
                }
            }
            info("Coordinator for " + m_topicAndPartition + " consumer is: " + m_coordinator);
        }

        public long getLastOffset(long whichTime) {
            if (m_offsetManager.get() == null) {
                return -1;
            }
            SimpleConsumer consumer = m_offsetManager.get();
            try {
                Map<TopicAndPartition, PartitionOffsetRequestInfo> requestInfo = new HashMap<TopicAndPartition, PartitionOffsetRequestInfo>();
                requestInfo.put(m_topicAndPartition, new PartitionOffsetRequestInfo(whichTime, 1));
                kafka.javaapi.OffsetRequest request = new kafka.javaapi.OffsetRequest(requestInfo, kafka.api.OffsetRequest.CurrentVersion(), CLIENT_ID);
                OffsetResponse response = consumer.getOffsetsBefore(request);

                if (response.hasError()) {
                    short code = response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                    if (code == ErrorMapping.NotLeaderForPartitionCode() || code == ErrorMapping.UnknownTopicOrPartitionCode()) {
                        HostAndPort leaderBroker = findNewLeader();
                        if (leaderBroker != null) {
                            info("Found new leader for " + m_topicAndPartition + " Coordinator will be updated.");
                            SimpleConsumer oconsumer = m_offsetManager.getAndSet(new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID) );
                            closeConsumer(oconsumer);
                            oconsumer = null;
                            m_coordinator = leaderBroker;
                        }
                    }
                    info("Error fetching Offset Data from Broker " + m_topicAndPartition.toString() +
                            " Reason: " + response.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition()) );
                    return -1;
                }
                long[] offsets = response.offsets(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                return offsets[0];
            } catch (Exception ex) {
                error("Failed to get last Offset for " + m_topicAndPartition, ex);
            }
            return -1;
        }

        //Callback for each invocation we have submitted.
        private class TopicPartitionInvocationCallback implements ProcedureCallback {

            private final long m_offset;
            private final long m_nextOffset;
            private final TopicAndPartition m_topicAndPartition;

            public TopicPartitionInvocationCallback(long offset, long noffset, TopicAndPartition tAndP) {
                m_offset = offset;
                m_nextOffset = noffset;
                m_topicAndPartition = tAndP;
            }

            public boolean commitOffset(long offset) {

                final int correlationId = m_topicAndPartition.partition();
                final short version = 1;

                OffsetAndMetadata offsetMetdata = new OffsetAndMetadata(offset, "commitRequest", ErrorMapping.NoError());
                Map<TopicAndPartition, OffsetAndMetadata> reqMap = new HashMap<TopicAndPartition, OffsetAndMetadata>();
                reqMap.put(m_topicAndPartition, offsetMetdata);
                OffsetCommitRequest offsetCommitRequest = new OffsetCommitRequest(m_groupId, reqMap, correlationId, CLIENT_ID, version);
                OffsetCommitResponse offsetCommitResponse = null;
                try {
                    SimpleConsumer consumer = m_offsetManager.get();
                    if (consumer == null) {
                        getOffsetCoordinator();
                        consumer = m_offsetManager.get();
                    }
                    if (consumer != null) {
                        offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                        final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                        if (code == ErrorMapping.NotCoordinatorForConsumerCode()) {
                            info("Not coordinator for committing offset for " + m_topicAndPartition + " Updating coordinator.");
                            getOffsetCoordinator();
                            consumer = m_offsetManager.get();
                            if (consumer != null) {
                                offsetCommitResponse = consumer.commitOffsets(offsetCommitRequest);
                            }
                        }
                    } else {
                        error("Commit Offset Failed to get offset coordinator for " + m_topicAndPartition);
                        return false;
                    }
                } catch (Exception e) {
                    error("Failed to commit Offset for " + m_topicAndPartition, e);
                    return false;
                }
                final short code = ((Short) offsetCommitResponse.errors().get(m_topicAndPartition));
                if (code != ErrorMapping.NoError()) {
                    error("Commit Offset Failed to commit for " + m_topicAndPartition + " Code: " + code);
                    return false;
                }
                return true;
            }

            private void commitAndSaveOffset(long currentNext) {
                try {
                    //If we have too many commit last and clean up
                    if (m_seenOffset.size() >= m_perTopicPendingLimit) {
                        //Last possible commit point.
                        long commit = m_seenOffset.last();
                        if (commitOffset(commit)) {
                            debug("Committed offset " + commit + " for " + m_topicAndPartition);
                            m_currentOffset.set(commit);
                        }
                        synchronized(m_seenOffset) {
                            m_seenOffset.clear();
                        }
                        info("Seen offset commit list is too big. Size " + m_perTopicPendingLimit + " Commiting highest offset and clean.");
                        return;
                    }
                    long commit;
                    synchronized(m_seenOffset) {
                        if (!m_seenOffset.isEmpty()) {
                            m_seenOffset.add(currentNext);
                            //From first find the last continuous offset and commit that.
                            commit = m_seenOffset.first();
                            while (m_seenOffset.contains(++commit)) {
                                m_seenOffset.remove(commit);
                            }
                        } else {
                           commit =  currentNext;
                        }
                    }

                    //Highest commit we have seen after me will be committed.
                    if (commitOffset(commit)) {
                        debug("Committed offset " + commit + " for " + m_topicAndPartition);
                        m_currentOffset.set(commit);
                    }
                    //If this happens we will come back again on next callback.
                } catch (Exception ex) {
                    error("Failed to commit and save offset " + currentNext, ex);
                }
            }

            @Override
            public void clientCallback(ClientResponse response) throws Exception {
                try {
                    //We should never get here with no pending offsets.
                    assert(!m_pendingOffsets.isEmpty());

                    m_pendingOffsets.remove(m_offset);
                    commitAndSaveOffset(m_nextOffset);

                } catch (Throwable t) {
                    // Should never get here
                  t.printStackTrace();
                }
            }

        }

        //Sleep with backoff.
        private int backoffSleep(int fetchFailedCount) {
            try {
                Thread.sleep(1000 * fetchFailedCount++);
                if (fetchFailedCount > 10) fetchFailedCount = 1;
            } catch (InterruptedException ie) {
            }
            return fetchFailedCount;
        }

        @Override
        public void run() {
            SimpleConsumer consumer = null;
            info("Starting partition fetcher for " + m_topicAndPartition);
            try {
                //Startwith the starting leader.
                HostAndPort leaderBroker = m_leader;
                int fetchFailedCount = 1;
                while (!m_shutdown) {
                    if (consumer == null) {
                        consumer = new SimpleConsumer(leaderBroker.getHost(), leaderBroker.getPort(), m_consumerSocketTimeout, m_fetchSize, CLIENT_ID);
                    }
                    //If we dont know the offset get it backoff if we fail.
                    if (m_currentOffset.get() < 0) {
                        getOffsetCoordinator();
                        m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                        if (m_currentOffset.get() < 0) {
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }
                        info("Starting offset for " + m_topicAndPartition + " is set to: " + m_currentOffset.get());
                    }
                    long currentFetchCount = 0;
                    //Build fetch request of we have a valid offset and not too many are pending.
                    if (m_pendingOffsets.size() < m_perTopicPendingLimit) {
                        FetchRequest req = new FetchRequestBuilder().clientId(CLIENT_ID)
                                .addFetch(m_topicAndPartition.topic(),
                                        m_topicAndPartition.partition(), m_currentOffset.get(), m_fetchSize)
                                .build();
                        FetchResponse fetchResponse = null;
                        try {
                            fetchResponse = consumer.fetch(req);
                            if (fetchResponse == null) {
                                fetchFailedCount = backoffSleep(fetchFailedCount);
                                continue;
                            }
                        } catch (Exception ex) {
                            error("Failed to fetch from " + m_topicAndPartition, ex);
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            continue;
                        }

                        if (fetchResponse.hasError()) {
                            // Something went wrong!
                            short code = fetchResponse.errorCode(m_topicAndPartition.topic(), m_topicAndPartition.partition());
                            fetchFailedCount = backoffSleep(fetchFailedCount);
                            error("Failed to fetch messages for " + m_topicAndPartition + " Code " + code);
                            if (code == ErrorMapping.OffsetOutOfRangeCode()) {
                                // We asked for an invalid offset. For simple case ask for the last element to reset
                                info("Invalid offset requested for " + m_topicAndPartition);
                                getOffsetCoordinator();
                                m_currentOffset.set(getLastOffset(kafka.api.OffsetRequest.LatestTime()));
                                continue;
                            }
                            closeConsumer(consumer);
                            consumer = null;
                            leaderBroker = findNewLeader();
                            if (leaderBroker == null) {
                                //point to original leader which will fail and we fall back again here.
                                error("Failed to find leader continue with old leader: " + m_leader);
                                leaderBroker = m_leader;
                            } else {
                                if (!leaderBroker.equals(m_leader)) {
                                    info("Found new leader for " + m_topicAndPartition + " New Leader: " + leaderBroker);
                                }
                            }
                            continue;
                        }
                        fetchFailedCount = 1;
                        for (MessageAndOffset messageAndOffset : fetchResponse.messageSet(m_topicAndPartition.topic(), m_topicAndPartition.partition())) {
                            long currentOffset = messageAndOffset.offset();
                            //if currentOffset is less means we have already pushed it and also check pending queue.
                            if (currentOffset < m_currentOffset.get() || m_pendingOffsets.contains(currentOffset)) {
                                continue;
                            }
                            ByteBuffer payload = messageAndOffset.message().payload();

                            currentFetchCount++;
                            byte[] bytes = new byte[payload.limit()];
                            payload.get(bytes);
                            String line = new String(bytes, "UTF-8");
                            CSVInvocation invocation = new CSVInvocation(m_procedure, line);
                            TopicPartitionInvocationCallback cb = new TopicPartitionInvocationCallback(currentOffset, messageAndOffset.nextOffset(), m_topicAndPartition);
                            m_pendingOffsets.add(currentOffset);
                            if (!callProcedure(cb, invocation)) {
                                debug("Failed to process Invocation possibly bad data: " + line);
                                m_pendingOffsets.remove(messageAndOffset.nextOffset());
                                //Not in pending but let sequencer coomit account for this and clear.
                                synchronized(m_seenOffset) {
                                    m_seenOffset.add(messageAndOffset.nextOffset());
                                }
                                continue;
                            }
                        }
                    }

                    if (currentFetchCount == 0) {
                        try {
                            Thread.sleep(1000);
                        } catch (InterruptedException ie) {
                        }
                    }
                }
                info("Partition fecher stopping for " + m_topicAndPartition);
                int cnt = 1;
                while (m_pendingOffsets.size() > 0) {
                    cnt = backoffSleep(cnt);
                }
                info("Partition fecher stopped for " + m_topicAndPartition + " Last commit point is: " + m_currentOffset.get());
            } catch (Exception ex) {
                error("Failed to start topic partition fetcher for " + m_topicAndPartition, ex);
            } finally {
                closeConsumer(consumer);
                consumer = null;
            }
        }

    }

    public void closeConsumer(SimpleConsumer consumer) {
        try {
            if (consumer != null) {
                consumer.close();
            }
        } catch (Exception e) {
            error("Failed to close consumer connection.", e);
        }
    }

    //On getting this event kick off ready
    @Override
    public void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version) {
        if (m_stopping) {
            info("Importer is stopping ignoring the change notification.");
        }
        if (m_es == null) {
            //Create executor with sufficient threads.
            VoltDB.crashLocalVoltDB("buildTopicLeaderMetadata must be called before getting an onChange", false, null);
        }

        //For addeed create fetchers...make sure existing fetchers are not there.
        for (URI nuri : added) {
            Map<String, List<Integer>> topicMap = new HashMap<String, List<Integer>>();
            for (String topic : m_topicList) {
                topicMap.put(topic, Collections.singletonList(0));
            }
            for (String topic : m_topicList) {
                List<Integer> topicPartitions = m_topicPartitions.get(topic);
                if (topicPartitions == null) {
                    //I got a change for added partition that I am not aware of die die.
                    VoltDB.crashLocalVoltDB("Unknown kafka topic added for this node", false, null);
                }
                for (int partition : topicPartitions) {
                    String leaderKey = topic + "-" + partition;
                    URI assignedKey = URI.create("kafka:/" + topic + "/partition/" + partition);
                    //The fetcher must not have existed.
                    if (!m_fetchers.containsKey(nuri) && nuri.equals(assignedKey)) {
                        info("Channel " + assignedKey + " mastership is assigned to this node.");
                        HostAndPort hap = m_topicPartitionLeader.get(leaderKey);
                        TopicPartitionFetcher fetcher = new TopicPartitionFetcher(m_brokerList, assignedKey, topic, partition,
                                hap, m_fetchSize, m_consumerSocketTimeout);
                        m_fetchers.put(assignedKey.toString(), fetcher);
                        m_es.submit(fetcher);
                        info("KafkaImporter is fetching for resource: " + nuri);
                    }
                }
            }
        }

        //For removed shutdown the fetchers if all are removed the importer will be closed/shutdown?
        for (URI r : removed) {
            TopicPartitionFetcher fetcher = m_fetchers.get(r.toString());
            if (fetcher != null) {
                fetcher.shutdown();
                info("KafkaImporter is NOT fetching for resource: " + r);
                m_fetchers.remove(r.toString());
            }
        }
    }


    /**
     * This is called when server is ready to accept any transactions.
     */
    @Override
    public void readyForData() {
        try {
            info("Configured and ready with properties: " + m_properties);
            //We wait for shutdown task to release.
            m_done.acquire();
        } catch (Exception ex) {
            error("Kafka Importer finished with exeception ", ex);
        }
    }

}


File: src/frontend/org/voltdb/importer/ChannelAssignment.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import java.util.NavigableSet;
import java.util.Set;

import com.google_voltpatches.common.collect.Sets;

public class ChannelAssignment {

    final Set<ChannelSpec> added;
    final Set<ChannelSpec> removed;
    final NavigableSet<ChannelSpec> channels;
    final int version;

    ChannelAssignment(NavigableSet<ChannelSpec> prev, NavigableSet<ChannelSpec> next, int version) {
        this.version  = version;
        this.added    = Sets.difference(next, prev);
        this.removed  = Sets.difference(prev, next);
        this.channels = next;
    }

    public Set<ChannelSpec> getAdded() {
        return added;
    }

    public Set<ChannelSpec> getRemoved() {
        return removed;
    }

    public NavigableSet<ChannelSpec> getChannels() {
        return channels;
    }

    public int getVersion() {
        return version;
    }

    public boolean hasChanges() {
        return !removed.isEmpty() || !added.isEmpty();
    }

    @Override
    public String toString() {
        return "ChannelAssignment [added=" + added + ", removed=" + removed
                + ", channels=" + channels + ", version=" + version + "]";
    }
}


File: src/frontend/org/voltdb/importer/ChannelChangeCallback.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import java.net.URI;
import java.util.Set;

public interface ChannelChangeCallback {
    void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version);
}


File: src/frontend/org/voltdb/importer/ChannelChangeNotifier.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import static com.google_voltpatches.common.base.Preconditions.checkNotNull;
import static com.google_voltpatches.common.base.Predicates.equalTo;
import static com.google_voltpatches.common.base.Predicates.not;

import java.net.URI;
import java.util.Map;
import java.util.NavigableMap;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.concurrent.atomic.AtomicStampedReference;

import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;

import com.google_voltpatches.common.base.Optional;
import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.collect.ImmutableSetMultimap;
import com.google_voltpatches.common.collect.ImmutableSortedMap;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.SetMultimap;
import com.google_voltpatches.common.collect.Sets;

public class ChannelChangeNotifier implements Runnable {

    private final static VoltLogger LOG = new VoltLogger("IMPORT");

    /**
     * Boiler plate method to log an error message and wrap, and return a {@link DistributerException}
     * around the message and cause
     *
     * @param cause fault origin {@link Throwable}
     * @param format a {@link String#format(String, Object...) compliant format string
     * @param args formatter arguments
     * @return a {@link DistributerException}
     */
    static DistributerException loggedDistributerException(Throwable cause, String format, Object...args) {
        Optional<DistributerException> causeFor = DistributerException.isCauseFor(cause);
        if (causeFor.isPresent()) {
            return causeFor.get();
        }
        String msg = String.format(format, args);
        if (cause != null) {
            LOG.error(msg, cause);
            return new DistributerException(msg, cause);
        } else {
            LOG.error(msg);
            return new DistributerException(msg);
        }
    }

    SetMultimap<String, URI> mapByImporter(Set<ChannelSpec> specs) {
        ImmutableSetMultimap.Builder<String, URI> mmbldr = ImmutableSetMultimap.builder();
        for (ChannelSpec spec: specs) {
            mmbldr.put(spec.getImporter(),spec.getUri());
        }
        return mmbldr.build();
    }

    private final CallbacksRef m_callbacks = new CallbacksRef();
    private final AtomicReference<BlockingDeque<ChannelAssignment>> m_qref = new AtomicReference<>();
    private final AtomicBoolean m_done = new AtomicBoolean(false);
    private final ExecutorService m_es;

    public ChannelChangeNotifier() {
        m_es = CoreUtils.getCachedSingleThreadExecutor("Import Channel Change Notification Dispatcher", 15000);
    }

    public void startPolling(BlockingDeque<ChannelAssignment> deque) {
        if (m_qref.compareAndSet(null, checkNotNull(deque, "deque is null"))) {
            m_es.submit(this);
        } else {
            throw new IllegalStateException("this notifier has already an assigned blocking deque");
        }
    }

    public void registerCallback(String importer, ChannelChangeCallback callback) {
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        callback = checkNotNull(callback, "callback is null");

        int [] stamp = new int[]{0};
        NavigableMap<String, ChannelChangeCallback> prev = null;
        ImmutableSortedMap.Builder<String,ChannelChangeCallback> mbldr = null;

        do {
            prev = m_callbacks.get(stamp);
            mbldr = ImmutableSortedMap.naturalOrder();
            mbldr.putAll(Maps.filterKeys(prev, not(equalTo(importer))));
            mbldr.put(importer, callback);
        } while (!m_callbacks.compareAndSet(prev, mbldr.build(), stamp[0], stamp[0]+1));
    }

    public void shutdown() {
        if (m_done.compareAndSet(false, true)) {
            m_es.shutdown();
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
        }
    }

    @Override
    public void run() {
        if (m_done.get()) return;
        ChannelAssignment assignment = null;
        try {
            assignment = m_qref.get().poll(200, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            throw loggedDistributerException(e, "interrupted while polling for channel assignmanets");
        }
        if (assignment != null) {

            final SetMultimap<String, URI> added = mapByImporter(assignment.getAdded());
            final SetMultimap<String, URI> removed = mapByImporter(assignment.getRemoved());
            final SetMultimap<String, URI> assigned = mapByImporter(assignment.getChannels());

            NavigableMap<String, ChannelChangeCallback> callbacks = m_callbacks.getReference();
            for (Map.Entry<String, ChannelChangeCallback> e: callbacks.entrySet()) {
                final String importer = e.getKey();
                if (added.get(importer).isEmpty() && removed.get(importer).isEmpty()) {
                    continue;
                }
                final ChannelChangeCallback callback = e.getValue();
                final int version = assignment.getVersion();
                m_es.submit(new Runnable() {
                    @Override
                    public void run() {
                        if (m_done.get()) return;
                        try {
                            callback.onChange(
                                    added.get(importer),
                                    removed.get(importer),
                                    assigned.get(importer),
                                    version
                                    );
                        } catch (Exception e) {
                            throw loggedDistributerException(
                                    e, "failed to invoke channel changed callback for %s", importer
                                    );
                        }
                    }
                });
            }
            for (String noCallbackFor: Sets.difference(assigned.keySet(), callbacks.keySet())) {
                LOG.warn("Missing channel notification callbacks for importer \"" + noCallbackFor
                        + "\", which leave these channels \"" + assigned.get(noCallbackFor)
                        + "\" without any assigned handler"
                        );
            }
        }
        if (!m_done.get()) {
            m_es.submit(this);
        }
    }

    final static class CallbacksRef
        extends AtomicStampedReference<NavigableMap<String,ChannelChangeCallback>> {

        static final NavigableMap<String,ChannelChangeCallback> EMTPY_MAP =
                ImmutableSortedMap.of();

        public CallbacksRef(
                NavigableMap<String, ChannelChangeCallback> initialRef,
                int initialStamp) {
            super(initialRef, initialStamp);
        }

        public CallbacksRef() {
            this(EMTPY_MAP,0);
        }
    }
}


File: src/frontend/org/voltdb/importer/ChannelDistributer.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import static com.google_voltpatches.common.base.Predicates.equalTo;
import static com.google_voltpatches.common.base.Predicates.isNull;
import static com.google_voltpatches.common.base.Predicates.not;
import static org.voltcore.zk.ZKUtil.joinZKPath;

import java.io.File;
import java.net.URI;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.NavigableMap;
import java.util.NavigableSet;
import java.util.Random;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicStampedReference;

import org.apache.zookeeper_voltpatches.AsyncCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.Children2Callback;
import org.apache.zookeeper_voltpatches.AsyncCallback.DataCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StatCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.StringCallback;
import org.apache.zookeeper_voltpatches.AsyncCallback.VoidCallback;
import org.apache.zookeeper_voltpatches.CreateMode;
import org.apache.zookeeper_voltpatches.KeeperException;
import org.apache.zookeeper_voltpatches.KeeperException.Code;
import org.apache.zookeeper_voltpatches.KeeperException.NodeExistsException;
import org.apache.zookeeper_voltpatches.WatchedEvent;
import org.apache.zookeeper_voltpatches.Watcher;
import org.apache.zookeeper_voltpatches.Watcher.Event.EventType;
import org.apache.zookeeper_voltpatches.Watcher.Event.KeeperState;
import org.apache.zookeeper_voltpatches.ZooDefs;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.apache.zookeeper_voltpatches.data.Stat;
import org.json_voltpatches.JSONArray;
import org.json_voltpatches.JSONException;
import org.json_voltpatches.JSONStringer;
import org.voltcore.logging.VoltLogger;
import org.voltcore.utils.CoreUtils;
import org.voltcore.zk.ZKUtil;

import com.google_voltpatches.common.base.Function;
import com.google_voltpatches.common.base.Optional;
import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Predicate;
import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableSortedMap;
import com.google_voltpatches.common.collect.ImmutableSortedSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;
import com.google_voltpatches.common.collect.TreeMultimap;

/**
 *  An importer channel distributer that uses zookeeper to coordinate how importer channels are
 *  distributed among VoltDB cluster nodes. A proposal is merged against a master channel lists,
 *  stored in the /import/master zookeeper node. The elected distributer leader distributes the
 *  merge differences among all available nodes, by writing each node's assigned list of
 *  channels in their respective /import/host/[host-name] nodes. When a node leaves the mesh
 *  its assigned channels are redistributed among the surviving nodes
 */
public class ChannelDistributer {

    private final static VoltLogger LOG = new VoltLogger("IMPORT");

    /** root for all importer nodes */
    static final String IMPORT_DN = "/import";
    /** parent node for all {@link CreateMode#EPHEMERAL ephemeral} host nodes */
    static final String HOST_DN = joinZKPath(IMPORT_DN, "host");
    /** parent directory for leader candidates and holder of the channels master list */
    static final String MASTER_DN = joinZKPath(IMPORT_DN, "master");
    /** leader candidate node prefix for {@link CreateMode#EPHEMERAL_SEQUENTIAL} nodes */
    static final String CANDIDATE_PN = joinZKPath(MASTER_DN, "candidate_");

    static final byte[] EMPTY_ARRAY = "[]".getBytes(StandardCharsets.UTF_8);

    static void mkdirs(ZooKeeper zk, String zkNode) {
        try {
            ZKUtil.asyncMkdirs(zk, zkNode, EMPTY_ARRAY).get();
        } catch (NodeExistsException itIsOk) {
        } catch (InterruptedException | KeeperException e) {
            String msg = "Unable to create zk directory: " + zkNode;
            LOG.error(msg, e);
            throw new DistributerException(msg, e);
        }
    }

    /**
     * Boiler plate method to log an error message and wrap, and return a {@link DistributerException}
     * around the message and cause
     *
     * @param cause fault origin {@link Throwable}
     * @param format a {@link String#format(String, Object...) compliant format string
     * @param args formatter arguments
     * @return a {@link DistributerException}
     */
    static DistributerException loggedDistributerException(Throwable cause, String format, Object...args) {
        Optional<DistributerException> causeFor = DistributerException.isCauseFor(cause);
        if (causeFor.isPresent()) {
            return causeFor.get();
        }
        String msg = String.format(format, args);
        if (cause != null) {
            LOG.error(msg, cause);
            return new DistributerException(msg, cause);
        } else {
            LOG.error(msg);
            return new DistributerException(msg);
        }
    }

    /**
     * Boiler plate method that checks a zookeeper callback @{link {@link KeeperException.Code},
     * converts it to a {@link DistributerException} and if it does not indicate success,
     *
     * @param code a {@link KeeperException.Code callback code}
     * @param format {@link String#format(String, Object...) compliant format string
     * @param args formatter arguments
     * @return an {@link Optional} that may contain a {@link DistributerException}
     */
    static Optional<DistributerException> checkCode(Code code, String format, Object...args) {
        if (code != Code.OK) {
            KeeperException kex = KeeperException.create(code);
            return Optional.of(loggedDistributerException(kex, format, args));
        } else {
            return Optional.absent();
        }
    }

    /**
     * Boiler plate method that acquires, and releases a {@link Semaphore}
     * @param lock a {@link Semaphore}
     */
    static void acquireAndRelease(Semaphore lock) {
        try {
            lock.acquire();
            lock.release();
        } catch (InterruptedException ex) {
            throw loggedDistributerException(ex, "iterruped while waiting for a semaphare");
        }
    }

    /**
     * Reads the JSON document contained in the byte array data, and
     * converts it to a {@link NavigableSet<ChannelSpec> set of channel specs}
     *
     * @param data zookeeper node data content
     * @return a {@link NavigableSet<ChannelSpec> set of channel specs}
     * @throws JSONException on JSON parse failures
     * @throws IllegalArgumentException on encoded channel spec parse failures
     */
    static NavigableSet<ChannelSpec> asChannelSet(byte[] data)
            throws JSONException, IllegalArgumentException {
        ImmutableSortedSet.Builder<ChannelSpec> sbld = ImmutableSortedSet.naturalOrder();
        JSONArray ja = new JSONArray(new String(data, StandardCharsets.UTF_8));
        for (int i=0; i< ja.length(); ++i) {
            sbld.add(new ChannelSpec(ja.getString(i)));
        }
        return  sbld.build();
    }

    /**
     * Converts the given a {@link NavigableSet<ChannelSpec> set of channel specs}
     * into a byte array with the content of a JSON document
     *
     * @param specs a a {@link NavigableSet<ChannelSpec> set of channel specs}
     * @return a byte array
     * @throws JSONException on JSON building failures
     * @throws IllegalArgumentException on channel spec encoding failures
     */
    static byte [] asHostData(NavigableSet<ChannelSpec> specs)
            throws JSONException, IllegalArgumentException {
        JSONStringer js = new JSONStringer();
        js.array();
        for (ChannelSpec spec: specs) {
            js.value(spec.asJSONValue());
        }
        js.endArray();
        return js.toString().getBytes(StandardCharsets.UTF_8);
    }

    /**
     * Tracing utility method useful for debugging
     *
     * @param o and object
     * @return string with information on the given object
     */
    static String id(Object o) {
        if (o == null) return "(null)";
        Thread t = Thread.currentThread();
        StringBuilder sb = new StringBuilder(128);
        sb.append("(T[").append(t.getName()).append("]@");
        sb.append(Long.toString(t.getId(), Character.MAX_RADIX));
        sb.append(":O[").append(o.getClass().getSimpleName());
        sb.append("]@");
        sb.append(Long.toString(System.identityHashCode(o),Character.MAX_RADIX));
        sb.append(")");
        return sb.toString();
    }

    private final ExecutorService m_es;
    private final AtomicBoolean m_done = new AtomicBoolean(false);
    private final ZooKeeper m_zk;
    private final String m_hostId;
    private final String m_candidate;
    private final BlockingDeque<ChannelAssignment> m_assignq;

    volatile boolean m_isLeader = false;
    volatile SpecsRef m_specs = new SpecsRef();
    volatile HostsRef m_hosts = new HostsRef();
    volatile ChannelsRef m_channels = new ChannelsRef();

    /**
     * Initialize a distributer within importer channel distribution mesh by performing the
     * following actions:
     * <ul>
     * <li>registers a leader candidate</li>
     * <li>starts watchers on the channel master list, on the directory holding host nodes,
     * and the directory used for leader elections</li>
     * <li>create election candidate node</li>
     * <li>create its own host node</li>
     * </ul>
     * @param zk
     * @param hostId
     * @param queue
     */
    public ChannelDistributer(ZooKeeper zk, String hostId, BlockingDeque<ChannelAssignment> queue) {
        Preconditions.checkArgument(
                hostId != null && !hostId.trim().isEmpty(),
                "hostId is null or empty"
                );
        m_hostId = hostId;
        m_zk = Preconditions.checkNotNull(zk, "zookeeper is null");
        m_assignq = Preconditions.checkNotNull(queue, "assignment queue is null");
        m_es = CoreUtils.getCachedSingleThreadExecutor("Import Channel Distributer for Host " + hostId, 15000);

        // Prime directory structure if needed
        mkdirs(zk, HOST_DN);
        mkdirs(zk, MASTER_DN);

        MonitorHostNodes monitor = new MonitorHostNodes(HOST_DN);
        CreateNode createHostNode = new CreateNode(
                joinZKPath(HOST_DN, hostId),
                EMPTY_ARRAY, CreateMode.EPHEMERAL
                );
        CreateNode electionCandidate = new CreateNode(
                CANDIDATE_PN,
                EMPTY_ARRAY, CreateMode.EPHEMERAL_SEQUENTIAL
                );
        ElectLeader elector = new ElectLeader(MASTER_DN, electionCandidate);

        monitor.getChildren();
        createHostNode.getNode();
        elector.elect();

        m_candidate = electionCandidate.getNode();
        // monitor the master list
        new GetChannels(MASTER_DN).getChannels();
    }

    public final BlockingDeque<ChannelAssignment> getChannelAssignmentQueue() {
        return m_assignq;
    }

    public String getHostId() {
        return m_hostId;
    }

    /**
     * Register channels for the given importer. If they match to what is already registered
     * then nothing is done
     *
     * @param importer importer designation
     * @param uris list of channel URIs
     */
    public void registerChannels(String importer, Set<URI> uris) {
        Preconditions.checkArgument(
                importer != null && !importer.trim().isEmpty(),
                "importer is null or empty"
                );
        Preconditions.checkArgument(uris != null, "uris set is null");
        Preconditions.checkArgument(
                !FluentIterable.from(uris).anyMatch(isNull()),
                "uris set %s contains null elements",uris
                );

        Predicate<ChannelSpec> forImporter = ChannelSpec.importerIs(importer);
        Function<URI,ChannelSpec> asSpec = ChannelSpec.fromUri(importer);

        // convert method parameters to a set of ChannelSpecs
        NavigableSet<ChannelSpec> proposed = ImmutableSortedSet.copyOf(
                FluentIterable.from(uris).transform(asSpec)
                );

        LOG.info("(" + m_hostId + ") proposing channels " + proposed);

        int [] stamp = new int[]{0};

        ImmutableSortedSet.Builder<ChannelSpec> sbldr = null;
        NavigableSet<ChannelSpec> prev = null;
        SetData setter = null;

        // retry writes when merging with stale data
        do {
            prev = m_channels.get(stamp);

            NavigableSet<ChannelSpec> current  = Sets.filter(prev, forImporter);
            if (current.equals(proposed)) {
                return;
            }
            sbldr = ImmutableSortedSet.naturalOrder();
            sbldr.addAll(Sets.filter(prev, not(forImporter)));
            sbldr.addAll(proposed);

            byte [] data = null;
            try {
                data = asHostData(sbldr.build());
            } catch (JSONException|IllegalArgumentException e) {
                throw loggedDistributerException(e, "failed to serialize the registration as json");
            }

            setter = new SetData(MASTER_DN, stamp[0], data);
        } while (setter.getCallbackCode() == Code.BADVERSION);

        setter.getStat();
    }

    /**
     * Sets the done flag, shuts down its executor thread, and deletes its own host
     * and candidate nodes
     */
    public void shutdown() {
        if (m_done.compareAndSet(false, true)) {
            m_es.shutdown();
            DeleteNode deleteHost = new DeleteNode(joinZKPath(HOST_DN, m_hostId));
            DeleteNode deleteCandidate = new DeleteNode(m_candidate);
            try {
                m_es.awaitTermination(365, TimeUnit.DAYS);
            } catch (InterruptedException e) {
                throw loggedDistributerException(e, "interrupted while waiting for executor termination");
            }
            deleteHost.onComplete();
            deleteCandidate.onComplete();
        }
    }

    /**
     * Base class for all runnables submitted to the executor service
     */
    abstract class DistributerRunnable implements Runnable {
        @Override
        public void run() {
            try {
                if (!m_done.get()) {
                    susceptibleRun();
                }
            } catch (Exception ex) {
                throw loggedDistributerException(ex, "Fault occured while executing runnable");
            }
        }

        public abstract void susceptibleRun() throws Exception;
    }

    /**
     * A {@link DistributerRunnable} that compares the registered {@link ChannelSpec} list
     * against the already assigned list of {@link ChannelSpec}. Any additions are distributed
     * as evenly as possible to all the nodes participating in the distributer mesh, taking into
     * account the removals. Then it writes to each node their assigned list of importer
     * channels. This is run exclusively by the mesh leader.
     *
     */
    class AssignChannels extends DistributerRunnable {

        /** registered channels */
        final NavigableSet<ChannelSpec> channels = m_channels.getReference();
        /** assigned channels */
        final NavigableMap<ChannelSpec,String> specs = m_specs.getReference();
        /** mesh nodes */
        final NavigableMap<String,AtomicInteger> hosts = m_hosts.getReference();

        @Override
        public void susceptibleRun() throws Exception {
            NavigableSet<ChannelSpec> assigned = specs.navigableKeySet();
            Set<ChannelSpec> added   = Sets.difference(channels, assigned);
            Set<ChannelSpec> removed = Sets.difference(assigned, channels);

            if (added.isEmpty() && removed.isEmpty()) {
                return;
            }

            Predicate<Map.Entry<ChannelSpec,String>> withoutRemoved =
                    not(ChannelSpec.specKeyIn(removed, String.class));
            NavigableMap<ChannelSpec,String> pruned =
                    Maps.filterEntries(specs, withoutRemoved);

            if (!removed.isEmpty()) {
                LOG.info("LEADER (" + m_hostId + ") removing channels " + removed);
            }
            // makes it easy to group channels by host
            TreeMultimap<String, ChannelSpec> byhost = TreeMultimap.create();

            for (Map.Entry<ChannelSpec,String> e: pruned.entrySet()) {
                byhost.put(e.getValue(), e.getKey());
            }
            // approximation of how many channels should be assigned to each node
            int fair = new Double(Math.ceil(channels.size()/(double)hosts.size())).intValue();
            List<String> hostassoc = new ArrayList<>(added.size());
            for (String host: hosts.navigableKeySet()) {
                // negative means it is over allocated
                int room = fair - byhost.get(host).size();
                for (int i = 0; i < room; ++i) {
                    hostassoc.add(host);
                }
            }
            Collections.shuffle(hostassoc, new Random(System.identityHashCode(this)));

            Iterator<String> hitr = hostassoc.iterator();
            Iterator<ChannelSpec> citr = added.iterator();
            while (citr.hasNext()) {
                String host = hitr.next();
                ChannelSpec spec = citr.next();
                byhost.put(host, spec);
                LOG.info("LEADER (" + m_hostId + ") assingning " + spec + " to host " + host);
            }

            try {
                // write to each node their assigned channel list
                NavigableSet<ChannelSpec> previous = null;
                NavigableSet<ChannelSpec> needed = null;
                SetNodeChannels setter = null;

                for (String host: hosts.navigableKeySet()) {
                    previous = Maps.filterValues(specs,equalTo(host)).navigableKeySet();
                    needed = byhost.get(host);
                    if (!needed.equals(previous)) {
                        int version = hosts.get(host).get();
                        byte [] nodedata = asHostData(needed);
                        setter = new SetNodeChannels(joinZKPath(HOST_DN, host), version, nodedata);
                    }
                }
                // wait for the last write to complete
                if (setter != null) {
                    setter.getCallbackCode();
                }
            } catch (JSONException|IllegalArgumentException e) {
                LOG.fatal("unable to create json document to assign imported channels to nodes", e);
            }
        }
    }

    /**
     * A wrapper around {@link ZooKeeper#setData(String, byte[], int, StatCallback, Object)} that
     * acts as its own invocation {@link AsyncCallback.StatCallback}
     */
    class SetData implements StatCallback {

        final String path;
        final int version;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        SetData(String path, int version, byte [] data ) {
            this.path = path;
            this.version = version;
            m_zk.setData(path, data, version, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx, Stat stat) {
            callbackCode = Optional.of(Code.get(rc));
            Code code = callbackCode.get();
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
            } else if (code == Code.NONODE || code == Code.BADVERSION) {
                // keep the fault but don't log it
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("failed to write to " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "failed to write to %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
            } finally {
                lock.release();
            }
        }

        public Stat getStat() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return stat.get();
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }
    }

    /**
     * An extension of {@link SetData} that is used to write to nodes their
     * assigned list of import channels. NB the mesh leader is the only one
     * that instantiates and uses this class
     */
    class SetNodeChannels extends SetData {

        SetNodeChannels(String path, int version, byte[] data) {
            super(path, version, data);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, Stat stat) {
            try {
                internalProcessResult(rc, path, ctx, stat);
                Code code = Code.get(rc);
                // no node, or bad version means that we need to work on the assignments
                // again.
                if ((code == Code.NONODE || code == Code.BADVERSION) && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }
    }

    /**
     * A wrapper around {@link ZooKeeper#create(String, byte[], List, CreateMode, StringCallback, Object)}
     * that acts as its own invocation {@link AsyncCallback.StringCallback}
     */
    class CreateNode implements StringCallback {

        final Semaphore lock = new Semaphore(0);
        volatile Optional<String> node = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        CreateNode(String path, byte [] data, CreateMode cmode) {
            m_zk.create(path, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, cmode, this, null);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, String name) {
            try {
                Code code = Code.get(rc);
                switch(code) {
                case NODEEXISTS:
                    code = Code.OK;
                    break;
                case OK:
                    node = Optional.of(name);
                    break;
                default:
                    node = Optional.of(path);
                }
                fault = checkCode(code, "cannot create node %s", node.get());
            } finally {
                lock.release();
            }
        }

        String getNode() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return node.get();
        }
    }

    /**
     * A wrapper around a more tolerant {@link ZooKeeper#delete(String, int, VoidCallback, Object)} that
     * acts as its own invocation {@link AsyncCallback.VoidCallback}.
     */
    class DeleteNode implements VoidCallback {
        final String path;

        final Semaphore lock = new Semaphore(0);
        volatile Optional<DistributerException> fault = Optional.absent();
        volatile Optional<Code> callbackCode = Optional.absent();

        DeleteNode(String path) {
            this.path = path;
            m_zk.delete(path, -1, this, null);
        }

        void internalProcessResult(int rc, String path, Object ctx) {
            callbackCode = Optional.of(Code.get(rc));
            switch (callbackCode.get()) {
            case OK:
            case NONODE:
            case SESSIONEXPIRED:
            case SESSIONMOVED:
            case CONNECTIONLOSS:
                break;
            default:
                fault = checkCode(callbackCode.get(), "failed to delete %s", path);
                break;
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx) {
            try {
                internalProcessResult(rc, path, ctx);
            } finally {
                lock.release();
            }
        }

        public Code getCallbackCode() {
            acquireAndRelease(lock);
            return callbackCode.get();
        }

        public void onComplete() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
        }
    }

    /**
     * A wrapper around {@link ZooKeeper#getChildren(String, Watcher, Children2Callback, Object)} that
     * acts as its own one time {@link Watcher} and its own {@link AsyncCallback.Children2Callback}
     */
    class GetChildren extends DistributerRunnable implements Children2Callback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<NavigableSet<String>> children = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetChildren(String path) {
            this.path = path;
            m_zk.getChildren(path, this, this, null);
        }

        void internalProcessResults(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                NavigableSet<String> childset = ImmutableSortedSet.copyOf(children);
                this.stat = Optional.of(stat);
                this.children = Optional.of(childset);
            } else if (code == Code.SESSIONEXPIRED) {
                // keep the fault but don't log it
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException("unable to get children for " + path, e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to get children for %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
            } finally {
                lock.release();
            }
        }

        public NavigableSet<String> getChildren() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return children.get();
        }

        public Optional<Stat> getStat() {
            return stat;
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeChildrenChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChildren(path);
        }
    }

    /**
     * An extension of {@link GetChildren} that is used to determine the distributer mesh leader
     */
    class ElectLeader extends GetChildren {
        final CreateNode leaderCandidate;

        ElectLeader(String path, CreateNode leaderCandidate) {
            super(path);
            this.leaderCandidate = Preconditions.checkNotNull(leaderCandidate,"candidate is null");
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK || m_done.get()) {
                    return;
                }
                m_es.submit(new DistributerRunnable() {
                    @Override
                    public void susceptibleRun() throws Exception {
                        String candidate = basename.apply(leaderCandidate.getNode());
                        if (!m_isLeader && candidate.equals(ElectLeader.this.children.get().first())) {
                            m_isLeader = true;
                            LOG.info("LEADER (" + m_hostId + ") is now the importer channel leader");
                            // determine node importer channel assignments
                            new AssignChannels().run();
                        }
                    }
                });
            } finally {
                lock.release();
            }
        }

        boolean elect() {
            return getChildren().first().equals(leaderCandidate.getNode());
        }

        @Override
        public void susceptibleRun() throws Exception {
            new ElectLeader(path, leaderCandidate);
        }
    }

    /**
     * A wrapper around {@link ZooKeeper#getData(String, Watcher, DataCallback, Object)} that acts
     * as its own {@link Watcher}, and {@link AsyncCallback.DataCallback}
     */
    class GetData extends DistributerRunnable implements DataCallback, Watcher {

        final String path;
        final Semaphore lock = new Semaphore(0);

        volatile Optional<Stat> stat = Optional.absent();
        volatile Optional<byte[]> data = Optional.absent();
        volatile Optional<DistributerException> fault = Optional.absent();

        GetData(String path) {
            this.path = path;
            m_zk.getData(path, this, this, null);
        }

        @Override
        public void process(WatchedEvent e) {
            if (   e.getState() == KeeperState.SyncConnected
                && e.getType() == EventType.NodeDataChanged
                && !m_done.get())
            {
                m_es.submit(this);
            }
        }

        void internalProcessResults(int rc, String path, Object ctx, byte[] data, Stat stat) {
            Code code = Code.get(rc);
            if (code == Code.OK) {
                this.stat = Optional.of(stat);
                this.data = Optional.of(data != null ? data : EMPTY_ARRAY);
            } else if (code == Code.NONODE || code == Code.SESSIONEXPIRED) {
                // keep the fault but don't log it
                KeeperException e = KeeperException.create(code);
                fault = Optional.of(new DistributerException(path + " went away", e));
            } else if (!m_done.get()) {
                fault = checkCode(code, "unable to read data in %s", path);
            }
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetData(path);
        }

        public byte [] getData() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return data.get();
        }
    }

    /**
     * An extension of {@link GetData} that reads the date contents of a host
     * node as set of assigned importer channels. It merges the set against the
     * the import channels in {@link ChannelDistributer#m_specs}, and if the host
     * node is its own, it sends to the notification queue instances of
     * {@link ChannelAssignment} that describe assignment changes.
     *
     * It is instantiated mainly in {@link MonitorHostNodes}
     *
     */
    class GetHostChannels extends GetData {
        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> nodespecs = Optional.absent();

        final String host;
        final Predicate<Map.Entry<ChannelSpec,String>> thisHost;

        public GetHostChannels(String path) {
            super(path);
            this.host = basename.apply(path);
            this.thisHost = hostValueIs(this.host, ChannelSpec.class);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    nodespecs = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }

                int [] sstamp = new int[]{0};
                AtomicInteger dstamp = m_hosts.getReference().get(host);
                if (dstamp == null) {
                    LOG.warn("(" + m_hostId + ") has no data stamp for "
                            + host + ", host registry contains: " + m_hosts.getReference()
                            );
                    dstamp = new AtomicInteger(0);
                }
                NavigableMap<ChannelSpec,String> prev = null;
                NavigableSet<ChannelSpec> oldspecs = null;
                ImmutableSortedMap.Builder<ChannelSpec,String> mbldr = null;

                do {
                    final int specversion = dstamp.get();
                    // callback has a stale version
                    if (specversion >= stat.getVersion()) {
                        return;
                    }
                    // register the data node version
                    if (!dstamp.compareAndSet(specversion, stat.getVersion())) {
                        return;
                    }

                    prev = m_specs.get(sstamp);
                    oldspecs = Maps.filterEntries(prev, thisHost).navigableKeySet();
                    // rebuild the assigned channel spec list
                    mbldr = ImmutableSortedMap.naturalOrder();
                    mbldr.putAll(Maps.filterEntries(prev, not(thisHost)));
                    for (ChannelSpec spec: nodespecs.get()) {
                        mbldr.put(spec, host);
                    }
                } while (!m_specs.compareAndSet(prev, mbldr.build(), sstamp[0], sstamp[0]+1));

                if (host.equals(m_hostId) && !m_done.get()) {
                    ChannelAssignment assignment = new ChannelAssignment(
                            oldspecs, nodespecs.get(), stat.getVersion()
                            );
                    if (assignment.hasChanges() && !m_assignq.offer(assignment)) {
                        fault = Optional.of(
                                loggedDistributerException(null, "failed to offer channel assignments")
                                );
                    }
                    if (!assignment.getRemoved().isEmpty()) {
                        LOG.info("(" + m_hostId + ") removing the following channel assingments: " + assignment.getRemoved());
                    }
                    if (!assignment.getAdded().isEmpty()) {
                        LOG.info("(" + m_hostId + ") adding the following channel assingments: " + assignment.getAdded());
                    }
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetHostChannels(path);
        }

        NavigableSet<ChannelSpec> getSpecs() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return nodespecs.get();
        }
    }

    /**
     * An extension of {@link GetData} that monitors the content of the registered
     * importer channel list.
     */
    class GetChannels extends GetData {

        Optional<DistributerException> fault = Optional.absent();
        Optional<NavigableSet<ChannelSpec>> channels = Optional.absent();

        public GetChannels(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx, byte[] data, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, data, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }
                try {
                    channels = Optional.of(asChannelSet(data));
                } catch (IllegalArgumentException|JSONException e) {
                    fault = Optional.of(
                            loggedDistributerException(e, "failed to parse json in %s", path)
                            );
                    return;
                }
                int [] stamp = new int[]{0};
                NavigableSet<ChannelSpec> oldspecs = m_channels.get(stamp);
                if (stamp[0] >= stat.getVersion()) {
                    return;
                }
                if (!m_channels.compareAndSet(oldspecs, channels.get(), stamp[0], stat.getVersion())) {
                    return;
                }
                LOG.info("(" + m_hostId + ") succesfully received channel assignment master copy");
                if (m_isLeader && !m_done.get()) {
                    m_es.submit(new AssignChannels());
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new GetChannels(path);
        }

        NavigableSet<ChannelSpec> getChannels() {
            acquireAndRelease(lock);
            if (fault.isPresent()) throw fault.get();
            return channels.get();
        }
    }

    /**
     * An extension of {@link GetChildren} that monitor hosts that participate in the distributer mesh.
     * if any nodes leave the mesh, then they are removed from the assigned list, if any are added
     * then their channel assignments will start to get monitored.
     */
    class MonitorHostNodes extends GetChildren {

        MonitorHostNodes(String path) {
            super(path);
        }

        @Override
        public void processResult(int rc, String path, Object ctx,
                List<String> children, Stat stat) {
            try {
                internalProcessResults(rc, path, ctx, children, stat);
                if (Code.get(rc) != Code.OK) {
                    return;
                }

                int [] hstamp = new int[]{0};
                NavigableMap<String,AtomicInteger> oldgen = m_hosts.get(hstamp);
                if (hstamp[0] >= stat.getCversion()) {
                    return;
                }

                final Set<String> added   = Sets.difference(this.children.get(), oldgen.navigableKeySet());
                final Set<String> removed = Sets.difference(oldgen.navigableKeySet(), this.children.get());

                ImmutableSortedMap.Builder<String,AtomicInteger> hbldr = ImmutableSortedMap.naturalOrder();
                hbldr.putAll(Maps.filterEntries(oldgen, not(hostKeyIn(removed, AtomicInteger.class))));
                for (String add: added) {
                    hbldr.put(add, new AtomicInteger(0));
                }
                NavigableMap<String,AtomicInteger> newgen = hbldr.build();

                if (!m_hosts.compareAndSet(oldgen, newgen, hstamp[0], stat.getCversion())) {
                    return;
                }

                if (!removed.isEmpty()) {
                    final Predicate<Map.Entry<ChannelSpec,String>> inRemoved =
                            hostValueIn(removed, ChannelSpec.class);

                    int [] sstamp = new int[]{0};
                    NavigableMap<ChannelSpec,String> prev = null;
                    NavigableMap<ChannelSpec,String> next = null;

                    do {
                        prev = m_specs.get(sstamp);
                        next = Maps.filterEntries(prev, not(inRemoved));
                    } while (!m_specs.compareAndSet(prev, next, sstamp[0], sstamp[0]+1));

                    LOG.info("(" + m_hostId + ") hosts " + removed + " no longer servicing importer channels");

                    if (m_isLeader && !m_done.get()) {
                        m_es.submit(new AssignChannels());
                    }
                }

                if (!added.isEmpty() && !m_done.get()) {
                    m_es.submit(new DistributerRunnable() {
                        @Override
                        public void susceptibleRun() throws Exception {
                            for (String host: added) {
                                LOG.info("(" + m_hostId + ") starting to monitor host node " + host);
                                new GetHostChannels(joinZKPath(HOST_DN, host));
                            }
                        }
                    });
                }
            } finally {
                lock.release();
            }
        }

        @Override
        public void susceptibleRun() throws Exception {
            new MonitorHostNodes(path);
        }
    }

    // a form of type alias
    final static class HostsRef extends AtomicStampedReference<NavigableMap<String,AtomicInteger>> {
        static final NavigableMap<String,AtomicInteger> EMPTY_MAP = ImmutableSortedMap.of();

        public HostsRef(NavigableMap<String,AtomicInteger> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public HostsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    // a form of type alias
    final static class ChannelsRef extends AtomicStampedReference<NavigableSet<ChannelSpec>> {
        static final NavigableSet<ChannelSpec> EMPTY_SET = ImmutableSortedSet.of();

        public ChannelsRef(NavigableSet<ChannelSpec> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public ChannelsRef() {
            this(EMPTY_SET, 0);
        }
    }

    // a form of type alias
    final static class SpecsRef extends AtomicStampedReference<NavigableMap<ChannelSpec,String>> {
        static final NavigableMap<ChannelSpec,String> EMPTY_MAP = ImmutableSortedMap.of();

        public SpecsRef(NavigableMap<ChannelSpec,String> initialRef, int initialStamp) {
            super(initialRef, initialStamp);
        }

        public SpecsRef() {
            this(EMPTY_MAP, 0);
        }
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIs(final String s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.equals(e.getValue());
            }
        };
    }

    static <K> Predicate<Map.Entry<K, String>> hostValueIn(final Set<String> s, Class<K> clazz) {
        return new Predicate<Map.Entry<K,String>>() {
            @Override
            public boolean apply(Entry<K, String> e) {
                return s.contains(e.getValue());
            }
        };
    }

    static <V> Predicate<Map.Entry<String,V>> hostKeyIn(final Set<String> s, Class<V> clazz) {
        return new Predicate<Map.Entry<String,V>>() {
            @Override
            public boolean apply(Entry<String,V> e) {
                return s.contains(e.getKey());
            }
        };
    }

    final static Function<String,String> basename = new Function<String, String>() {
        @Override
        public String apply(String path) {
            return new File(path).getName();
        }
    };
}


File: src/frontend/org/voltdb/importer/ImportHandlerProxy.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.Method;
import java.net.URI;
import java.util.Set;
import java.util.concurrent.TimeUnit;
import org.voltdb.client.ProcedureCallback;

/**
 * This is the proxy for real ImportHandler. This is used as real handler
 * has lot of server code dependencies and not really helpful for the import bundle builder.
 * @author akhanzode
 */
public abstract class ImportHandlerProxy implements ImportContext, ChannelChangeCallback {

    private Object m_handler = null;
    private Method m_callProcMethod;
    private Method m_asyncCallProcMethod;
    private Method m_hasTableMethod;
    private Method m_info_log;
    private Method m_error_log;
    private Method m_warn_log;
    private Method m_error_log_withT;
    private Method m_debug_log;

    @Override
    public boolean canContinue() {
        return true;
    }

    public boolean hasTable(String name) {
        try {
            return (Boolean) m_hasTableMethod.invoke(m_handler, name);
        } catch(InvocationTargetException e) { // this shouldn't happen
            throw new RuntimeException(e);
        } catch(IllegalAccessException e) { // this shouldn't happen
            throw new RuntimeException(e);
        }
    }

    /**
     * This calls real handler using reflection.
     * @param ic
     * @param proc
     * @param fieldList
     * @return
     */
    @Override
    public boolean callProcedure(String proc, Object... fieldList) {
        try {
            return (Boolean )m_callProcMethod.invoke(m_handler, this, proc, fieldList);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_callProcMethod.invoke(m_handler, this, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public boolean callProcedure(ProcedureCallback cb, Invocation invocation) {
        try {
            Object params[] = invocation.getParams();
            return (Boolean )m_asyncCallProcMethod.invoke(m_handler, this, cb, invocation.getProcedure(), params);
        } catch (Exception ex) {
            return false;
        }
    }

    @Override
    public void setHandler(Object handler) throws Exception {
        m_handler = handler;
        m_callProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, String.class, Object[].class);
        m_asyncCallProcMethod = m_handler.getClass().getMethod("callProcedure", ImportContext.class, ProcedureCallback.class, String.class, Object[].class);
        m_hasTableMethod = m_handler.getClass().getMethod("hasTable", String.class);
        m_info_log = m_handler.getClass().getMethod("info", String.class);
        m_error_log = m_handler.getClass().getMethod("error", String.class);
        m_warn_log = m_handler.getClass().getMethod("warn", String.class);
        m_debug_log = m_handler.getClass().getMethod("debug", String.class);
        m_error_log_withT = m_handler.getClass().getMethod("error", String.class, Throwable.class);
    }

    @Override
    public void info(String message) {
        try {
            if (m_info_log != null) {
                m_info_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message, Throwable t) {
        try {
            if (m_error_log != null) {
                m_error_log_withT.invoke(m_handler, message, t);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void error(String message) {
        try {
            if (m_error_log != null) {
                m_error_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void warn(String message) {
        try {
            if (m_error_log != null) {
                m_warn_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public void debug(String message) {
        try {
            if (m_debug_log != null) {
                m_debug_log.invoke(m_handler, message);
            }
        } catch (Exception ex) {
        }
    }

    @Override
    public long getBackpressureTimeout() {
        return TimeUnit.MINUTES.toNanos(2);
    }

    @Override
    public boolean isRunEveryWhere() {
        return true;
    }

    @Override
    public Set<URI> getAllResponsibleResources() {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }

    @Override
    public void onChange(Set<URI> added, Set<URI> removed, Set<URI> assigned, int version) {
        throw new UnsupportedOperationException("For Distributed Importer this must be implemented.");
    }
}


File: src/frontend/org/voltdb/importer/ImportManager.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.ServiceLoader;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.atomic.AtomicReference;
import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.osgi.framework.BundleException;
import org.osgi.framework.Constants;
import org.osgi.framework.launch.Framework;
import org.osgi.framework.launch.FrameworkFactory;
import static org.voltcore.common.Constants.VOLT_TMP_DIR;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.VoltDB;
import org.voltdb.utils.CatalogUtil;

/**
 *
 * @author akhanzode
 */
public class ImportManager {

    /**
     * Processors also log using this facility.
     */
    private static final VoltLogger importLog = new VoltLogger("IMPORT");

    AtomicReference<ImportDataProcessor> m_processor = new AtomicReference<ImportDataProcessor>();
    private volatile Map<String, Properties> m_processorConfig = new HashMap<>();

    /** Obtain the global ImportManager via its instance() method */
    private static ImportManager m_self;
    private final HostMessenger m_messenger;

    private final FrameworkFactory m_frameworkFactory;
    private final Map<String, String> m_frameworkProps;
    private final Framework m_framework;
    private final int m_myHostId;
    private BlockingDeque<ChannelAssignment> m_queue = new LinkedBlockingDeque<ChannelAssignment>(Integer.getInteger("voltdb.import.maxchannels", 2048));
    private final ChannelDistributer m_distributer;
    /**
     * Get the global instance of the ImportManager.
     * @return The global single instance of the ImportManager.
     */
    public static ImportManager instance() {
        return m_self;
    }

    protected ImportManager(int myHostId, HostMessenger messenger) throws BundleException {
        m_myHostId = myHostId;
        m_messenger = messenger;
        m_distributer = new ChannelDistributer(m_messenger.getZK(), String.valueOf(m_myHostId), m_queue);

        //create properties for osgi
        m_frameworkProps = new HashMap<String, String>();
        //Need this so that ImportContext is available.
        m_frameworkProps.put(Constants.FRAMEWORK_SYSTEMPACKAGES_EXTRA, "org.voltcore.network;version=1.0.0"
                + ",org.voltdb.importer;version=1.0.0,org.apache.log4j;version=1.0.0,org.voltdb.client;version=1.0.0,org.slf4j;version=1.0.0,org.voltcore.utils;version=1.0.0");
        // more properties available at: http://felix.apache.org/documentation/subprojects/apache-felix-framework/apache-felix-framework-configuration-properties.html
        m_frameworkProps.put("org.osgi.framework.storage.clean", "onFirstInit");
        String tmpFilePath = System.getProperty(VOLT_TMP_DIR, System.getProperty("java.io.tmpdir"));
        m_frameworkProps.put("felix.cache.rootdir", tmpFilePath);
        m_frameworkFactory = ServiceLoader.load(FrameworkFactory.class).iterator().next();
        importLog.info("Framework properties are: " + m_frameworkProps);
        m_framework = m_frameworkFactory.newFramework(m_frameworkProps);
        m_framework.start();
    }

    /**
     * Create the singleton ImportManager and initialize.
     */
    public static synchronized void initialize(int myHostId, CatalogContext catalogContext, List<Integer> partitions, HostMessenger messenger) throws BundleException {
        ImportManager em = new ImportManager(myHostId, messenger);

        m_self = em;
        em.create(myHostId, m_self.m_distributer, catalogContext, messenger.getZK());
    }

    /**
     * This creates a import connector from configuration provided.
     * @param catalogContext
     * @param partitions
     */
    private synchronized void create(int myHostId, ChannelDistributer distributer, CatalogContext catalogContext, ZooKeeper zk) {
        try {
            if (catalogContext.getDeployment().getImport() == null) {
                return;
            }
            ImportDataProcessor newProcessor = new ImportProcessor(myHostId, distributer, m_framework);
            m_processorConfig = CatalogUtil.getImportProcessorConfig(catalogContext.getDeployment().getImport());
            newProcessor.setProcessorConfig(m_processorConfig);
            m_processor.set(newProcessor);
            importLog.info("Import Processor is configured.");
        } catch (final Exception e) {
            VoltDB.crashLocalVoltDB("Error creating import processor", true, e);
        }
    }

    public synchronized void shutdown() {
        close();
        m_distributer.shutdown();
    }

    public synchronized void close() {
        //If no processor set we dont have any import configuration
        if (m_processor.get() == null) {
            return;
        }
        m_processor.get().shutdown();
        //Unset until it gets recreated.
        m_processor.set(null);
    }

    //Call this method to restart the whole importer system. It takes current catalogcontext and hostmessenger
    public synchronized void restart(CatalogContext catalogContext, HostMessenger messenger) {
        //Shutdown and recreate.
        m_self.close();
        assert(m_processor.get() == null);
        m_self.create(m_myHostId, m_distributer, catalogContext, messenger.getZK());
        m_self.readyForData(catalogContext, messenger);
    }

    public void updateCatalog(CatalogContext catalogContext, HostMessenger messenger) {
        restart(catalogContext, messenger);
    }

    public synchronized void readyForData(CatalogContext catalogContext, HostMessenger messenger) {
        //If we dont have any processors we dont have any import configured.
        if (m_processor.get() == null) {
            return;
        }
        //Tell import processors and in turn ImportHandlers that we are ready to take in data.
        m_processor.get().readyForData(catalogContext, messenger);
    }

}


File: src/frontend/org/voltdb/importer/ImportProcessor.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.importer;

import java.util.HashMap;
import java.util.Map;
import java.util.Properties;

import org.osgi.framework.Bundle;
import org.osgi.framework.ServiceReference;
import org.osgi.framework.launch.Framework;
import org.voltcore.logging.VoltLogger;
import org.voltcore.messaging.HostMessenger;
import org.voltdb.CatalogContext;
import org.voltdb.ImportHandler;
import org.voltdb.VoltDB;

import com.google_voltpatches.common.base.Preconditions;
import com.google_voltpatches.common.base.Throwables;
import java.net.URI;
import java.util.HashSet;
import java.util.Set;
import org.osgi.framework.BundleException;

public class ImportProcessor implements ImportDataProcessor {

    private static final VoltLogger m_logger = new VoltLogger("IMPORT");
    private final Map<String, BundleWrapper> m_bundles = new HashMap<String, BundleWrapper>();
    private final Map<String, BundleWrapper> m_bundlesByName = new HashMap<String, BundleWrapper>();
    private final Framework m_framework;
    private final ChannelDistributer m_distributer;
    private final ChannelChangeNotifier m_channelNotifier;

    public ImportProcessor(int myHostId, ChannelDistributer distributer, Framework framework) throws BundleException {
        m_framework = framework;
        m_distributer = distributer;
        m_channelNotifier = new ChannelChangeNotifier();
    }

    //This abstracts OSGi based and class based importers.
    public class BundleWrapper {
        public final Bundle m_bundle;
        public final Properties m_properties;
        public final ImportHandlerProxy m_handlerProxy;
        private ImportHandler m_handler;
        private ChannelDistributer m_channelDistributer;

        public BundleWrapper(ImportHandlerProxy handler, Properties properties, Bundle bundle) {
            m_bundle = bundle;
            m_handlerProxy = handler;
            m_properties = properties;
        }

        public void setChannelDistributer(ChannelDistributer distributer) {
            m_channelDistributer = distributer;
        }

        public void setHandler(ImportHandler handler) throws Exception {
            Preconditions.checkState((m_handler == null), "ImportHandler can only be set once.");
            m_handler = handler;
            m_handlerProxy.setHandler(handler);
        }

        public ImportHandler getHandler() {
            return m_handler;
        }

        public void stop() {
            try {
                m_handler.stop();
                if (m_bundle != null) {
                    m_bundle.stop();
                }
                if (m_channelDistributer != null) {
                    m_channelDistributer.registerChannels(m_handlerProxy.getName(), new HashSet<URI>());
                }
            } catch (Exception ex) {
                m_logger.error("Failed to stop the import bundles.", ex);
            }
        }
    }

    public void addProcessorConfig(Properties properties) {
        String module = properties.getProperty(ImportDataProcessor.IMPORT_MODULE);
        String moduleAttrs[] = module.split("\\|");
        String bundleJar = moduleAttrs[1];
        String moduleType = moduleAttrs[0];

        Preconditions.checkState(!m_bundles.containsKey(bundleJar), "Import to source is already defined.");
        try {
            BundleWrapper wrapper = null;
            ImportHandlerProxy importHandlerProxy = null;
            if (moduleType.equalsIgnoreCase("osgi")) {

                Bundle bundle = m_framework.getBundleContext().installBundle(bundleJar);
                bundle.start();
                ServiceReference refs[] = bundle.getRegisteredServices();
                //Must have one service only.
                ServiceReference reference = refs[0];
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    bundle.stop();
                    return;
                }
                Object o = bundle.getBundleContext().getService(reference);
                importHandlerProxy = (ImportHandlerProxy )o;
                wrapper = new BundleWrapper(importHandlerProxy, properties, bundle);
            } else {
                //Class based importer.
                Class reference = this.getClass().getClassLoader().loadClass(bundleJar);
                if (reference == null) {
                    m_logger.error("Failed to initialize importer from: " + bundleJar);
                    return;
                }

                importHandlerProxy = (ImportHandlerProxy )reference.newInstance();
                 wrapper = new BundleWrapper(importHandlerProxy, properties, null);
            }
            importHandlerProxy.configure(properties);
            String name = importHandlerProxy.getName();
            if (name == null || name.trim().length() == 0) {
                throw new RuntimeException("Importer must implement and return a valid unique name.");
            }
            Preconditions.checkState(!m_bundlesByName.containsKey(name), "Importer must implement and return a valid unique name: " + name);
            m_bundlesByName.put(name, wrapper);
            m_bundles.put(bundleJar, wrapper);
        } catch(Throwable t) {
            m_logger.error("Failed to configure import handler for " + bundleJar, t);
            Throwables.propagate(t);
        }
    }

    @Override
    public synchronized void readyForData(CatalogContext catContext, HostMessenger messenger) {

        for (BundleWrapper bw : m_bundles.values()) {
            try {
                ImportHandler importHandler = new ImportHandler(bw.m_handlerProxy, catContext);
                //Set the internal handler
                bw.setHandler(importHandler);
                if (!bw.m_handlerProxy.isRunEveryWhere()) {
                    //This is a distributed and fault tolerant importer so get the resources.
                    Set<URI> allResources = bw.m_handlerProxy.getAllResponsibleResources();
                    m_logger.info("All Available Resources for " + bw.m_handlerProxy.getName() + " Are: " + allResources);

                    bw.setChannelDistributer(m_distributer);
                    //Register callback
                    m_channelNotifier.registerCallback(bw.m_handlerProxy.getName(), bw.m_handlerProxy);
                    m_distributer.registerChannels(bw.m_handlerProxy.getName(), allResources);
                }
                importHandler.readyForData();
                m_logger.info("Importer started: " + bw.m_handlerProxy.getName());
            } catch (Exception ex) {
                //Should never fail. crash.
                VoltDB.crashLocalVoltDB("Import failed to set Handler", true, ex);
                m_logger.error("Failed to start the import handler: " + bw.m_handlerProxy.getName(), ex);
            }
        }
        //Start polling for channel assignments.
        m_channelNotifier.startPolling(m_distributer.getChannelAssignmentQueue());
    }

    @Override
    public synchronized void shutdown() {
        try {
            //Stop the notifier
            m_channelNotifier.shutdown();
            //Stop all the bundle wrappers.
            for (BundleWrapper bw : m_bundles.values()) {
                try {
                    bw.stop();
                } catch (Exception ex) {
                    m_logger.error("Failed to stop the import handler: " + bw.m_handlerProxy.getName(), ex);
                }
            }
            m_bundles.clear();
        } catch (Exception ex) {
            m_logger.error("Failed to stop the import bundles.", ex);
        }
    }

    @Override
    public void setProcessorConfig(Map<String, Properties> config) {
        for (String cname : config.keySet()) {
            Properties properties = config.get(cname);

            String importBundleJar = properties.getProperty(IMPORT_MODULE);
            Preconditions.checkNotNull(importBundleJar, "Import source is undefined or custom export plugin class missing.");
            addProcessorConfig(properties);
        }
    }

}


File: src/frontend/org/voltdb/sysprocs/Pause.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Pause extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Pause was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    /**
     * Enter admin mode
     * @param ctx       Internal parameter. Not user-accessible.
     * @return          Standard STATUS table.
     */
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        // Choose the lowest site ID on this host to actually flip the bit
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.PAUSED);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.PAUSED.toString().getBytes("UTF-8"), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}


File: src/frontend/org/voltdb/sysprocs/Resume.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as
 * published by the Free Software Foundation, either version 3 of the
 * License, or (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with VoltDB.  If not, see <http://www.gnu.org/licenses/>.
 */

package org.voltdb.sysprocs;

import java.util.List;
import java.util.Map;

import org.voltdb.DependencyPair;
import org.voltdb.SystemProcedureExecutionContext;
import org.voltdb.OperationMode;
import org.voltdb.ParameterSet;
import org.voltdb.ProcInfo;
import org.voltdb.VoltDB;
import org.voltdb.VoltSystemProcedure;
import org.voltdb.VoltTable;
import org.voltdb.VoltZK;

@ProcInfo(singlePartition = false)

public class Resume extends VoltSystemProcedure
{
    @Override
    public void init() {}

    @Override
    public DependencyPair executePlanFragment(
            Map<Integer, List<VoltTable>> dependencies, long fragmentId,
            ParameterSet params, SystemProcedureExecutionContext context)
    {
        throw new RuntimeException("Resume was given an " +
                                   "invalid fragment id: " + String.valueOf(fragmentId));
    }

    /**
     * Exit admin mode
     * @param ctx       Internal parameter. Not user-accessible.
     * @return          Standard STATUS table.
     */
    public VoltTable[] run(SystemProcedureExecutionContext ctx)
    {
        // Choose the lowest site ID on this host to actually flip the bit
        if (ctx.isLowestSiteId())
        {
            VoltDB.instance().setMode(OperationMode.RUNNING);
            try {
                VoltDB.instance().getHostMessenger().getZK().setData(
                        VoltZK.operationMode,
                        OperationMode.RUNNING.toString().getBytes("UTF-8"), -1);
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }

        VoltTable t = new VoltTable(VoltSystemProcedure.STATUS_SCHEMA);
        t.addRow(VoltSystemProcedure.STATUS_OK);
        return (new VoltTable[] {t});
    }
}


File: tests/frontend/org/voltdb/importer/TestChannelDistributer.java
/* This file is part of VoltDB.
 * Copyright (C) 2008-2015 VoltDB Inc.
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 */

package org.voltdb.importer;

import static com.google_voltpatches.common.base.Predicates.equalTo;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;

import java.net.URI;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.BlockingDeque;
import java.util.concurrent.LinkedBlockingDeque;
import java.util.concurrent.TimeUnit;

import org.apache.zookeeper_voltpatches.ZooKeeper;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.voltcore.zk.ZKTestBase;

import com.google_voltpatches.common.collect.FluentIterable;
import com.google_voltpatches.common.collect.ImmutableMap;
import com.google_voltpatches.common.collect.ImmutableSet;
import com.google_voltpatches.common.collect.Maps;
import com.google_voltpatches.common.collect.Sets;

public class TestChannelDistributer extends ZKTestBase {

    private final static String ZERO = "zero";
    private final static String UNO  = "uno";
    private final static String DUE  = "due";
    private final static String YO   = "yo";

    Map<String, ZooKeeper> zks;
    Map<String, ChannelDistributer> distributers;
    BlockingDeque<ChannelAssignment> queue;

    static Set<ChannelSpec> fromURIs(Set<URI> uris) {
        return FluentIterable.from(uris).transform(ChannelSpec.fromUri(YO)).toSet();
    }

    static Set<URI> generateURIs(int count) {
        ImmutableSet.Builder<URI> sbldr = ImmutableSet.builder();
        for (int i=0; i < count; ++i) {
            sbldr.add(URI.create(String.format("x-import://yo/no%04d", i)));
        }
        return sbldr.build();
    }

    Set<ChannelSpec> getRemoved(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<ChannelSpec> sbldr = ImmutableSet.builder();
        ChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200,TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getRemoved().size();
            sbldr.addAll(assignment.getRemoved());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    Set<ChannelSpec> getAdded(int expected) throws Exception {
        int received = 0;
        ImmutableSet.Builder<ChannelSpec> sbldr = ImmutableSet.builder();
        ChannelAssignment assignment = null;
        while (received < expected && (assignment=queue.poll(200,TimeUnit.MILLISECONDS)) != null) {
            received += assignment.getAdded().size();
            sbldr.addAll(assignment.getAdded());
        }
        assertEquals("failed to poll the expected number of removed", expected, received);
        assertTrue(queue.isEmpty());
        return sbldr.build();
    }

    @Before
    public void setup() throws Exception {
        setUpZK(3);
        queue = new LinkedBlockingDeque<>();
        zks = ImmutableMap.<String, ZooKeeper>builder()
                .put(ZERO, getClient(0))
                .put(UNO,  getClient(1))
                .put(DUE,  getClient(2))
                .build();
        distributers = ImmutableMap.<String, ChannelDistributer>builder()
                .put(ZERO, new ChannelDistributer(zks.get(ZERO), ZERO, queue))
                .put(UNO,  new ChannelDistributer(zks.get(UNO), UNO, queue))
                .put(DUE,  new ChannelDistributer(zks.get(DUE), DUE, queue))
                .build();
    }

    @Test
    public void testRegistration() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<ChannelSpec> expected = fromURIs(uris);
        // add nine
        distributers.get(UNO).registerChannels(YO, uris);
        Set<ChannelSpec> actual = getAdded(9);

        assertEquals(expected, actual);

        Set<URI> pruned = generateURIs(6);
        expected = Sets.difference(fromURIs(uris), fromURIs(pruned));
        // remove 3
        distributers.get(DUE).registerChannels(YO, pruned);
        actual = getRemoved(3);

        assertEquals(expected, actual);
        // register the same
        distributers.get(ZERO).registerChannels(YO, pruned);
        assertNull(queue.poll(200,TimeUnit.MILLISECONDS));

        uris = generateURIs(8);
        expected = Sets.difference(fromURIs(uris), fromURIs(pruned));
        // add two
        distributers.get(UNO).registerChannels(YO, uris);
        actual = getAdded(2);

        assertEquals(expected, actual);

        expected = fromURIs(uris);
        // remove all
        distributers.get(UNO).registerChannels(YO, ImmutableSet.<URI>of());
        actual = getRemoved(8);

        assertEquals(expected, actual);

        int leaderCount = 0;
        for (ChannelDistributer distributer: distributers.values()) {
            if (distributer.m_isLeader) {
                ++leaderCount;
            }
        }
        assertEquals(1, leaderCount);
    }

    @Test
    public void testHostFailure() throws Exception {
        Set<URI> uris = generateURIs(9);
        Set<ChannelSpec> expected = fromURIs(uris);
        // add nine
        distributers.get(UNO).registerChannels(YO, uris);
        Set<ChannelSpec> actual = getAdded(9);

        assertEquals(expected, actual);

        // let's wait for the mesh to settle
        int attempts = 4;
        boolean settled = false;
        while (!settled && --attempts >=0) {
            Thread.sleep(50);
            settled = true;
            int stamp = distributers.get(ZERO).m_specs.getStamp();
            for (ChannelDistributer distributer: distributers.values()) {
                settled = settled && stamp == distributer.m_specs.getStamp();
            }
        }
        assertTrue(settled);

        Set<ChannelSpec> inZERO = Maps.filterValues(
                distributers.get(DUE).m_specs.getReference(),
                equalTo(ZERO))
                .navigableKeySet();
        assertTrue(inZERO.size() > 0);

        zks.get(ZERO).close();

        actual = getAdded(inZERO.size());
        assertEquals(inZERO, actual);
    }

    @After
    public void tearDown() throws Exception {
        for (ChannelDistributer distributer: distributers.values()) {
            distributer.shutdown();
        }
        tearDownZK();
    }
}
