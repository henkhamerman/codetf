Refactoring Types: ['Extract Method']
rg/apache/drill/exec/physical/impl/window/DefaultFrameTemplate.java
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.drill.exec.physical.impl.window;

import org.apache.drill.common.exceptions.DrillException;
import org.apache.drill.exec.exception.SchemaChangeException;
import org.apache.drill.exec.record.TransferPair;
import org.apache.drill.exec.record.VectorAccessible;
import org.apache.drill.exec.record.VectorContainer;
import org.apache.drill.exec.record.VectorWrapper;
import org.apache.drill.exec.vector.ValueVector;

import javax.inject.Named;
import java.util.Iterator;
import java.util.List;


public abstract class DefaultFrameTemplate implements WindowFramer {
  private static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(DefaultFrameTemplate.class);

  private VectorContainer container;
  private List<WindowDataBatch> batches;
  private int outputCount; // number of rows in currently/last processed batch

  /**
   * current partition being processed.</p>
   * Can span over multiple batches, so we may need to keep it between calls to doWork()
   */
  private Partition partition;

  @Override
  public void setup(List<WindowDataBatch> batches, final VectorContainer container) throws SchemaChangeException {
    this.container = container;
    this.batches = batches;

    outputCount = 0;
    partition = null;
  }

  private void allocateOutgoing() {
    for (VectorWrapper<?> w : container) {
      w.getValueVector().allocateNew();
    }
  }

  /**
   * processes all rows of current batch:
   * <ul>
   *   <li>compute aggregations</li>
   *   <li>compute window functions</li>
   *   <li>transfer remaining vectors from current batch to container</li>
   * </ul>
   */
  @Override
  public void doWork() throws DrillException {
    int currentRow = 0;

    logger.trace("WindowFramer.doWork() START, num batches {}, current batch has {} rows",
      batches.size(), batches.get(0).getRecordCount());

    allocateOutgoing();

    final WindowDataBatch current = batches.get(0);

    // we need to store the record count explicitly, because we release current batch at the end of this call
    outputCount = current.getRecordCount();

    while (currentRow < outputCount) {
      if (partition != null) {
        assert currentRow == 0 : "pending windows are only expected at the start of the batch";

        // we have a pending window we need to handle from a previous call to doWork()
        logger.trace("we have a pending partition {}", partition);
      } else {
        final int length = computePartitionSize(currentRow);
        partition = new Partition(length);
        setupWrite(current, container);
      }

      currentRow = processPartition(currentRow);
      if (partition.isDone()) {
        partition = null;
        resetValues();
      }
    }

    // transfer "non aggregated" vectors
    for (VectorWrapper<?> vw : current) {
      ValueVector v = container.addOrGet(vw.getField());
      TransferPair tp = vw.getValueVector().makeTransferPair(v);
      tp.transfer();
    }

    for (VectorWrapper<?> v : container) {
      v.getValueVector().getMutator().setValueCount(outputCount);
    }

    // because we are using the default frame, and we keep the aggregated value until we start a new frame
    // we can safely free the current batch
    batches.remove(0).clear();

    logger.trace("WindowFramer.doWork() END");
  }

  /**
   * process all rows (computes and writes aggregation values) of current batch that are part of current partition.
   * @param currentRow first unprocessed row
   * @return index of next unprocessed row
   * @throws DrillException if it can't write into the container
   */
  private int processPartition(final int currentRow) throws DrillException {
    logger.trace("process partition {}, currentRow: {}, outputCount: {}", partition, currentRow, outputCount);

    int row = currentRow;
    while (row < outputCount && !partition.isDone()) {
      if (partition.isFrameDone()) {
        // because all peer rows share the same frame, we only need to compute and aggregate the frame once
        partition.newFrame(countPeers(row));
        aggregatePeers(row);
      }

      outputAggregatedValues(row, partition);

      partition.rowAggregated();
      row++;
    }

    return row;
  }

  /**
   * @return number of rows that are part of the partition starting at row start of first batch
   */
  private int computePartitionSize(final int start) {
    logger.trace("compute partition size starting from {} on {} batches", start, batches.size());

    // current partition always starts from first batch
    final VectorAccessible first = getCurrent();

    int length = 0;

    // count all rows that are in the same partition of start
    // keep increasing length until we find first row of next partition or we reach the very
    // last batch
    for (WindowDataBatch batch : batches) {
      final int recordCount = batch.getRecordCount();

      // check first container from start row, and subsequent containers from first row
      for (int row = (batch == first) ? start : 0; row < recordCount; row++, length++) {
        if (!isSamePartition(start, first, row, batch)) {
          return length;
        }
      }
    }

    return length;
  }

  /**
   * Counts how many rows are peer with the first row of the current frame
   * @param start first row of current frame
   * @return number of peer rows
   */
  private int countPeers(final int start) {
    // current frame always starts from first batch
    final VectorAccessible first = getCurrent();

    int length = 0;

    // count all rows that are in the same frame of starting row
    // keep increasing length until we find first non peer row we reach the very
    // last batch
    for (WindowDataBatch batch : batches) {
      final int recordCount = batch.getRecordCount();

      // for every remaining row in the partition, count it if it's a peer row
      final int remaining = partition.getRemaining();
      for (int row = (batch == first) ? start : 0; row < recordCount && length < remaining; row++, length++) {
        if (!isPeer(start, first, row, batch)) {
          return length;
        }
      }
    }

    return length;
  }

  /**
   * aggregates all peer rows of current row
   * @param currentRow starting row of the current frame
   * @throws SchemaChangeException
   */
  private void aggregatePeers(final int currentRow) throws SchemaChangeException {
    logger.trace("aggregating {} rows starting from {}", partition.getPeers(), currentRow);
    assert !partition.isFrameDone() : "frame is empty!";

    // a single frame can include rows from multiple batches
    // start processing first batch and, if necessary, move to next batches
    Iterator<WindowDataBatch> iterator = batches.iterator();
    WindowDataBatch current = iterator.next();
    setupRead(current, container);

    final int peers = partition.getPeers();
    for (int i = 0, row = currentRow; i < peers; i++, row++) {
      if (row >= current.getRecordCount()) {
        // we reached the end of the current batch, move to the next one
        current = iterator.next();
        setupRead(current, container);
        row = 0;
      }

      aggregateRecord(row);
    }
  }

  @Override
  public boolean canDoWork() {
    // check if we can process a saved batch
    if (batches.size() < 2) {
      logger.trace("we don't have enough batches to proceed, fetch next batch");
      return false;
    }

    final VectorAccessible current = getCurrent();
    final int currentSize = current.getRecordCount();
    final VectorAccessible last = batches.get(batches.size() - 1);
    final int lastSize = last.getRecordCount();

    if (!isSamePartition(currentSize - 1, current, lastSize - 1, last)
        || !isPeer(currentSize - 1, current, lastSize - 1, last)) {
      logger.trace("frame changed, we are ready to process first saved batch");
      return true;
    } else {
      logger.trace("frame didn't change, fetch next batch");
      return false;
    }
  }

  /**
   * @return saved batch that will be processed in doWork()
   */
  private VectorAccessible getCurrent() {
    return batches.get(0);
  }

  @Override
  public int getOutputCount() {
    return outputCount;
  }

  @Override
  public void cleanup() {
  }

  /**
   * setup incoming container for aggregateRecord()
   */
  public abstract void setupRead(@Named("incoming") VectorAccessible incoming, @Named("outgoing") VectorAccessible outgoing) throws SchemaChangeException;

  /**
   * setup outgoing container for outputAggregatedValues. This will also reset the aggregations in most cases.
   */
  public abstract void setupWrite(@Named("incoming") WindowDataBatch incoming, @Named("outgoing") VectorAccessible outgoing) throws SchemaChangeException;

  /**
   * aggregates a row from the incoming container
   * @param index of row to aggregate
   */
  public abstract void aggregateRecord(@Named("index") int index);

  /**
   * writes aggregated values to row of outgoing container
   * @param outIndex index of row
   */
  public abstract void outputAggregatedValues(@Named("outIndex") int outIndex, @Named("partition") Partition partition);

  /**
   * reset all window functions
   */
  public abstract boolean resetValues();

  /**
   * compares two rows from different batches (can be the same), if they have the same value for the partition by
   * expression
   * @param b1Index index of first row
   * @param b1 batch for first row
   * @param b2Index index of second row
   * @param b2 batch for second row
   * @return true if the rows are in the same partition
   */
  public abstract boolean isSamePartition(@Named("b1Index") int b1Index, @Named("b1") VectorAccessible b1,
                                          @Named("b2Index") int b2Index, @Named("b2") VectorAccessible b2);

  /**
   * compares two rows from different batches (can be the same), if they have the same value for the order by
   * expression
   * @param b1Index index of first row
   * @param b1 batch for first row
   * @param b2Index index of second row
   * @param b2 batch for second row
   * @return true if the rows are in the same partition
   */
  public abstract boolean isPeer(@Named("b1Index") int b1Index, @Named("b1") VectorAccessible b1,
                                 @Named("b2Index") int b2Index, @Named("b2") VectorAccessible b2);
}


File: exec/java-exec/src/main/java/org/apache/drill/exec/physical/impl/xsort/MSortTemplate.java
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.drill.exec.physical.impl.xsort;

import com.typesafe.config.ConfigException;
import io.netty.buffer.DrillBuf;

import java.util.Queue;

import javax.inject.Named;

import org.apache.drill.exec.ExecConstants;
import org.apache.drill.exec.exception.SchemaChangeException;
import org.apache.drill.exec.memory.BufferAllocator;
import org.apache.drill.exec.ops.FragmentContext;
import org.apache.drill.exec.record.RecordBatch;
import org.apache.drill.exec.record.VectorContainer;
import org.apache.drill.exec.record.selection.SelectionVector4;
import org.apache.hadoop.util.IndexedSortable;

import com.google.common.base.Preconditions;
import com.google.common.base.Stopwatch;
import com.google.common.collect.Queues;

public abstract class MSortTemplate implements MSorter, IndexedSortable{
//  private static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(MSortTemplate.class);

  private SelectionVector4 vector4;
  private SelectionVector4 aux;
  private long compares;
  private Queue<Integer> runStarts = Queues.newLinkedBlockingQueue();
  private Queue<Integer> newRunStarts;
  private FragmentContext context;

  @Override
  public void setup(final FragmentContext context, final BufferAllocator allocator, final SelectionVector4 vector4, final VectorContainer hyperBatch) throws SchemaChangeException{
    // we pass in the local hyperBatch since that is where we'll be reading data.
    Preconditions.checkNotNull(vector4);
    this.vector4 = vector4.createNewWrapperCurrent();
    this.context = context;
    vector4.clear();
    doSetup(context, hyperBatch, null);
    runStarts.add(0);
    int batch = 0;
    final int totalCount = this.vector4.getTotalCount();
    for (int i = 0; i < totalCount; i++) {
      final int newBatch = this.vector4.get(i) >>> 16;
      if (newBatch == batch) {
        continue;
      } else if(newBatch == batch + 1) {
        runStarts.add(i);
        batch = newBatch;
      } else {
        throw new UnsupportedOperationException("Missing batch");
      }
    }
    final DrillBuf drillBuf = allocator.buffer(4 * totalCount);

    // This is only useful for debugging: change the maximum size of batches exposed to downstream
    // when we don't spill to disk
    int MSORT_BATCH_MAXSIZE;
    try {
      MSORT_BATCH_MAXSIZE = context.getConfig().getInt(ExecConstants.EXTERNAL_SORT_MSORT_MAX_BATCHSIZE);
    } catch(ConfigException.Missing e) {
      MSORT_BATCH_MAXSIZE = Character.MAX_VALUE;
    }
    aux = new SelectionVector4(drillBuf, totalCount, MSORT_BATCH_MAXSIZE);
  }

  /**
   * For given recordCount how much memory does MSorter needs for its own purpose. This is used in
   * ExternalSortBatch to make decisions about whether to spill or not.
   *
   * @param recordCount
   * @return
   */
  public static long memoryNeeded(final int recordCount) {
    // We need 4 bytes (SV4) for each record.
    return recordCount * 4;
  }

  private int merge(final int leftStart, final int rightStart, final int rightEnd, final int outStart) {
    int l = leftStart;
    int r = rightStart;
    int o = outStart;
    while (l < rightStart && r < rightEnd) {
      if (compare(l, r) <= 0) {
        aux.set(o++, vector4.get(l++));
      } else {
        aux.set(o++, vector4.get(r++));
      }
    }
    while (l < rightStart) {
      aux.set(o++, vector4.get(l++));
    }
    while (r < rightEnd) {
      aux.set(o++, vector4.get(r++));
    }
    assert o == outStart + (rightEnd - leftStart);
    return o;
  }

  @Override
  public SelectionVector4 getSV4() {
    return vector4;
  }

  @Override
  public void sort(final VectorContainer container) {
    final Stopwatch watch = new Stopwatch();
    watch.start();
    while (runStarts.size() > 1) {

      // check if we're cancelled/failed frequently
      if (!context.shouldContinue()) {
        return;
      }

      int outIndex = 0;
      newRunStarts = Queues.newLinkedBlockingQueue();
      newRunStarts.add(outIndex);
      final int size = runStarts.size();
      for (int i = 0; i < size / 2; i++) {
        final int left = runStarts.poll();
        final int right = runStarts.poll();
        Integer end = runStarts.peek();
        if (end == null) {
          end = vector4.getTotalCount();
        }
        outIndex = merge(left, right, end, outIndex);
        if (outIndex < vector4.getTotalCount()) {
          newRunStarts.add(outIndex);
        }
      }
      if (outIndex < vector4.getTotalCount()) {
        copyRun(outIndex, vector4.getTotalCount());
      }
      final SelectionVector4 tmp = aux.createNewWrapperCurrent();
      aux.clear();
      aux = this.vector4.createNewWrapperCurrent();
      vector4.clear();
      this.vector4 = tmp.createNewWrapperCurrent();
      tmp.clear();
      runStarts = newRunStarts;
    }
    aux.clear();
  }

  private void copyRun(final int start, final int end) {
    for (int i = start; i < end; i++) {
      aux.set(i, vector4.get(i));
    }
  }

  @Override
  public void swap(final int sv0, final int sv1) {
    final int tmp = vector4.get(sv0);
    vector4.set(sv0, vector4.get(sv1));
    vector4.set(sv1, tmp);
  }

  @Override
  public int compare(final int leftIndex, final int rightIndex) {
    final int sv1 = vector4.get(leftIndex);
    final int sv2 = vector4.get(rightIndex);
    compares++;
    return doEval(sv1, sv2);
  }

  @Override
  public void clear() {
    if(vector4 != null) {
      vector4.clear();
    }

    if(aux != null) {
      aux.clear();
    }
  }

  public abstract void doSetup(@Named("context") FragmentContext context, @Named("incoming") VectorContainer incoming, @Named("outgoing") RecordBatch outgoing);
  public abstract int doEval(@Named("leftIndex") int leftIndex, @Named("rightIndex") int rightIndex);

}


File: exec/java-exec/src/main/java/org/apache/drill/exec/record/selection/SelectionVector4.java
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.drill.exec.record.selection;

import io.netty.buffer.ByteBuf;

import org.apache.drill.exec.exception.SchemaChangeException;
import org.apache.drill.exec.record.DeadBuf;

public class SelectionVector4 {
  static final org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(SelectionVector4.class);

  private ByteBuf data;
  private int recordCount;
  private int start;
  private int length;

  public SelectionVector4(ByteBuf vector, int recordCount, int batchRecordCount) throws SchemaChangeException {
    if (recordCount > Integer.MAX_VALUE /4) {
      throw new SchemaChangeException(String.format("Currently, Drill can only support allocations up to 2gb in size.  You requested an allocation of %d bytes.", recordCount * 4));
    }
    this.recordCount = recordCount;
    this.start = 0;
    this.length = Math.min(batchRecordCount, recordCount);
    this.data = vector;
  }

  public int getTotalCount() {
    return recordCount;
  }

  public int getCount() {
    return length;
  }

  public void setCount(int length) {
    this.length = length;
    this.recordCount = length;
  }

  public void set(int index, int compound) {
    data.setInt(index*4, compound);
  }

  public void set(int index, int recordBatch, int recordIndex) {
    data.setInt(index*4, (recordBatch << 16) | (recordIndex & 65535));
  }

  public int get(int index) {
    return data.getInt( (start+index)*4);
  }

  /**
   * Caution: This method shares the underlying buffer between this vector and the newly created one.
   * @return Newly created single batch SelectionVector4.
   * @throws SchemaChangeException
   */
  public SelectionVector4 createNewWrapperCurrent() {
    try {
      data.retain();
      SelectionVector4 sv4 = new SelectionVector4(data, recordCount, length);
      sv4.start = this.start;
      return sv4;
    } catch (SchemaChangeException e) {
      throw new IllegalStateException("This shouldn't happen.");
    }
  }

  public boolean next() {
//    logger.debug("Next called. Start: {}, Length: {}, recordCount: " + recordCount, start, length);

    if (start + length >= recordCount) {

      start = recordCount;
      length = 0;
//      logger.debug("Setting count to zero.");
      return false;
    }

    start = start+length;
    int newEnd = Math.min(start+length, recordCount);
    length = newEnd - start;
//    logger.debug("New start {}, new length {}", start, length);
    return true;
  }

  public void clear() {
    start = 0;
    length = 0;
    if (data != DeadBuf.DEAD_BUFFER) {
      data.release();
      data = DeadBuf.DEAD_BUFFER;
    }
  }

}
